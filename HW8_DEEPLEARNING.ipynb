{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patty-13/DEEP_LEARNING_NJIT/blob/main/HW8_DEEPLEARNING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huHYD5NSSkIM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"  # specify which GPU(s) to be used\n",
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import os.path\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import data\n",
        "import random\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 1213\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "np.random.seed(seed)\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "ybsYxBrMTgLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# An example of load labelled data.\n",
        "# The unlabelled data and test data have similar format\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!gdown --id '1YfFHDr9sV-98K4bf0d89W49-73wx7m0n' --output \"labelled.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "am3q7O8fTXdJ",
        "outputId": "ae4773ae-a82f-4282-f1c3-c6045638df80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1YfFHDr9sV-98K4bf0d89W49-73wx7m0n\n",
            "To: /content/labelled.zip\n",
            "100% 2.67G/2.67G [00:13<00:00, 203MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q \"labelled.zip\" -d \"./\""
      ],
      "metadata": {
        "id": "ICMtGufaTmFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip  '/content/gdrive/MyDrive/unlabelled_data.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGvMfHEAM90i",
        "outputId": "cdaf6e58-f42d-40ff-de0f-c6e45c7912c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/gdrive/MyDrive/unlabelled_data.zip\n",
            "   creating: unlabelled_data/\n",
            "  inflating: __MACOSX/._unlabelled_data  \n",
            "  inflating: unlabelled_data/file_28.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_28.hdf5  \n",
            "  inflating: unlabelled_data/file_45.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_45.hdf5  \n",
            "  inflating: unlabelled_data/file_12.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_12.hdf5  \n",
            "  inflating: unlabelled_data/file_53.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_53.hdf5  \n",
            "  inflating: unlabelled_data/file_24.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_24.hdf5  \n",
            "  inflating: unlabelled_data/file_32.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_32.hdf5  \n",
            "  inflating: unlabelled_data/file_49.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_49.hdf5  \n",
            "  inflating: unlabelled_data/file_48.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_48.hdf5  \n",
            "  inflating: unlabelled_data/file_33.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_33.hdf5  \n",
            "  inflating: unlabelled_data/file_64.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_64.hdf5  \n",
            "  inflating: unlabelled_data/file_25.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_25.hdf5  \n",
            "  inflating: unlabelled_data/file_52.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_52.hdf5  \n",
            "  inflating: unlabelled_data/file_1.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_1.hdf5  \n",
            "  inflating: unlabelled_data/file_13.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_13.hdf5  \n",
            "  inflating: unlabelled_data/file_44.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_44.hdf5  \n",
            "  inflating: unlabelled_data/file_29.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_29.hdf5  \n",
            "  inflating: unlabelled_data/file_22.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_22.hdf5  \n",
            "  inflating: unlabelled_data/file_63.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_63.hdf5  \n",
            "  inflating: unlabelled_data/file_34.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_34.hdf5  \n",
            "  inflating: unlabelled_data/file_18.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_18.hdf5  \n",
            "  inflating: unlabelled_data/file_59.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_59.hdf5  \n",
            "  inflating: unlabelled_data/file_38.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_38.hdf5  \n",
            "  inflating: unlabelled_data/file_43.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_43.hdf5  \n",
            "  inflating: unlabelled_data/file_14.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_14.hdf5  \n",
            "  inflating: unlabelled_data/file_6.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_6.hdf5  \n",
            "  inflating: unlabelled_data/file_55.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_55.hdf5  \n",
            "  inflating: unlabelled_data/file_54.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_54.hdf5  \n",
            "  inflating: unlabelled_data/file_7.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_7.hdf5  \n",
            "  inflating: unlabelled_data/file_15.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_15.hdf5  \n",
            "  inflating: unlabelled_data/file_42.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_42.hdf5  \n",
            "  inflating: unlabelled_data/file_39.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_39.hdf5  \n",
            "  inflating: unlabelled_data/file_58.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_58.hdf5  \n",
            "  inflating: unlabelled_data/file_19.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_19.hdf5  \n",
            "  inflating: unlabelled_data/file_35.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_35.hdf5  \n",
            "  inflating: unlabelled_data/file_62.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_62.hdf5  \n",
            "  inflating: unlabelled_data/file_23.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_23.hdf5  \n",
            "  inflating: unlabelled_data/file_8.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_8.hdf5  \n",
            "  inflating: unlabelled_data/file_36.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_36.hdf5  \n",
            "  inflating: unlabelled_data/file_61.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_61.hdf5  \n",
            "  inflating: unlabelled_data/file_20.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_20.hdf5  \n",
            "  inflating: unlabelled_data/file_57.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_57.hdf5  \n",
            "  inflating: unlabelled_data/file_4.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_4.hdf5  \n",
            "  inflating: unlabelled_data/file_16.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_16.hdf5  \n",
            "  inflating: unlabelled_data/file_41.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_41.hdf5  \n",
            "  inflating: unlabelled_data/file_40.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_40.hdf5  \n",
            "  inflating: unlabelled_data/file_17.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_17.hdf5  \n",
            "  inflating: unlabelled_data/file_5.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_5.hdf5  \n",
            "  inflating: unlabelled_data/file_56.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_56.hdf5  \n",
            "  inflating: unlabelled_data/file_21.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_21.hdf5  \n",
            "  inflating: unlabelled_data/file_60.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_60.hdf5  \n",
            "  inflating: unlabelled_data/file_37.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_37.hdf5  \n",
            "  inflating: unlabelled_data/file_9.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_9.hdf5  \n",
            "  inflating: unlabelled_data/file_51.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_51.hdf5  \n",
            "  inflating: unlabelled_data/file_2.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_2.hdf5  \n",
            "  inflating: unlabelled_data/file_10.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_10.hdf5  \n",
            "  inflating: unlabelled_data/file_47.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_47.hdf5  \n",
            "  inflating: unlabelled_data/file_30.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_30.hdf5  \n",
            "  inflating: unlabelled_data/file_26.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_26.hdf5  \n",
            "  inflating: unlabelled_data/file_27.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_27.hdf5  \n",
            "  inflating: unlabelled_data/file_31.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_31.hdf5  \n",
            "  inflating: unlabelled_data/file_46.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_46.hdf5  \n",
            "  inflating: unlabelled_data/file_11.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_11.hdf5  \n",
            "  inflating: unlabelled_data/file_3.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_3.hdf5  \n",
            "  inflating: unlabelled_data/file_50.hdf5  \n",
            "  inflating: __MACOSX/unlabelled_data/._file_50.hdf5  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MAIN CODE STARTS HERE....."
      ],
      "metadata": {
        "id": "kDjVsujJ00j-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"  # specify which GPU(s) to be used\n",
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import os.path\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import data\n",
        "import random\n",
        "import torch\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "NLqUjZhK49om"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CUSTOM DATASET, PREPROCESSING"
      ],
      "metadata": {
        "id": "Z3lU8OLu5RHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset():\n",
        "  def __init__(self, file_paths):\n",
        "    self.file_paths = file_paths\n",
        "    self.sample_size = 0\n",
        "    self.index_mapping = []\n",
        "\n",
        "    for f_p in self.file_paths:\n",
        "      with h5py.File(f_p, 'r') as f:\n",
        "        current_file_size = f['H_Re'].shape[0]\n",
        "        self.sample_size += current_file_size\n",
        "        self.index_mapping.extend([f_p, i] for i in range(current_file_size))\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.sample_size\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    file_path, local_index = self.index_mapping[idx]\n",
        "    with h5py.File(file_path, 'r') as file:\n",
        "      H_Re = torch.from_numpy(file['H_Re'][local_index]).float()\n",
        "      H_Im = torch.from_numpy(file['H_Im'][local_index]).float()\n",
        "      SNR = torch.from_numpy(file['SNR'][local_index]).float()\n",
        "    return H_Re, H_Im, SNR\n"
      ],
      "metadata": {
        "id": "vEIpbt1x5SlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SELF-SUPERVISED MODEL"
      ],
      "metadata": {
        "id": "L4dQH9bVGm1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(56, 32, kernel_size = 3, stride = 1, padding = 1)\n",
        "    self.bn1 = nn.BatchNorm2d(32)\n",
        "    self.conv2 = nn.Conv2d(32, 16, kernel_size = 3, stride = 1, padding = 1)\n",
        "    self.bn2 = nn.BatchNorm2d(16)\n",
        "\n",
        "  def forward(self, x):\n",
        "     x = F.relu(self.conv1(x))\n",
        "     x = F.max_pool2d(x, 2)\n",
        "     x = F.relu(self.conv2(x))\n",
        "     x = F.max_pool2d(x, 2)\n",
        "     return x\n",
        "class SNRProcessor(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SNRProcessor, self).__init__()\n",
        "    self.fc1 = nn.Linear(56 * 5, 231)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 56*5)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = x.view(-1, 1, 231, 1)\n",
        "    return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.conv3 = nn.Conv2d(33, 16, kernel_size=3, stride=1, padding=1)\n",
        "    self.conv4 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "    self.conv5 = nn.Conv2d(32, 56, kernel_size=3, stride=1, padding=1)\n",
        "    self.conv_adjust = nn.Conv2d(56, 56, kernel_size=(1, 3), stride=1, padding=0)\n",
        "\n",
        "    # Decoder layers with batch normalization and dropout\n",
        "    self.fc1 = nn.Linear(56 * 924 * 2, 280)\n",
        "    self.bn1 = nn.BatchNorm1d(280)\n",
        "    self.dropout1 = nn.Dropout(0.5)  # Adjust dropout rate as needed\n",
        "    self.fc2 = nn.Linear(280, 56 * 5)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    x = F.relu(self.conv3(x))\n",
        "    x = F.interpolate(x, scale_factor=2)\n",
        "    x = F.relu(self.conv4(x))\n",
        "    x = F.interpolate(x, scale_factor=2)\n",
        "    x = torch.sigmoid(self.conv5(x))\n",
        "    x = self.conv_adjust(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    # Decoder layers with batch normalization and dropout\n",
        "    x = F.relu(self.bn1(self.fc1(x)))\n",
        "    x = self.dropout1(x)\n",
        "    x = self.fc2(x)\n",
        "    x = x.view(-1, 56, 5)\n",
        "    return x\n",
        "\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Autoencoder, self).__init__()\n",
        "    self.encoder = Encoder()\n",
        "    self.snr_processor = SNRProcessor()\n",
        "    self.decoder = Decoder()\n",
        "\n",
        "  def forward(self, re, im, snr):\n",
        "    # print(\"Input re type:\", re.dtype)  # Check data type\n",
        "    # print(\"Input im type:\", im.dtype)  # Check data type\n",
        "    # print(\"Input SNR type:\", snr.dtype)  # Check data type\n",
        "\n",
        "    encoded_re = self.encoder(re)\n",
        "    encoded_im = self.encoder(im)\n",
        "    processed_snr = self.snr_processor(snr)\n",
        "\n",
        "    # print(\"Encoded re type:\", encoded_re.dtype)  # Check data type\n",
        "    # print(\"Encoded im type:\", encoded_im.dtype)  # Check data type\n",
        "    # print(\"Processed SNR type:\", processed_snr.dtype)\n",
        "\n",
        "    concat_data = torch.cat((encoded_re, encoded_im, processed_snr), dim = 1)\n",
        "    decoded_data = self.decoder(concat_data)\n",
        "\n",
        "    # print(\"Output type:\", decoded_data.dtype)\n",
        "    return decoded_data\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tpuY9NUX_7lP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SELF SUPERVISED TRAINING"
      ],
      "metadata": {
        "id": "Rh_YNbopGp1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = '/content/checkpoints/'\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Is CUDA available: \", torch.cuda.is_available())\n",
        "\n",
        "model = Autoencoder().to(device)\n",
        "if torch.cuda.is_available():\n",
        "    model = model\n",
        "\n",
        "file_paths = [str(path) for path in Path('/content/unlabelled_data/').glob('*.hdf5')]\n",
        "\n",
        "dataset = CustomDataset(file_paths)\n",
        "\n",
        "data_loader = DataLoader(dataset,\n",
        "                         batch_size=32,\n",
        "                         shuffle=True,\n",
        "                         num_workers = 8)\n",
        "\n",
        "criterion = nn.SmoothL1Loss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "\n",
        "\n",
        "\n",
        "num_epochs = 50\n",
        "\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5, min_lr=1e-6, verbose=True)\n",
        "early_stopping_patience = 5\n",
        "early_stopping_counter = 0\n",
        "best_loss = float('inf')\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for H_Re, H_Im, SNR in tqdm(data_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
        "        # H_Re, H_Im, SNR = H_Re.to(device), H_Im.to(device), SNR.to(device)\n",
        "        H_Re = H_Re.to(device).to(torch.float32)\n",
        "        H_Im = H_Im.to(device).to(torch.float32)\n",
        "        SNR = SNR.to(device).to(torch.float32)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(H_Re, H_Im, SNR)\n",
        "        loss = criterion(outputs, SNR)  # Consider changing the loss function if needed\n",
        "\n",
        "        # Backward and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    avg_loss = epoch_loss / len(data_loader)\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Avg. Loss: {avg_loss:.4f}')\n",
        "\n",
        "    # Scheduler step and Early Stopping\n",
        "    scheduler.step(avg_loss)\n",
        "    if avg_loss < best_loss:\n",
        "        best_loss = avg_loss\n",
        "        early_stopping_counter = 0\n",
        "    else:\n",
        "        early_stopping_counter += 1\n",
        "        if early_stopping_counter >= early_stopping_patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "# Save the model\n",
        "    checkpoint_path = os.path.join(checkpoint_dir, f'autoencoder_epoch_{epoch+1}.pth')\n",
        "    torch.save(model.state_dict(), checkpoint_path)\n",
        "    print(f'Model saved to {checkpoint_path}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW7yWQFvGtk5",
        "outputId": "d4ceb7b0-dd71-49af-b42c-db0f3dbc0c31"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is CUDA available:  True\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch 1/50: 100%|██████████| 1131/1131 [05:24<00:00,  3.49it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/50], Avg. Loss: 24.1852\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_1.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/50: 100%|██████████| 1131/1131 [05:26<00:00,  3.47it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/50], Avg. Loss: 19.5208\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_2.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/50: 100%|██████████| 1131/1131 [05:24<00:00,  3.48it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/50], Avg. Loss: 18.9843\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_3.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/50: 100%|██████████| 1131/1131 [05:27<00:00,  3.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/50], Avg. Loss: 18.6069\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_4.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/50: 100%|██████████| 1131/1131 [05:23<00:00,  3.50it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/50], Avg. Loss: 18.0195\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_5.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/50: 100%|██████████| 1131/1131 [05:27<00:00,  3.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/50], Avg. Loss: 17.7532\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_6.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/50: 100%|██████████| 1131/1131 [05:35<00:00,  3.37it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/50], Avg. Loss: 17.4257\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_7.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/50: 100%|██████████| 1131/1131 [05:42<00:00,  3.30it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/50], Avg. Loss: 17.2445\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_8.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/50: 100%|██████████| 1131/1131 [05:41<00:00,  3.31it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [9/50], Avg. Loss: 16.9939\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_9.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/50: 100%|██████████| 1131/1131 [05:37<00:00,  3.35it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/50], Avg. Loss: 16.8435\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_10.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/50: 100%|██████████| 1131/1131 [05:40<00:00,  3.32it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [11/50], Avg. Loss: 16.6378\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_11.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/50: 100%|██████████| 1131/1131 [05:37<00:00,  3.35it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [12/50], Avg. Loss: 16.6015\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_12.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/50: 100%|██████████| 1131/1131 [05:37<00:00,  3.35it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [13/50], Avg. Loss: 16.4264\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_13.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/50: 100%|██████████| 1131/1131 [05:37<00:00,  3.35it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [14/50], Avg. Loss: 16.3598\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_14.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/50: 100%|██████████| 1131/1131 [05:37<00:00,  3.35it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [15/50], Avg. Loss: 16.2607\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_15.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/50: 100%|██████████| 1131/1131 [05:32<00:00,  3.40it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [16/50], Avg. Loss: 16.1948\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_16.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17/50: 100%|██████████| 1131/1131 [05:30<00:00,  3.42it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [17/50], Avg. Loss: 16.1144\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_17.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18/50: 100%|██████████| 1131/1131 [05:32<00:00,  3.40it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [18/50], Avg. Loss: 16.1352\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_18.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19/50: 100%|██████████| 1131/1131 [05:30<00:00,  3.42it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [19/50], Avg. Loss: 16.0339\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_19.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20/50: 100%|██████████| 1131/1131 [05:31<00:00,  3.42it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [20/50], Avg. Loss: 16.0555\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_20.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 21/50: 100%|██████████| 1131/1131 [05:27<00:00,  3.46it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [21/50], Avg. Loss: 15.9814\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_21.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 22/50: 100%|██████████| 1131/1131 [05:33<00:00,  3.39it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [22/50], Avg. Loss: 15.9937\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_22.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 23/50: 100%|██████████| 1131/1131 [05:31<00:00,  3.42it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [23/50], Avg. Loss: 15.9370\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_23.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 24/50: 100%|██████████| 1131/1131 [05:31<00:00,  3.42it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [24/50], Avg. Loss: 15.9167\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_24.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 25/50: 100%|██████████| 1131/1131 [05:37<00:00,  3.35it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [25/50], Avg. Loss: 15.9087\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_25.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 26/50: 100%|██████████| 1131/1131 [05:28<00:00,  3.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [26/50], Avg. Loss: 15.8396\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_26.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 27/50: 100%|██████████| 1131/1131 [05:31<00:00,  3.42it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [27/50], Avg. Loss: 15.9169\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_27.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 28/50: 100%|██████████| 1131/1131 [05:24<00:00,  3.48it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [28/50], Avg. Loss: 15.8136\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_28.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 29/50: 100%|██████████| 1131/1131 [05:24<00:00,  3.49it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [29/50], Avg. Loss: 15.8264\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_29.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 30/50: 100%|██████████| 1131/1131 [05:32<00:00,  3.40it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [30/50], Avg. Loss: 15.7552\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_30.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 31/50: 100%|██████████| 1131/1131 [05:24<00:00,  3.49it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [31/50], Avg. Loss: 15.6998\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_31.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 32/50: 100%|██████████| 1131/1131 [05:27<00:00,  3.46it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [32/50], Avg. Loss: 15.7030\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_32.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 33/50: 100%|██████████| 1131/1131 [05:26<00:00,  3.47it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [33/50], Avg. Loss: 15.6500\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_33.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 34/50: 100%|██████████| 1131/1131 [05:25<00:00,  3.48it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [34/50], Avg. Loss: 15.6167\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_34.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 35/50: 100%|██████████| 1131/1131 [05:27<00:00,  3.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [35/50], Avg. Loss: 15.6570\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_35.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 36/50: 100%|██████████| 1131/1131 [05:36<00:00,  3.36it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [36/50], Avg. Loss: 15.6127\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_36.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 37/50: 100%|██████████| 1131/1131 [05:34<00:00,  3.38it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [37/50], Avg. Loss: 15.6224\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_37.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 38/50: 100%|██████████| 1131/1131 [05:32<00:00,  3.40it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [38/50], Avg. Loss: 15.5792\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_38.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39/50: 100%|██████████| 1131/1131 [05:33<00:00,  3.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [39/50], Avg. Loss: 15.5740\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_39.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40/50: 100%|██████████| 1131/1131 [05:33<00:00,  3.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [40/50], Avg. Loss: 15.5709\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_40.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 41/50: 100%|██████████| 1131/1131 [05:37<00:00,  3.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [41/50], Avg. Loss: 15.5381\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_41.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 42/50: 100%|██████████| 1131/1131 [05:36<00:00,  3.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [42/50], Avg. Loss: 15.5519\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_42.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43/50: 100%|██████████| 1131/1131 [05:41<00:00,  3.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [43/50], Avg. Loss: 15.5791\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_43.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44/50: 100%|██████████| 1131/1131 [05:33<00:00,  3.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [44/50], Avg. Loss: 15.4783\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_44.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45/50: 100%|██████████| 1131/1131 [05:36<00:00,  3.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [45/50], Avg. Loss: 15.5013\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_45.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46/50: 100%|██████████| 1131/1131 [05:36<00:00,  3.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [46/50], Avg. Loss: 15.5396\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_46.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47/50: 100%|██████████| 1131/1131 [05:34<00:00,  3.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [47/50], Avg. Loss: 15.4777\n",
            "Epoch 00047: reducing learning rate of group 0 to 5.0000e-04.\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_47.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 48/50: 100%|██████████| 1131/1131 [05:38<00:00,  3.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [48/50], Avg. Loss: 15.4177\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_48.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 49/50: 100%|██████████| 1131/1131 [05:30<00:00,  3.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [49/50], Avg. Loss: 15.4439\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_49.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 50/50: 100%|██████████| 1131/1131 [05:37<00:00,  3.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [50/50], Avg. Loss: 15.4144\n",
            "Model saved to /content/checkpoints/autoencoder_epoch_50.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.version.cuda)\n",
        "print(torch.cuda.is_available())\n",
        "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu120\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdKkx_EP4HT8",
        "outputId": "21627220-6b00-416a-8136-09dcf5a21059"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Nov 15 04:34:38 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "2.1.0+cu118\n",
            "11.8\n",
            "False\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu120\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SUPERVISED MODEL"
      ],
      "metadata": {
        "id": "25m2WLUeG31i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Labeled_Dataset():\n",
        "    def __init__(self, file_paths):\n",
        "\n",
        "      self.file_paths = file_paths\n",
        "      self.sample_size = 0\n",
        "      self.index_mapping = []\n",
        "\n",
        "      for f_p in self.file_paths:\n",
        "        with h5py.File(f_p, 'r') as f:\n",
        "          current_file_size = f['H_Re'].shape[0]\n",
        "          self.sample_size += current_file_size\n",
        "          self.index_mapping.extend([f_p, i] for i in range(current_file_size))\n",
        "\n",
        "    def __len__(self):\n",
        "      return self.sample_size\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "\n",
        "      file_path, local_index = self.index_mapping[idx]\n",
        "      with h5py.File(file_path, 'r') as file:\n",
        "        H_Re = torch.from_numpy(file['H_Re'][local_index]).float()\n",
        "        H_Im = torch.from_numpy(file['H_Im'][local_index]).float()\n",
        "        SNR = torch.from_numpy(file['SNR'][local_index]).float()\n",
        "        POS = torch.from_numpy(file['Pos'][local_index]).float()\n",
        "      return H_Re, H_Im, SNR, POS"
      ],
      "metadata": {
        "id": "6Nabn9EVG4LC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class PositionPredictor(nn.Module):\n",
        "#     def __init__(self, trained_encoder, trained_snr_processor):\n",
        "#         super(PositionPredictor, self).__init__()\n",
        "#         self.encoder = trained_encoder\n",
        "#         self.snr_processor = trained_snr_processor\n",
        "\n",
        "#         # Adjust the input size according to your encoded feature size\n",
        "#         # Assuming the encoder outputs 16 * 231 * 1 features per sample\n",
        "#         # and the SNR processor outputs a 231-dimensional vector\n",
        "#         total_feature_size = (16 * 231 * 1) * 2 + 231\n",
        "#         self.fc = nn.Linear(total_feature_size, 3)  # 3 for x, y, z coordinates\n",
        "\n",
        "#     def forward(self, H_Re, H_Im, SNR):\n",
        "#         encoded_re = self.encoder(H_Re)\n",
        "#         encoded_im = self.encoder(H_Im)\n",
        "#         processed_snr = self.snr_processor(SNR)\n",
        "\n",
        "#         # Flatten and concatenate the outputs\n",
        "#         encoded_re_flat = encoded_re.view(encoded_re.size(0), -1)\n",
        "#         encoded_im_flat = encoded_im.view(encoded_im.size(0), -1)\n",
        "#         processed_snr_flat = processed_snr.view(processed_snr.size(0), -1)\n",
        "#         encoded_features = torch.cat([encoded_re_flat, encoded_im_flat, processed_snr_flat], dim=1)\n",
        "\n",
        "#         position = self.fc(encoded_features)\n",
        "#         return position\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class PositionPredictor(nn.Module):\n",
        "    def __init__(self, trained_encoder, trained_snr_processor):\n",
        "        super(PositionPredictor, self).__init__()\n",
        "        self.encoder = trained_encoder\n",
        "        self.snr_processor = trained_snr_processor\n",
        "\n",
        "        # Adjust the input size according to your encoded feature size\n",
        "        # Assuming the encoder outputs 16 * 231 * 1 features per sample\n",
        "        # and the SNR processor outputs a 231-dimensional vector\n",
        "        total_feature_size = (16 * 231 * 1) * 2 + 231\n",
        "\n",
        "        # Add Batch Normalization\n",
        "        self.batch_norm = nn.BatchNorm1d(total_feature_size)\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(total_feature_size, 3)  # 3 for x, y, z coordinates\n",
        "\n",
        "        # Dropout layer\n",
        "\n",
        "\n",
        "    def forward(self, H_Re, H_Im, SNR):\n",
        "        encoded_re = self.encoder(H_Re)\n",
        "        encoded_im = self.encoder(H_Im)\n",
        "        processed_snr = self.snr_processor(SNR)\n",
        "\n",
        "        # Flatten and concatenate the outputs\n",
        "        encoded_re_flat = encoded_re.view(encoded_re.size(0), -1)\n",
        "        encoded_im_flat = encoded_im.view(encoded_im.size(0), -1)\n",
        "        processed_snr_flat = processed_snr.view(processed_snr.size(0), -1)\n",
        "\n",
        "        encoded_features = torch.cat([encoded_re_flat, encoded_im_flat, processed_snr_flat], dim=1)\n",
        "\n",
        "        # Apply Batch Normalization\n",
        "        encoded_features_bn = self.batch_norm(encoded_features)\n",
        "\n",
        "        # Apply Dropout\n",
        "        # encoded_features_dropout = self.dropout(encoded_features_bn)\n",
        "\n",
        "        position = self.fc(encoded_features_bn)\n",
        "        return position\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "j7Sfc3rQMf8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VALIDATION"
      ],
      "metadata": {
        "id": "kcUVZU6FGur6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Is CUDA available: \", torch.cuda.is_available())\n",
        "# Define hyperparameters\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "num_epochs = 20\n",
        "\n",
        "# Split the labeled dataset into training and validation sets\n",
        "file_paths = [str(path) for path in Path('/content/labelled_data/').glob('*.hdf5')]\n",
        "train_file_paths, val_file_paths = train_test_split(file_paths, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create DataLoader for training and validation\n",
        "train_dataset = Labeled_Dataset(train_file_paths)\n",
        "val_dataset = Labeled_Dataset(val_file_paths)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "# Initialize the model\n",
        "trained_autoencoder = Autoencoder()\n",
        "#trained_autoencoder.load_state_dict(torch.load('/content/checkpoints/autoencoder_epoch_50.pth')).\n",
        "trained_autoencoder.load_state_dict(torch.load('/content/autoencoder_epoch_21.pth', map_location=torch.device('cpu')))\n",
        "\n",
        "trained_autoencoder.to(device)\n",
        "trained_encoder = trained_autoencoder.encoder\n",
        "trained_snr_processor = trained_autoencoder.snr_processor\n",
        "supervised_model = PositionPredictor(trained_encoder, trained_snr_processor).to(device)\n",
        "\n",
        "# Define loss function (Mean Absolute Error) and optimizer\n",
        "criterion = nn.SmoothL1Loss()\n",
        "optimizer = optim.AdamW(supervised_model.parameters(), lr=learning_rate, weight_decay=1e-2)\n",
        "# scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5, min_lr=1e-6, verbose=True)\n",
        "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    supervised_model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for H_Re, H_Im, SNR, POS in train_loader:\n",
        "        H_Re = H_Re.to(device).to(torch.float32)\n",
        "        H_Im = H_Im.to(device).to(torch.float32)\n",
        "        SNR = SNR.to(device).to(torch.float32)\n",
        "        POS = POS.to(device).to(torch.float32)\n",
        "        # Forward pass\n",
        "        predicted_position = supervised_model(H_Re, H_Im, SNR)\n",
        "\n",
        "        # Compute the loss\n",
        "        loss = criterion(predicted_position, POS)\n",
        "\n",
        "        # Backpropagation and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    scheduler.step()\n",
        "    # Print training loss for this epoch\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {total_loss / len(train_loader)}\")\n",
        "\n",
        "    # Validation loop\n",
        "    supervised_model.eval()\n",
        "    val_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for H_Re, H_Im, SNR, POS in val_loader:\n",
        "            H_Re = H_Re.to(device).to(torch.float32)\n",
        "            H_Im = H_Im.to(device).to(torch.float32)\n",
        "            SNR = SNR.to(device).to(torch.float32)\n",
        "            POS = POS.to(device).to(torch.float32)\n",
        "        # Forward pass\n",
        "\n",
        "            # Forward pass\n",
        "            predicted_position = supervised_model(H_Re, H_Im, SNR)\n",
        "\n",
        "            # Compute the validation loss\n",
        "            val_loss += criterion(predicted_position, POS).item()\n",
        "\n",
        "    # Print validation loss for this epoch\n",
        "    #scheduler.step(val_loss)\n",
        "    print(f\"Validation Loss: {val_loss / len(val_loader)}\")\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(supervised_model.state_dict(), 'supervised_model.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtsfvpWRbUld",
        "outputId": "bcee2f56-e2ba-4b04-f115-bc892804d2cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is CUDA available:  True\n",
            "Epoch [1/20] - Loss: 276.6199935277303\n",
            "Validation Loss: 212.47847175598145\n",
            "Epoch [2/20] - Loss: 123.6341940164566\n",
            "Validation Loss: 53.58294069766998\n",
            "Epoch [3/20] - Loss: 48.86056456963221\n",
            "Validation Loss: 43.99505317211151\n",
            "Epoch [4/20] - Loss: 43.92183597882589\n",
            "Validation Loss: 39.97443652153015\n",
            "Epoch [5/20] - Loss: 40.18163484334946\n",
            "Validation Loss: 37.76792508363724\n",
            "Epoch [6/20] - Loss: 39.26855502525965\n",
            "Validation Loss: 36.893955171108246\n",
            "Epoch [7/20] - Loss: 38.14927087227503\n",
            "Validation Loss: 35.62565207481384\n",
            "Epoch [8/20] - Loss: 36.5435116092364\n",
            "Validation Loss: 35.46857851743698\n",
            "Epoch [9/20] - Loss: 35.47769449154536\n",
            "Validation Loss: 33.619841277599335\n",
            "Epoch [10/20] - Loss: 34.479462722937264\n",
            "Validation Loss: 33.50402253866196\n",
            "Epoch [11/20] - Loss: 34.19695373376211\n",
            "Validation Loss: 32.488071620464325\n",
            "Epoch [12/20] - Loss: 33.55821621417999\n",
            "Validation Loss: 31.95210152864456\n",
            "Epoch [13/20] - Loss: 32.15605507294337\n",
            "Validation Loss: 32.32102471590042\n",
            "Epoch [14/20] - Loss: 33.584682603677116\n",
            "Validation Loss: 32.239856481552124\n",
            "Epoch [15/20] - Loss: 32.85154263178507\n",
            "Validation Loss: 32.39815270900726\n",
            "Epoch [16/20] - Loss: 33.53287790218989\n",
            "Validation Loss: 31.966888070106506\n",
            "Epoch [17/20] - Loss: 32.37289627393087\n",
            "Validation Loss: 32.00200057029724\n",
            "Epoch [18/20] - Loss: 33.30438299973806\n",
            "Validation Loss: 31.628863632678986\n",
            "Epoch [19/20] - Loss: 32.8368933002154\n",
            "Validation Loss: 32.710008561611176\n",
            "Epoch [20/20] - Loss: 33.98276605208715\n",
            "Validation Loss: 31.875673592090607\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip  '/content/gdrive/MyDrive/test.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4D5KARpAgEMl",
        "outputId": "648484cd-f25e-4586-c13d-08e87e72ca0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/gdrive/MyDrive/test.zip\n",
            "   creating: test/\n",
            "  inflating: test/file_1.hdf5        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset class for test data\n",
        "class TestDataset(Dataset):\n",
        "\n",
        "  def __init__(self, file_paths):\n",
        "    self.file_paths = file_paths\n",
        "    self.sample_size = 0\n",
        "    self.index_mapping = []\n",
        "\n",
        "    for f_p in self.file_paths:\n",
        "      with h5py.File(f_p, 'r') as f:\n",
        "        current_file_size = f['H_Re'].shape[0]\n",
        "        self.sample_size += current_file_size\n",
        "        self.index_mapping.extend([f_p, i] for i in range(current_file_size))\n",
        "\n",
        "  def __len__(self):\n",
        "\n",
        "    return self.sample_size\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "\n",
        "    file_path, local_index = self.index_mapping[idx]\n",
        "    with h5py.File(file_path, 'r') as file:\n",
        "      H_Re = torch.from_numpy(file['H_Re'][local_index]).float()\n",
        "      H_Im = torch.from_numpy(file['H_Im'][local_index]).float()\n",
        "      SNR = torch.from_numpy(file['SNR'][local_index]).float()\n",
        "\n",
        "    return H_Re, H_Im, SNR\n",
        "# Similar to CustomDataset but without Pos\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "supervised_model = PositionPredictor(trained_encoder, trained_snr_processor)\n",
        "model_path = '/content/supervised_model.pth'\n",
        "state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
        "supervised_model.load_state_dict(state_dict)\n",
        "supervised_model.to(device)\n",
        "supervised_model.eval()\n",
        "\n",
        "# Create a DataLoader for the test data\n",
        "test_file_paths = [str(path) for path in Path('/content/test/').glob('*.hdf5')]\n",
        "test_data_loader = DataLoader(TestDataset(test_file_paths), batch_size=1)\n",
        "\n",
        "# Predict positions\n",
        "predictions = []\n",
        "with torch.no_grad():  # Disable gradient calculation\n",
        "    for H_Re, H_Im, SNR in test_data_loader:\n",
        "        H_Re = H_Re.to(device).to(torch.float32)\n",
        "        H_Im = H_Im.to(device).to(torch.float32)\n",
        "        SNR = SNR.to(device).to(torch.float32)\n",
        "\n",
        "        # Predict positions using the supervised model\n",
        "        outputs = supervised_model(H_Re, H_Im, SNR)\n",
        "\n",
        "        # Store predictions, modify this depending on the output format of your model\n",
        "        predictions.append(outputs.detach().cpu().numpy())\n",
        "\n",
        "# Flatten the predictions list if it's nested\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "\n",
        "# Create and save the submission CSV file\n",
        "submission_df = pd.DataFrame(flat_predictions, columns=['x', 'y', 'z'])\n",
        "submission_df.insert(0, 'id', range(0, len(submission_df)))\n",
        "submission_df.to_csv('/content/submission_pranav.csv', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "DMvIjbQOG63T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SAVING RESULTS"
      ],
      "metadata": {
        "id": "0zEKC4ETG7Tr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1QlUPEHJG8k6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}