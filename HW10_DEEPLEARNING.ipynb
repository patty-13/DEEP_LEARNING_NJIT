{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1b7926708a3a47839be22ae2ac4e14ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00026535ab9e49f88c97fa0f3711183c",
              "IPY_MODEL_981cf0ff0ba14c098f9c6ed4c1cf0b5e",
              "IPY_MODEL_a257cb4fe8dc431ea51ad879ae91c494"
            ],
            "layout": "IPY_MODEL_b9c076fd23274f1dbc74bb504d6688f2"
          }
        },
        "00026535ab9e49f88c97fa0f3711183c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0d778949e074108b1a37c29e5f49b9f",
            "placeholder": "​",
            "style": "IPY_MODEL_64b4a1461bbb48dc917914015605f484",
            "value": "Total: -179.2, Final: -100.0: 100%"
          }
        },
        "981cf0ff0ba14c098f9c6ed4c1cf0b5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a609bf3ce4a34088828127a024b1b684",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d433874cd5d7498f858057cb84e61523",
            "value": 100
          }
        },
        "a257cb4fe8dc431ea51ad879ae91c494": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d7aad2b2d1344a89a2e8f50602b093c",
            "placeholder": "​",
            "style": "IPY_MODEL_1ed1cbfb63e04f83b907acddb3474ac5",
            "value": " 100/100 [01:46&lt;00:00,  2.54s/it]"
          }
        },
        "b9c076fd23274f1dbc74bb504d6688f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0d778949e074108b1a37c29e5f49b9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64b4a1461bbb48dc917914015605f484": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a609bf3ce4a34088828127a024b1b684": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d433874cd5d7498f858057cb84e61523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d7aad2b2d1344a89a2e8f50602b093c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ed1cbfb63e04f83b907acddb3474ac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6c0a6481c394495b0f13f226431cb71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6347e78c24f4485a8bb83461a7602a7a",
              "IPY_MODEL_2d6e3926566b42ca9f356fdb6d3454df",
              "IPY_MODEL_4671fe797dd8464f9493dc72ae57929e"
            ],
            "layout": "IPY_MODEL_09090ad3f5114932baef3c1853c36312"
          }
        },
        "6347e78c24f4485a8bb83461a7602a7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3f3f65f2cac4961a646bd95c52b22ae",
            "placeholder": "​",
            "style": "IPY_MODEL_9e1c489b3f1d4c6eac4aa0e3761ade3a",
            "value": "Total: -90.3, Final: -30.3:  91%"
          }
        },
        "2d6e3926566b42ca9f356fdb6d3454df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51422438659040b6aeb6e6586e7959d9",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a62436cdb905485d81067b282d90c6e2",
            "value": 910
          }
        },
        "4671fe797dd8464f9493dc72ae57929e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba61537145834a68b6bf1c588e9f6ea4",
            "placeholder": "​",
            "style": "IPY_MODEL_50e84adfb4f445fcb8b772247e52e5b1",
            "value": " 910/1000 [3:47:02&lt;1:24:12, 56.14s/it]"
          }
        },
        "09090ad3f5114932baef3c1853c36312": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3f3f65f2cac4961a646bd95c52b22ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e1c489b3f1d4c6eac4aa0e3761ade3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51422438659040b6aeb6e6586e7959d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a62436cdb905485d81067b282d90c6e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba61537145834a68b6bf1c588e9f6ea4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50e84adfb4f445fcb8b772247e52e5b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patty-13/DEEP_LEARNING_NJIT/blob/main/HW10_DEEPLEARNING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp30SB4bxeQb"
      },
      "source": [
        "# **Homework 10 - Reinforcement Learning**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXsnCWPtWSNk"
      },
      "source": [
        "## Preliminary work\n",
        "\n",
        "First, we need to install all necessary packages.\n",
        "One of them, gym, builded by OpenAI, is a toolkit for developing Reinforcement Learning algorithm. Other packages are for visualization in colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5e2bScpnkVbv",
        "outputId": "698b00e3-1154-4d9b-f6a8-e79aef8598f6"
      },
      "source": [
        "!apt update\n",
        "!pip install -q swig\n",
        "!pip install box2d==2.3.2 gym[box2d]==0.25.2 box2d-py pyvirtualdisplay tqdm numpy==1.22.4\n",
        "!pip install box2d==2.3.2 box2d-kengz\n",
        "!pip freeze > requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:2 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "15 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Collecting box2d==2.3.2\n",
            "  Using cached Box2D-2.3.2.tar.gz (427 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gym[box2d]==0.25.2 in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Collecting box2d-py\n",
            "  Using cached box2d-py-2.3.8.tar.gz (374 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyvirtualdisplay\n",
            "  Using cached PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Collecting numpy==1.22.4\n",
            "  Using cached numpy-1.22.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]==0.25.2) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]==0.25.2) (0.0.8)\n",
            "Collecting box2d-py\n",
            "  Using cached box2d-py-2.3.5.tar.gz (374 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pygame==2.1.0 (from gym[box2d]==0.25.2)\n",
            "  Downloading pygame-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: swig==4.* in /usr/local/lib/python3.10/dist-packages (from gym[box2d]==0.25.2) (4.1.1.post1)\n",
            "Building wheels for collected packages: box2d, box2d-py\n",
            "  Building wheel for box2d (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d: filename=Box2D-2.3.2-cp310-cp310-linux_x86_64.whl size=2391305 sha256=a209c1dea09397f98b2a57888be3b1501599aec443a2f9c634b72bd8f3cab266\n",
            "  Stored in directory: /root/.cache/pip/wheels/eb/cb/be/e663f3ce9aba6580611c0febaf7cd3cf7603f87047de2a52f9\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp310-cp310-linux_x86_64.whl size=2373075 sha256=a7cf127849147ce8fdcbbb02e9e00a91868573d49658fbdd34935c76e025bf01\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/8f/6a/eaaadf056fba10a98d986f6dce954e6201ba3126926fc5ad9e\n",
            "Successfully built box2d box2d-py\n",
            "Installing collected packages: pyvirtualdisplay, box2d-py, box2d, pygame, numpy\n",
            "  Attempting uninstall: pygame\n",
            "    Found existing installation: pygame 2.5.2\n",
            "    Uninstalling pygame-2.5.2:\n",
            "      Successfully uninstalled pygame-2.5.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "plotnine 0.12.4 requires numpy>=1.23.0, but you have numpy 1.22.4 which is incompatible.\n",
            "tensorflow 2.14.0 requires numpy>=1.23.5, but you have numpy 1.22.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed box2d-2.3.2 box2d-py-2.3.5 numpy-1.22.4 pygame-2.1.0 pyvirtualdisplay-3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: box2d==2.3.2 in /usr/local/lib/python3.10/dist-packages (2.3.2)\n",
            "Collecting box2d-kengz\n",
            "  Using cached Box2D-kengz-2.3.3.tar.gz (425 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: box2d-kengz\n",
            "  Building wheel for box2d-kengz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-kengz: filename=Box2D_kengz-2.3.3-cp310-cp310-linux_x86_64.whl size=2391349 sha256=f8e9b0e28bb2b93b4c6331b4b48558b2b5c0e445a96eab1adfb9b1d2f6e7993b\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/a3/5f/6396406aa0163da86c2a8d28304a120b55cfa98363654d853b\n",
            "Successfully built box2d-kengz\n",
            "Installing collected packages: box2d-kengz\n",
            "Successfully installed box2d-kengz-2.3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install xvfb -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vnCKXQfuGml",
        "outputId": "7f2df8b0-7331-4047-b4b1-b3c0c418d2dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 15 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_-i3cdoYsks"
      },
      "source": [
        "\n",
        "Next, set up virtual display，and import all necessaary packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl2nREINDLiw"
      },
      "source": [
        "%%capture\n",
        "from pyvirtualdisplay import Display\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Categorical\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaEJ8BUCpN9P"
      },
      "source": [
        "# Warning ! Do not revise random seed !!!\n",
        "Make your HW result to be reproducible.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV9i8i2YkRbO"
      },
      "source": [
        "seed = 2023 # Do not change this\n",
        "def fix(env, seed):\n",
        "  env.seed(seed)\n",
        "  env.action_space.seed(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  np.random.seed(seed)\n",
        "  random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  if torch.cuda.is_available():\n",
        "      torch.cuda.manual_seed_all(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He0XDx6bzjgC"
      },
      "source": [
        "Last, call gym and build an [Lunar Lander](https://gym.openai.com/envs/LunarLander-v2/) environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_4-xJcbBt09"
      },
      "source": [
        "%%capture\n",
        "import gym\n",
        "import random\n",
        "env = gym.make('LunarLander-v2')\n",
        "fix(env, seed) # fix the environment Do not revise this !!!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrkVvTrvWZ5H"
      },
      "source": [
        "## What Lunar Lander？\n",
        "\n",
        "“LunarLander-v2”is to simulate the situation when the craft lands on the surface of the moon.\n",
        "\n",
        "This task is to enable the craft to land \"safely\" at the pad between the two yellow flags.\n",
        "> Landing pad is always at coordinates (0,0).\n",
        "> Coordinates are the first two numbers in state vector.\n",
        "\n",
        "![](https://gym.openai.com/assets/docs/aeloop-138c89d44114492fd02822303e6b4b07213010bb14ca5856d2d49d6b62d88e53.svg)\n",
        "\n",
        "\"LunarLander-v2\" actually includes \"Agent\" and \"Environment\".\n",
        "\n",
        "In this homework, we will utilize the function `step()` to control the action of \"Agent\".\n",
        "\n",
        "Then `step()` will return the observation/state and reward given by the \"Environment\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIbp82sljvAt"
      },
      "source": [
        "### Observation / State\n",
        "\n",
        "First, we can take a look at what an Observation / State looks like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsXZra3N9R5T",
        "outputId": "94366b61-a39f-4041-82bb-f02388f1f5b2"
      },
      "source": [
        "print(env.observation_space)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Box([-1.5       -1.5       -5.        -5.        -3.1415927 -5.\n",
            " -0.        -0.       ], [1.5       1.5       5.        5.        3.1415927 5.        1.\n",
            " 1.       ], (8,), float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezdfoThbAQ49"
      },
      "source": [
        "\n",
        "`Box(8,)`means that observation is an 8-dim vector\n",
        "### Action\n",
        "\n",
        "Actions can be taken by looks like"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1k4dIrBAaKi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90cadc47-d03c-40c3-d120-06c97cceabce"
      },
      "source": [
        "print(env.action_space)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discrete(4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dejXT6PHBrPn"
      },
      "source": [
        "`Discrete(4)` implies that there are four kinds of actions can be taken by agent.\n",
        "- 0 implies the agent will not take any actions\n",
        "- 2 implies the agent will accelerate downward\n",
        "- 1, 3 implies the agent will accelerate left and right\n",
        "\n",
        "Next, we will try to make the agent interact with the environment.\n",
        "Before taking any actions, we recommend to call `reset()` function to reset the environment. Also, this function will return the initial state of the environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pi4OmrmZgnWA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acb1c3e6-800c-4e0f-ff2d-a4472dab2a70"
      },
      "source": [
        "initial_state = env.reset()\n",
        "print(initial_state)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.00506535  1.413064   -0.5130838   0.09527162  0.00587628  0.11622101\n",
            "  0.          0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBx0mEqqgxJ9"
      },
      "source": [
        "Then, we try to get a random action from the agent's action space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxkOEXRKgizt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ad70396-ba51-4b26-8b19-3b9e5e8b1a1a"
      },
      "source": [
        "random_action = env.action_space.sample()\n",
        "print(random_action)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mns-bO01g0-J"
      },
      "source": [
        "More, we can utilize `step()` to make agent act according to the randomly-selected `random_action`.\n",
        "The `step()` function will return four values:\n",
        "- observation / state\n",
        "- reward\n",
        "- done (True/ False)\n",
        "- Other information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_WViSxGgIk9"
      },
      "source": [
        "observation, reward, done, info = env.step(random_action)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK7r126kuCNp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3c63343-6e78-495b-9368-703d8085a388"
      },
      "source": [
        "print(done)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKdS8vOihxhc"
      },
      "source": [
        "### Reward\n",
        "\n",
        "\n",
        "> Landing pad is always at coordinates (0,0). Coordinates are the first two numbers in state vector. Reward for moving from the top of the screen to landing pad and zero speed is about 100-140 points. If lander moves away from landing pad it loses reward back. Episode finishes if the lander crashes or comes to rest, receiving additional -100 or +100 points. Each leg ground contact is +10. Firing main engine is -0.3 points each frame. Solved is 200 points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxQNs77hi0_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15ff86bb-d039-4628-fca0-9d7656d61bac"
      },
      "source": [
        "print(reward)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1.4981841929643156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mhqp6D-XgHpe"
      },
      "source": [
        "### Random Agent\n",
        "In the end, before we start training, we can see whether a random agent can successfully land the moon or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3G0bxoccelv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "outputId": "6d3b9fd7-ae21-4d37-f392-dcdf13de1df1"
      },
      "source": [
        "env.reset()\n",
        "\n",
        "img = plt.imshow(env.render(mode='rgb_array'))\n",
        "\n",
        "done = False\n",
        "while not done:\n",
        "    action = env.action_space.sample()\n",
        "    observation, reward, done, _ = env.step(action)\n",
        "\n",
        "    img.set_data(env.render(mode='rgb_array'))\n",
        "    display.display(plt.gcf())\n",
        "    display.clear_output(wait=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DQN"
      ],
      "metadata": {
        "id": "6y1wasMwW-VI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DQN(nn.Module):\n",
        "  \"\"\"Actor (Policy) Model.\"\"\"\n",
        "\n",
        "  def __init__(self, state_size=8, action_size=4, fc1_units=64, fc2_units=64):\n",
        "\n",
        "    \"\"\"Initialize parameters and build model.\n",
        "    Params\n",
        "    ======\n",
        "        state_size (int): Dimension of each state\n",
        "        action_size (int): Dimension of each action\n",
        "        seed (int): Random seed\n",
        "        fc1_units (int): Number of nodes in first hidden layer\n",
        "        fc2_units (int): Number of nodes in second hidden layer\n",
        "    \"\"\"\n",
        "    super(DQN, self).__init__()\n",
        "    self.fc1 = nn.Linear(state_size, fc1_units)\n",
        "    self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
        "    self.fc3 = nn.Linear(fc2_units, action_size)\n",
        "\n",
        "  def forward(self, state):\n",
        "    \"\"\"Build a network that maps state -> action values.\"\"\"\n",
        "    x = F.relu(self.fc1(state))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    return self.fc3(x)"
      ],
      "metadata": {
        "id": "8VZtGsGcThip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import namedtuple\n",
        "\n",
        "class ReplayMemory:\n",
        "  \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
        "  def __init__(self, CAPACITY):\n",
        "    self.capacity = CAPACITY\n",
        "    self.memory = []\n",
        "    self.index = 0\n",
        "    self.transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
        "\n",
        "  def push(self, state, action, state_next, reward):\n",
        "    \"\"\"Push a new experience to memory.\"\"\"\n",
        "    if len(self.memory) < self.capacity:\n",
        "        self.memory.append(None)\n",
        "\n",
        "    self.memory[self.index] = self.transition(state, action, state_next, reward)\n",
        "\n",
        "    self.index = (self.index + 1) % self.capacity\n",
        "\n",
        "  def sample(self, batch_size):\n",
        "    \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
        "    return random.sample(self.memory, batch_size)\n",
        "\n",
        "  def __len__(self):\n",
        "    \"\"\"Return the current size of internal memory.\"\"\"\n",
        "    return len(self.memory)"
      ],
      "metadata": {
        "id": "4AjRAu9wW1QO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DQNAgent():\n",
        "  \"\"\"Interacts with and learns from the environment.\"\"\"\n",
        "  def __init__(self, num_states, num_actions):\n",
        "    \"\"\"Initialize an Agent object.\"\"\"\n",
        "\n",
        "    self.num_states = num_states\n",
        "    self.num_actions = num_actions\n",
        "\n",
        "    # Replay memory\n",
        "    self.memory_capacity = 10000\n",
        "    self.memory = ReplayMemory(self.memory_capacity)\n",
        "\n",
        "    # Q-Network\n",
        "    self.main_q_network = DQN()\n",
        "    self.target_q_network = DQN()\n",
        "\n",
        "    # optimizer\n",
        "    self.optimizer = optim.RMSprop(self.main_q_network.parameters(), lr=1e-4)\n",
        "    # self.optimizer = optim.Adam(self.main_q_network.parameters(), lr=1e-4)\n",
        "\n",
        "\n",
        "  def update_q_function(self):\n",
        "    '''update q function'''\n",
        "\n",
        "    # no enough samples, just return\n",
        "    if len(self.memory) < BATCH_SIZE:\n",
        "        return\n",
        "    # If enough samples are available in memory, get random subset and learn\n",
        "    self.batch, self.state_batch, self.action_batch, self.reward_batch, self.non_final_next_states = self.make_minibatch()\n",
        "\n",
        "    self.expected_state_action_values = self.get_expected_state_action_values()\n",
        "\n",
        "    self.update_main_q_network()\n",
        "\n",
        "  def make_minibatch(self):\n",
        "    '''Creating a mini-batch'''\n",
        "\n",
        "    transitions = self.memory.sample(BATCH_SIZE)\n",
        "\n",
        "    Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
        "    batch = Transition(*zip(*transitions))\n",
        "\n",
        "\n",
        "    state_batch = torch.cat(batch.state)\n",
        "    action_batch = torch.cat(batch.action)\n",
        "    reward_batch = torch.cat(batch.reward)\n",
        "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
        "                                        if s is not None])\n",
        "\n",
        "    return batch, state_batch, action_batch, reward_batch, non_final_next_states\n",
        "\n",
        "  def get_expected_state_action_values(self):\n",
        "    '''calculate Q（St,at）'''\n",
        "\n",
        "    self.main_q_network.eval()\n",
        "    self.target_q_network.eval()\n",
        "\n",
        "    self.state_action_values = self.main_q_network(\n",
        "        self.state_batch).gather(1, self.action_batch)\n",
        "\n",
        "    non_final_mask = torch.BoolTensor(tuple(map(lambda s: s is not None,\n",
        "                                                self.batch.next_state)))\n",
        "    # set all state to 0\n",
        "    next_state_values = torch.zeros(BATCH_SIZE)\n",
        "\n",
        "    next_state_values[non_final_mask] = self.target_q_network(\n",
        "        self.non_final_next_states).max(1)[0].detach()\n",
        "    # DQN formula\n",
        "    expected_state_action_values = self.reward_batch + GAMMA * next_state_values\n",
        "\n",
        "    return expected_state_action_values\n",
        "\n",
        "  def get_action(self, state, episode, test=False):\n",
        "    \"\"\"Returns actions for given state as per current policy.\"\"\"\n",
        "    if test:\n",
        "      self.main_q_network.eval()\n",
        "      with torch.no_grad():\n",
        "        action = self.main_q_network(torch.from_numpy(state).unsqueeze(0)).max(1)[1].view(1, 1)\n",
        "      return action.item()\n",
        "    global steps_done\n",
        "    epsilon = EPS_END + (EPS_START - EPS_END) * \\\n",
        "            np.exp(-1. * steps_done / EPS_DECAY)\n",
        "    steps_done += 1\n",
        "\n",
        "    if epsilon <= np.random.uniform(0, 1):\n",
        "      self.main_q_network.eval()\n",
        "      with torch.no_grad():\n",
        "        action = self.main_q_network(state).max(1)[1].view(1, 1)\n",
        "    else:\n",
        "      action = torch.LongTensor(\n",
        "          [[random.randrange(self.num_actions)]])\n",
        "    return action\n",
        "\n",
        "  def update_main_q_network(self):\n",
        "\n",
        "    '''update main q net'''\n",
        "    self.main_q_network.train()\n",
        "    loss = F.smooth_l1_loss(self.state_action_values,\n",
        "                            self.expected_state_action_values.unsqueeze(1))\n",
        "\n",
        "    # update\n",
        "    self.optimizer.zero_grad()  # reset gradient\n",
        "    loss.backward()  # backpropagation\n",
        "    for param in self.main_q_network.parameters():\n",
        "      param.grad.data.clamp_(-1, 1)\n",
        "    self.optimizer.step()  # update network\n",
        "\n",
        "\n",
        "  def memorize(self, state, action, state_next, reward):\n",
        "    '''save state, action, state_next, reward into replay memory'''\n",
        "    self.memory.push(state, action, state_next, reward)\n",
        "\n",
        "  def update_target_q_function(self):\n",
        "\n",
        "    '''synchronize Target Q-Network to Main Q-Network'''\n",
        "    self.target_q_network.load_state_dict(self.main_q_network.state_dict())"
      ],
      "metadata": {
        "id": "ULt9unn0W7nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network = DQN()\n",
        "agent = DQNAgent(env.observation_space.shape[0], env.action_space.n)"
      ],
      "metadata": {
        "id": "UrhJSgX3XCE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5paWqo7tWL2"
      },
      "source": [
        "## Policy Gradient\n",
        "Now, we can build a simple policy network. The network will return one of action in the action space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8tdmeD-tZew"
      },
      "source": [
        "# class PolicyGradientNetwork(nn.Module):\n",
        "\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#         self.fc1 = nn.Linear(8, 16)\n",
        "#         self.fc2 = nn.Linear(16, 16)\n",
        "#         self.fc3 = nn.Linear(16, 4)\n",
        "\n",
        "#     def forward(self, state):\n",
        "#         hid = torch.tanh(self.fc1(state))\n",
        "#         hid = torch.tanh(hid)\n",
        "#         return F.softmax(self.fc3(hid), dim=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynbqJrhIFTC3"
      },
      "source": [
        "Then, we need to build a simple agent. The agent will acts according to the output of the policy network above. There are a few things can be done by agent:\n",
        "- `learn()`：update the policy network from log probabilities and rewards.\n",
        "- `sample()`：After receiving observation from the environment, utilize policy network to tell which action to take. The return values of this function includes action and log probabilities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZo-IxJx286z"
      },
      "source": [
        "# from torch.optim.lr_scheduler import StepLR\n",
        "# class PolicyGradientAgent():\n",
        "\n",
        "#     def __init__(self, network):\n",
        "#         self.network = network\n",
        "#         self.optimizer = optim.SGD(self.network.parameters(), lr=0.002)\n",
        "\n",
        "#     def forward(self, state):\n",
        "#         return self.network(state)\n",
        "#     def learn(self, log_probs, rewards):\n",
        "#         loss = (-log_probs * rewards).sum() # You don't need to revise this to pass simple baseline (but you can)\n",
        "\n",
        "#         self.optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         self.optimizer.step()\n",
        "\n",
        "#     def sample(self, state):\n",
        "#         action_prob = self.network(torch.FloatTensor(state))\n",
        "#         action_dist = Categorical(action_prob)\n",
        "#         action = action_dist.sample()\n",
        "#         log_prob = action_dist.log_prob(action)\n",
        "#         return action.item(), log_prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehPlnTKyRZf9"
      },
      "source": [
        "Lastly, build a network and agent to start training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfJIvML-RYjL"
      },
      "source": [
        "# network = PolicyGradientNetwork()\n",
        "# agent = PolicyGradientAgent(network)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouv23glgf5Qt"
      },
      "source": [
        "## Training Agent\n",
        "\n",
        "Now let's start to train our agent.\n",
        "Through taking all the interactions between agent and environment as training data, the policy network can learn from all these attempts,"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8cQ0pvnFzxMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPISODE_PER_BATCH = 10\n",
        "NUM_BATCH = 1000\n",
        "BATCH_SIZE = 64\n",
        "GAMMA = 0.99\n",
        "EPS_START = 1.0\n",
        "EPS_END = 0.01\n",
        "EPS_DECAY = 500\n",
        "\n",
        "best_score = 0\n",
        "best_batch = 0\n",
        "\n",
        "\n",
        "agent.main_q_network.train()\n",
        "agent.target_q_network.train()\n",
        "steps_done = 0\n",
        "\n",
        "avg_total_rewards, avg_final_rewards = [], []\n",
        "\n",
        "prg_bar = tqdm(range(NUM_BATCH))\n",
        "for batch in prg_bar:\n",
        "\n",
        "  rewards = []\n",
        "  total_rewards, final_rewards = [], []\n",
        "\n",
        "\n",
        "  for episode in range(EPISODE_PER_BATCH):\n",
        "\n",
        "    observation = env.reset()\n",
        "    state = observation\n",
        "    state = torch.from_numpy(state).type(\n",
        "            torch.FloatTensor)\n",
        "    state = torch.unsqueeze(state, 0)\n",
        "    total_reward, total_step = 0, 0\n",
        "\n",
        "    while True:\n",
        "\n",
        "\n",
        "      action = agent.get_action(state, batch)\n",
        "\n",
        "      observation_next, reward, done, _ = env.step(action.item())\n",
        "\n",
        "      total_reward += reward\n",
        "      total_step += 1\n",
        "      rewards.append(reward)\n",
        "      if done:\n",
        "        state_next = None\n",
        "\n",
        "      else:\n",
        "\n",
        "        state_next = observation_next\n",
        "        state_next = torch.from_numpy(state_next).type(\n",
        "                torch.FloatTensor)\n",
        "        state_next = torch.unsqueeze(state_next, 0)\n",
        "\n",
        "\n",
        "      agent.memorize(state, action, state_next, torch.FloatTensor([reward]))\n",
        "\n",
        "\n",
        "      agent.update_q_function()\n",
        "\n",
        "\n",
        "      state = state_next\n",
        "\n",
        "      if done:\n",
        "        final_rewards.append(reward)\n",
        "        total_rewards.append(total_reward)\n",
        "        break\n",
        "\n",
        "  avg_total_reward = sum(total_rewards) / len(total_rewards)\n",
        "  avg_final_reward = sum(final_rewards) / len(final_rewards)\n",
        "  avg_total_rewards.append(avg_total_reward)\n",
        "  avg_final_rewards.append(avg_final_reward)\n",
        "  prg_bar.set_description(f\"Total: {avg_total_reward: 4.1f}, Final: {avg_final_reward: 4.1f}\")\n",
        "  agent.update_target_q_function()\n",
        "  print(\"torch.from_numpy(rewards) looks like \", torch.from_numpy(np.array(rewards)).size())\n",
        "\n",
        "\n",
        "    ### testing\n",
        "\n",
        "  fix(env, seed)\n",
        "  agent.main_q_network.eval()\n",
        "  NUM_OF_TEST = 5 # Do not revise it !!!!!\n",
        "  test_total_reward = []\n",
        "  action_list = []\n",
        "  for i in range(NUM_OF_TEST):\n",
        "\n",
        "    actions = []\n",
        "    state = env.reset()\n",
        "    total_reward = 0\n",
        "\n",
        "    done = False\n",
        "    while not done:\n",
        "      action = agent.get_action(state, episode=i, test=True)\n",
        "      actions.append(action)\n",
        "      state, reward, done, _ = env.step(action)\n",
        "\n",
        "      total_reward += reward\n",
        "    print(total_reward)\n",
        "    test_total_reward.append(total_reward)\n",
        "\n",
        "    action_list.append(actions)\n",
        "    print(\"length of actions is \", len(actions))\n",
        "  print(f\"Your final reward is : %.2f\"%np.mean(test_total_reward))\n",
        "  if np.mean(test_total_reward) > 280:\n",
        "\n",
        "    distribution = {}\n",
        "    for actions in action_list:\n",
        "\n",
        "      for action in actions:\n",
        "\n",
        "        if action not in distribution.keys():\n",
        "            distribution[action] = 1\n",
        "        else:\n",
        "          distribution[action] += 1\n",
        "    PATH = \"Action_List_test\" + str(batch) + \".npy\"\n",
        "    np.save(PATH ,np.array(action_list))\n",
        "    if np.mean(test_total_reward) > best_score:\n",
        "      best_score = np.mean(test_total_reward)\n",
        "      best_batch = batch\n",
        "      print('Improve to score %.2f at batch %d'% (best_score, best_batch ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c6c0a6481c394495b0f13f226431cb71",
            "6347e78c24f4485a8bb83461a7602a7a",
            "2d6e3926566b42ca9f356fdb6d3454df",
            "4671fe797dd8464f9493dc72ae57929e",
            "09090ad3f5114932baef3c1853c36312",
            "c3f3f65f2cac4961a646bd95c52b22ae",
            "9e1c489b3f1d4c6eac4aa0e3761ade3a",
            "51422438659040b6aeb6e6586e7959d9",
            "a62436cdb905485d81067b282d90c6e2",
            "ba61537145834a68b6bf1c588e9f6ea4",
            "50e84adfb4f445fcb8b772247e52e5b1"
          ]
        },
        "id": "2jAXNziWz1ji",
        "outputId": "9f51e3f9-76f3-4c09-d67f-7915e475cfcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6c0a6481c394495b0f13f226431cb71"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.from_numpy(rewards) looks like  torch.Size([1531])\n",
            "277.915075967029\n",
            "length of actions is  229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:256: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "298.32184457366236\n",
            "length of actions is  210\n",
            "254.33603221587387\n",
            "length of actions is  231\n",
            "283.4996510862022\n",
            "length of actions is  230\n",
            "12.266557530845674\n",
            "length of actions is  161\n",
            "Your final reward is : 225.27\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2297])\n",
            "282.36114750245076\n",
            "length of actions is  248\n",
            "52.15413229239664\n",
            "length of actions is  137\n",
            "304.4432424182538\n",
            "length of actions is  169\n",
            "33.85022126741518\n",
            "length of actions is  146\n",
            "223.60852628397913\n",
            "length of actions is  811\n",
            "Your final reward is : 179.28\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2948])\n",
            "275.03572911345873\n",
            "length of actions is  242\n",
            "-9.553016012866294\n",
            "length of actions is  125\n",
            "4.283995746692696\n",
            "length of actions is  103\n",
            "232.79614663079198\n",
            "length of actions is  308\n",
            "268.87082178432297\n",
            "length of actions is  203\n",
            "Your final reward is : 154.29\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2217])\n",
            "278.04033038327395\n",
            "length of actions is  225\n",
            "12.879062379773785\n",
            "length of actions is  145\n",
            "250.40366999590748\n",
            "length of actions is  193\n",
            "-19.86632148873791\n",
            "length of actions is  94\n",
            "2.962445075891935\n",
            "length of actions is  109\n",
            "Your final reward is : 104.88\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3001])\n",
            "277.67778496238054\n",
            "length of actions is  219\n",
            "230.14424824889724\n",
            "length of actions is  200\n",
            "293.9560514687539\n",
            "length of actions is  231\n",
            "232.24188014183878\n",
            "length of actions is  206\n",
            "242.27962937449342\n",
            "length of actions is  336\n",
            "Your final reward is : 255.26\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2535])\n",
            "167.7687703965061\n",
            "length of actions is  1000\n",
            "239.02217146810446\n",
            "length of actions is  178\n",
            "57.88338997739507\n",
            "length of actions is  176\n",
            "155.03201460156214\n",
            "length of actions is  1000\n",
            "118.82781269535381\n",
            "length of actions is  1000\n",
            "Your final reward is : 147.71\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2587])\n",
            "279.42516842276564\n",
            "length of actions is  239\n",
            "65.33593663861248\n",
            "length of actions is  137\n",
            "183.48581746007767\n",
            "length of actions is  1000\n",
            "62.31561660142614\n",
            "length of actions is  138\n",
            "29.646245194699304\n",
            "length of actions is  160\n",
            "Your final reward is : 124.04\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2100])\n",
            "275.710631775019\n",
            "length of actions is  219\n",
            "227.896310773646\n",
            "length of actions is  231\n",
            "238.08126290827542\n",
            "length of actions is  232\n",
            "278.4576036457451\n",
            "length of actions is  176\n",
            "288.08428533706865\n",
            "length of actions is  239\n",
            "Your final reward is : 261.65\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2056])\n",
            "273.32502689328896\n",
            "length of actions is  234\n",
            "48.261956826722155\n",
            "length of actions is  142\n",
            "181.52167508073944\n",
            "length of actions is  1000\n",
            "38.881022502852886\n",
            "length of actions is  134\n",
            "244.54932319183368\n",
            "length of actions is  226\n",
            "Your final reward is : 157.31\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2080])\n",
            "273.2413690955078\n",
            "length of actions is  239\n",
            "49.630667734288295\n",
            "length of actions is  144\n",
            "258.5449417568261\n",
            "length of actions is  248\n",
            "248.3130386753237\n",
            "length of actions is  233\n",
            "261.7716304729658\n",
            "length of actions is  230\n",
            "Your final reward is : 218.30\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2114])\n",
            "269.2873243284679\n",
            "length of actions is  268\n",
            "256.0710039003267\n",
            "length of actions is  246\n",
            "300.86175355428827\n",
            "length of actions is  818\n",
            "289.6288394076197\n",
            "length of actions is  229\n",
            "255.74310293160931\n",
            "length of actions is  209\n",
            "Your final reward is : 274.32\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2818])\n",
            "267.4356713720818\n",
            "length of actions is  257\n",
            "23.645238106386287\n",
            "length of actions is  152\n",
            "28.04658151995656\n",
            "length of actions is  141\n",
            "47.00543480845414\n",
            "length of actions is  145\n",
            "283.1455584810029\n",
            "length of actions is  259\n",
            "Your final reward is : 129.86\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2909])\n",
            "262.66283299917984\n",
            "length of actions is  275\n",
            "268.54435497202644\n",
            "length of actions is  218\n",
            "262.1000602620335\n",
            "length of actions is  264\n",
            "267.47047666075025\n",
            "length of actions is  280\n",
            "18.383025522282438\n",
            "length of actions is  155\n",
            "Your final reward is : 215.83\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3054])\n",
            "139.82862513014567\n",
            "length of actions is  1000\n",
            "248.93919412949253\n",
            "length of actions is  202\n",
            "252.1745332971495\n",
            "length of actions is  212\n",
            "149.65068042234802\n",
            "length of actions is  1000\n",
            "262.70714638283437\n",
            "length of actions is  219\n",
            "Your final reward is : 210.66\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2906])\n",
            "24.310416917582216\n",
            "length of actions is  157\n",
            "259.90256758547105\n",
            "length of actions is  192\n",
            "17.528531030145174\n",
            "length of actions is  152\n",
            "44.51571988446358\n",
            "length of actions is  177\n",
            "-23.80929559623783\n",
            "length of actions is  139\n",
            "Your final reward is : 64.49\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2145])\n",
            "137.69984957739135\n",
            "length of actions is  1000\n",
            "245.17980775757943\n",
            "length of actions is  216\n",
            "274.62225614685656\n",
            "length of actions is  236\n",
            "-36.97405303657416\n",
            "length of actions is  115\n",
            "5.711070137557044\n",
            "length of actions is  148\n",
            "Your final reward is : 125.25\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1906])\n",
            "131.93426264532044\n",
            "length of actions is  1000\n",
            "240.49474163111387\n",
            "length of actions is  248\n",
            "92.88980926486744\n",
            "length of actions is  1000\n",
            "278.5780483561898\n",
            "length of actions is  216\n",
            "291.791197277301\n",
            "length of actions is  228\n",
            "Your final reward is : 207.14\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2613])\n",
            "132.15827460186745\n",
            "length of actions is  1000\n",
            "239.74004224397632\n",
            "length of actions is  240\n",
            "254.9648937004747\n",
            "length of actions is  256\n",
            "12.953052506781916\n",
            "length of actions is  142\n",
            "30.47497547163067\n",
            "length of actions is  144\n",
            "Your final reward is : 134.06\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2207])\n",
            "131.32873943649523\n",
            "length of actions is  1000\n",
            "250.72711497754136\n",
            "length of actions is  180\n",
            "3.3008442474561406\n",
            "length of actions is  179\n",
            "157.71677109638972\n",
            "length of actions is  1000\n",
            "258.277093943145\n",
            "length of actions is  226\n",
            "Your final reward is : 160.27\n",
            "torch.from_numpy(rewards) looks like  torch.Size([4043])\n",
            "145.0260059497933\n",
            "length of actions is  1000\n",
            "252.7413089495361\n",
            "length of actions is  190\n",
            "270.23832880380365\n",
            "length of actions is  269\n",
            "231.56127384279893\n",
            "length of actions is  289\n",
            "284.1755312941624\n",
            "length of actions is  217\n",
            "Your final reward is : 236.75\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2487])\n",
            "148.68669251738305\n",
            "length of actions is  1000\n",
            "251.19384011052244\n",
            "length of actions is  196\n",
            "262.8071788591093\n",
            "length of actions is  183\n",
            "258.62076492228937\n",
            "length of actions is  244\n",
            "232.53582810093806\n",
            "length of actions is  226\n",
            "Your final reward is : 230.77\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2096])\n",
            "143.34502846313183\n",
            "length of actions is  1000\n",
            "255.83061899783843\n",
            "length of actions is  173\n",
            "288.53345463330686\n",
            "length of actions is  245\n",
            "14.618545420707818\n",
            "length of actions is  159\n",
            "234.05784982310013\n",
            "length of actions is  208\n",
            "Your final reward is : 187.28\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2232])\n",
            "30.588762369454997\n",
            "length of actions is  187\n",
            "19.952270607476038\n",
            "length of actions is  137\n",
            "242.42998154061786\n",
            "length of actions is  228\n",
            "230.79532133038757\n",
            "length of actions is  241\n",
            "235.36163859998913\n",
            "length of actions is  235\n",
            "Your final reward is : 151.83\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2420])\n",
            "245.5527984230625\n",
            "length of actions is  217\n",
            "284.5778369018932\n",
            "length of actions is  282\n",
            "231.8416427093426\n",
            "length of actions is  263\n",
            "17.94769083103664\n",
            "length of actions is  146\n",
            "148.76233570279675\n",
            "length of actions is  1000\n",
            "Your final reward is : 185.74\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3680])\n",
            "20.009654106576846\n",
            "length of actions is  193\n",
            "286.62939893386255\n",
            "length of actions is  687\n",
            "255.40947227146123\n",
            "length of actions is  213\n",
            "160.5669514881597\n",
            "length of actions is  1000\n",
            "273.971919173978\n",
            "length of actions is  233\n",
            "Your final reward is : 199.32\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2183])\n",
            "30.088962679132067\n",
            "length of actions is  198\n",
            "290.35968486136767\n",
            "length of actions is  262\n",
            "250.2179631221773\n",
            "length of actions is  269\n",
            "15.82890809137858\n",
            "length of actions is  149\n",
            "-11.15030051112474\n",
            "length of actions is  146\n",
            "Your final reward is : 115.07\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2289])\n",
            "137.8410028391978\n",
            "length of actions is  1000\n",
            "251.02496834777537\n",
            "length of actions is  181\n",
            "269.838585344899\n",
            "length of actions is  267\n",
            "269.42136326663285\n",
            "length of actions is  427\n",
            "242.4817400588012\n",
            "length of actions is  219\n",
            "Your final reward is : 234.12\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2473])\n",
            "217.95400672410995\n",
            "length of actions is  997\n",
            "265.61612292783275\n",
            "length of actions is  296\n",
            "253.80552160139587\n",
            "length of actions is  247\n",
            "261.6481433328647\n",
            "length of actions is  242\n",
            "131.583988611865\n",
            "length of actions is  1000\n",
            "Your final reward is : 226.12\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2715])\n",
            "39.65217631556649\n",
            "length of actions is  193\n",
            "274.7212685079321\n",
            "length of actions is  249\n",
            "272.2204380222831\n",
            "length of actions is  243\n",
            "168.25523683795174\n",
            "length of actions is  1000\n",
            "212.5449687377802\n",
            "length of actions is  944\n",
            "Your final reward is : 193.48\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2403])\n",
            "95.21821311540603\n",
            "length of actions is  1000\n",
            "249.52976244798876\n",
            "length of actions is  197\n",
            "300.7444632611948\n",
            "length of actions is  212\n",
            "267.5975528770243\n",
            "length of actions is  257\n",
            "243.18791342314165\n",
            "length of actions is  620\n",
            "Your final reward is : 231.26\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2393])\n",
            "73.06973420188915\n",
            "length of actions is  1000\n",
            "236.84497887419792\n",
            "length of actions is  185\n",
            "256.7169068797882\n",
            "length of actions is  528\n",
            "282.34603402325996\n",
            "length of actions is  229\n",
            "54.127568904661096\n",
            "length of actions is  1000\n",
            "Your final reward is : 180.62\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3321])\n",
            "140.58041440891012\n",
            "length of actions is  1000\n",
            "251.59588477411873\n",
            "length of actions is  197\n",
            "307.8539162048197\n",
            "length of actions is  209\n",
            "255.078532909605\n",
            "length of actions is  267\n",
            "42.799223246640196\n",
            "length of actions is  188\n",
            "Your final reward is : 199.58\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3664])\n",
            "35.253768221760396\n",
            "length of actions is  188\n",
            "48.277307518717635\n",
            "length of actions is  203\n",
            "267.84821229083013\n",
            "length of actions is  288\n",
            "281.06657911228314\n",
            "length of actions is  249\n",
            "58.14468776611463\n",
            "length of actions is  105\n",
            "Your final reward is : 138.12\n",
            "torch.from_numpy(rewards) looks like  torch.Size([5483])\n",
            "256.7592112266667\n",
            "length of actions is  231\n",
            "155.32537883432792\n",
            "length of actions is  1000\n",
            "271.8694341527299\n",
            "length of actions is  247\n",
            "297.8428937796258\n",
            "length of actions is  252\n",
            "273.4055954088859\n",
            "length of actions is  231\n",
            "Your final reward is : 251.04\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2225])\n",
            "30.37515830372962\n",
            "length of actions is  197\n",
            "256.02827370665426\n",
            "length of actions is  243\n",
            "260.95175459768393\n",
            "length of actions is  307\n",
            "255.8938600702658\n",
            "length of actions is  193\n",
            "263.76217850038506\n",
            "length of actions is  252\n",
            "Your final reward is : 213.40\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3014])\n",
            "150.51930858764052\n",
            "length of actions is  1000\n",
            "252.3792995376755\n",
            "length of actions is  182\n",
            "297.9053382636443\n",
            "length of actions is  227\n",
            "246.15624562077377\n",
            "length of actions is  270\n",
            "314.9515840091965\n",
            "length of actions is  179\n",
            "Your final reward is : 252.38\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2238])\n",
            "34.33927593657387\n",
            "length of actions is  191\n",
            "298.0919339081903\n",
            "length of actions is  187\n",
            "241.89640902840307\n",
            "length of actions is  268\n",
            "245.31095674641077\n",
            "length of actions is  169\n",
            "5.818590679255422\n",
            "length of actions is  119\n",
            "Your final reward is : 165.09\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2389])\n",
            "147.16519118341796\n",
            "length of actions is  1000\n",
            "252.69740850069167\n",
            "length of actions is  179\n",
            "284.9626243702407\n",
            "length of actions is  359\n",
            "299.65440896015264\n",
            "length of actions is  235\n",
            "283.63016677059875\n",
            "length of actions is  247\n",
            "Your final reward is : 253.62\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3392])\n",
            "153.71868078247513\n",
            "length of actions is  1000\n",
            "255.57988170055663\n",
            "length of actions is  167\n",
            "283.97332777117924\n",
            "length of actions is  759\n",
            "202.96871868958618\n",
            "length of actions is  270\n",
            "299.6928723855647\n",
            "length of actions is  193\n",
            "Your final reward is : 239.19\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2860])\n",
            "153.33594757118118\n",
            "length of actions is  1000\n",
            "251.51599170426198\n",
            "length of actions is  172\n",
            "299.7412926527378\n",
            "length of actions is  206\n",
            "255.78493557652908\n",
            "length of actions is  281\n",
            "264.705708534249\n",
            "length of actions is  212\n",
            "Your final reward is : 245.02\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2392])\n",
            "147.59263981533812\n",
            "length of actions is  1000\n",
            "254.09080776553344\n",
            "length of actions is  173\n",
            "296.13291069280285\n",
            "length of actions is  246\n",
            "301.72717966308346\n",
            "length of actions is  263\n",
            "282.4890560438791\n",
            "length of actions is  240\n",
            "Your final reward is : 256.41\n",
            "torch.from_numpy(rewards) looks like  torch.Size([4144])\n",
            "267.78142982916154\n",
            "length of actions is  227\n",
            "306.9371388906221\n",
            "length of actions is  253\n",
            "170.38240354181792\n",
            "length of actions is  1000\n",
            "263.0237909460027\n",
            "length of actions is  221\n",
            "280.02293590797916\n",
            "length of actions is  274\n",
            "Your final reward is : 257.63\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3742])\n",
            "271.33497441448526\n",
            "length of actions is  218\n",
            "90.93209769943954\n",
            "length of actions is  104\n",
            "287.8125052514522\n",
            "length of actions is  233\n",
            "299.2854417257924\n",
            "length of actions is  233\n",
            "278.71793389325853\n",
            "length of actions is  244\n",
            "Your final reward is : 245.62\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3109])\n",
            "151.52077294471215\n",
            "length of actions is  1000\n",
            "250.99878415395966\n",
            "length of actions is  189\n",
            "264.50016537904423\n",
            "length of actions is  275\n",
            "295.6880423345945\n",
            "length of actions is  232\n",
            "290.00475726775437\n",
            "length of actions is  177\n",
            "Your final reward is : 250.54\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2728])\n",
            "271.8779462073543\n",
            "length of actions is  219\n",
            "227.24211363144667\n",
            "length of actions is  213\n",
            "223.6177132004958\n",
            "length of actions is  227\n",
            "295.5499025868915\n",
            "length of actions is  250\n",
            "282.1931033560088\n",
            "length of actions is  223\n",
            "Your final reward is : 260.10\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2267])\n",
            "271.6485746747944\n",
            "length of actions is  231\n",
            "282.0399635097632\n",
            "length of actions is  263\n",
            "301.2873321601712\n",
            "length of actions is  221\n",
            "74.70107522633398\n",
            "length of actions is  94\n",
            "245.93279378488847\n",
            "length of actions is  244\n",
            "Your final reward is : 235.12\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2387])\n",
            "270.17445750521904\n",
            "length of actions is  219\n",
            "229.65181652425144\n",
            "length of actions is  199\n",
            "277.46863724135085\n",
            "length of actions is  223\n",
            "276.6440931913489\n",
            "length of actions is  156\n",
            "248.55000127526822\n",
            "length of actions is  228\n",
            "Your final reward is : 260.50\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2238])\n",
            "276.132131177803\n",
            "length of actions is  217\n",
            "296.3710766748816\n",
            "length of actions is  274\n",
            "293.97099003015796\n",
            "length of actions is  234\n",
            "280.5464428611449\n",
            "length of actions is  282\n",
            "257.8734186039244\n",
            "length of actions is  182\n",
            "Your final reward is : 280.98\n",
            "Improve to score 280.98 at batch 47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-89-b4ccb7a39aa3>:116: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  np.save(PATH ,np.array(action_list))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "length of actions is  99\n",
            "16.64483836188643\n",
            "length of actions is  137\n",
            "11.167010342552658\n",
            "length of actions is  166\n",
            "274.53520193052805\n",
            "length of actions is  186\n",
            "Your final reward is : 60.53\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1920])\n",
            "4.30770113797179\n",
            "length of actions is  146\n",
            "15.355615621867429\n",
            "length of actions is  138\n",
            "24.575303248566286\n",
            "length of actions is  147\n",
            "256.45298759985656\n",
            "length of actions is  214\n",
            "3.3558264281579966\n",
            "length of actions is  127\n",
            "Your final reward is : 60.81\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1534])\n",
            "13.88160496070067\n",
            "length of actions is  144\n",
            "19.738091488752204\n",
            "length of actions is  135\n",
            "-2.0811368398267547\n",
            "length of actions is  155\n",
            "17.498448305509598\n",
            "length of actions is  131\n",
            "32.85635359541831\n",
            "length of actions is  156\n",
            "Your final reward is : 16.38\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2048])\n",
            "-0.2956984720604794\n",
            "length of actions is  150\n",
            "7.241672106248032\n",
            "length of actions is  138\n",
            "260.87152805087294\n",
            "length of actions is  235\n",
            "24.80352749952813\n",
            "length of actions is  143\n",
            "0.0870322389060334\n",
            "length of actions is  143\n",
            "Your final reward is : 58.54\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1425])\n",
            "6.089065480134408\n",
            "length of actions is  146\n",
            "25.637192558435046\n",
            "length of actions is  134\n",
            "290.2577808182687\n",
            "length of actions is  217\n",
            "262.1500138585129\n",
            "length of actions is  216\n",
            "46.87554199696825\n",
            "length of actions is  131\n",
            "Your final reward is : 126.20\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1743])\n",
            "4.31458230605341\n",
            "length of actions is  151\n",
            "41.23891958145552\n",
            "length of actions is  123\n",
            "-15.494177048415693\n",
            "length of actions is  111\n",
            "1.3795343632109365\n",
            "length of actions is  135\n",
            "35.55303224171564\n",
            "length of actions is  126\n",
            "Your final reward is : 13.40\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2622])\n",
            "10.416893683070299\n",
            "length of actions is  148\n",
            "17.49876067659133\n",
            "length of actions is  112\n",
            "249.50662713001114\n",
            "length of actions is  203\n",
            "-2.1229882311083657\n",
            "length of actions is  130\n",
            "164.58766619460624\n",
            "length of actions is  1000\n",
            "Your final reward is : 87.98\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1931])\n",
            "5.344111258872118\n",
            "length of actions is  140\n",
            "-28.360060383521073\n",
            "length of actions is  129\n",
            "10.045541831157962\n",
            "length of actions is  122\n",
            "5.94426471318512\n",
            "length of actions is  132\n",
            "36.8026983679853\n",
            "length of actions is  121\n",
            "Your final reward is : 5.96\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3306])\n",
            "9.730393087402192\n",
            "length of actions is  146\n",
            "37.93647769085487\n",
            "length of actions is  138\n",
            "240.790570976902\n",
            "length of actions is  416\n",
            "53.1220958592813\n",
            "length of actions is  118\n",
            "131.2516622089435\n",
            "length of actions is  1000\n",
            "Your final reward is : 94.57\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1767])\n",
            "13.557669563539804\n",
            "length of actions is  146\n",
            "30.416077664579944\n",
            "length of actions is  137\n",
            "254.46034179493446\n",
            "length of actions is  179\n",
            "262.8076613057587\n",
            "length of actions is  226\n",
            "28.334768214358235\n",
            "length of actions is  146\n",
            "Your final reward is : 117.92\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2409])\n",
            "11.679810499378192\n",
            "length of actions is  147\n",
            "37.474619750967264\n",
            "length of actions is  154\n",
            "9.707775043490926\n",
            "length of actions is  141\n",
            "127.12355143679801\n",
            "length of actions is  1000\n",
            "41.82993363935324\n",
            "length of actions is  147\n",
            "Your final reward is : 45.56\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1529])\n",
            "9.361112927416158\n",
            "length of actions is  146\n",
            "26.320578508823672\n",
            "length of actions is  129\n",
            "15.428635049175895\n",
            "length of actions is  123\n",
            "281.83102129649797\n",
            "length of actions is  201\n",
            "16.353233961630593\n",
            "length of actions is  142\n",
            "Your final reward is : 69.86\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2167])\n",
            "13.228269632736868\n",
            "length of actions is  148\n",
            "27.367686416768578\n",
            "length of actions is  108\n",
            "-4.664573021069799\n",
            "length of actions is  131\n",
            "131.23325452743393\n",
            "length of actions is  1000\n",
            "32.1887818447143\n",
            "length of actions is  116\n",
            "Your final reward is : 39.87\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2685])\n",
            "11.517171073022439\n",
            "length of actions is  150\n",
            "-2.591751781710869\n",
            "length of actions is  131\n",
            "51.561774233631354\n",
            "length of actions is  148\n",
            "266.9733137013558\n",
            "length of actions is  208\n",
            "258.8202239136301\n",
            "length of actions is  216\n",
            "Your final reward is : 117.26\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2183])\n",
            "25.276900997709078\n",
            "length of actions is  147\n",
            "167.40543080398828\n",
            "length of actions is  1000\n",
            "4.1097062783590275\n",
            "length of actions is  126\n",
            "176.05873096124185\n",
            "length of actions is  1000\n",
            "141.0987979093653\n",
            "length of actions is  1000\n",
            "Your final reward is : 102.79\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1532])\n",
            "13.874624096698938\n",
            "length of actions is  150\n",
            "0.29244188285375117\n",
            "length of actions is  136\n",
            "26.637208985435933\n",
            "length of actions is  132\n",
            "281.02604383684684\n",
            "length of actions is  214\n",
            "-1.9890127764783472\n",
            "length of actions is  115\n",
            "Your final reward is : 63.97\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3664])\n",
            "19.765440338560637\n",
            "length of actions is  149\n",
            "24.4151241042254\n",
            "length of actions is  121\n",
            "246.1400455865601\n",
            "length of actions is  221\n",
            "26.008869608545027\n",
            "length of actions is  126\n",
            "113.48373150932998\n",
            "length of actions is  1000\n",
            "Your final reward is : 85.96\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1559])\n",
            "19.385736917335507\n",
            "length of actions is  145\n",
            "28.68554814782729\n",
            "length of actions is  141\n",
            "37.384515829275216\n",
            "length of actions is  126\n",
            "159.10219325240732\n",
            "length of actions is  1000\n",
            "136.2921996794178\n",
            "length of actions is  1000\n",
            "Your final reward is : 76.17\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2201])\n",
            "15.695799681989271\n",
            "length of actions is  151\n",
            "42.35058008032041\n",
            "length of actions is  123\n",
            "-18.650280400267746\n",
            "length of actions is  113\n",
            "128.73727720402954\n",
            "length of actions is  1000\n",
            "41.97887776054719\n",
            "length of actions is  125\n",
            "Your final reward is : 42.02\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3808])\n",
            "25.94858757561032\n",
            "length of actions is  157\n",
            "39.04735517438445\n",
            "length of actions is  139\n",
            "23.226843024117954\n",
            "length of actions is  131\n",
            "141.80633326869813\n",
            "length of actions is  1000\n",
            "274.4791462410426\n",
            "length of actions is  178\n",
            "Your final reward is : 100.90\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2815])\n",
            "27.208258122964523\n",
            "length of actions is  162\n",
            "264.94912322173525\n",
            "length of actions is  203\n",
            "170.800848687309\n",
            "length of actions is  1000\n",
            "164.66261700606273\n",
            "length of actions is  1000\n",
            "47.50601746276428\n",
            "length of actions is  117\n",
            "Your final reward is : 135.03\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2212])\n",
            "28.356052147959446\n",
            "length of actions is  160\n",
            "45.04758257857844\n",
            "length of actions is  162\n",
            "-11.685927560909363\n",
            "length of actions is  122\n",
            "29.236842202974145\n",
            "length of actions is  138\n",
            "21.747884588234243\n",
            "length of actions is  138\n",
            "Your final reward is : 22.54\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1420])\n",
            "22.881673140462823\n",
            "length of actions is  158\n",
            "27.004643625946798\n",
            "length of actions is  155\n",
            "-0.4997149265968801\n",
            "length of actions is  149\n",
            "146.94751742625772\n",
            "length of actions is  1000\n",
            "41.09447657691928\n",
            "length of actions is  145\n",
            "Your final reward is : 47.49\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1668])\n",
            "31.53917896705633\n",
            "length of actions is  161\n",
            "6.767432937474567\n",
            "length of actions is  145\n",
            "250.89726491283477\n",
            "length of actions is  185\n",
            "32.663323783157665\n",
            "length of actions is  142\n",
            "264.94042672941066\n",
            "length of actions is  167\n",
            "Your final reward is : 117.36\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3052])\n",
            "19.264738419533288\n",
            "length of actions is  160\n",
            "44.941924529543456\n",
            "length of actions is  163\n",
            "31.23577541663488\n",
            "length of actions is  159\n",
            "262.8567809115153\n",
            "length of actions is  197\n",
            "14.383630255177266\n",
            "length of actions is  123\n",
            "Your final reward is : 74.54\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2098])\n",
            "27.377490298050773\n",
            "length of actions is  163\n",
            "266.61257368236886\n",
            "length of actions is  187\n",
            "247.83997172850044\n",
            "length of actions is  178\n",
            "48.97331992835743\n",
            "length of actions is  150\n",
            "-11.598739248955965\n",
            "length of actions is  137\n",
            "Your final reward is : 115.84\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2601])\n",
            "30.8741523411247\n",
            "length of actions is  160\n",
            "39.04950601340241\n",
            "length of actions is  157\n",
            "20.104496888892214\n",
            "length of actions is  146\n",
            "30.868426425031345\n",
            "length of actions is  139\n",
            "271.5670440361076\n",
            "length of actions is  157\n",
            "Your final reward is : 78.49\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1892])\n",
            "9.485668049625176\n",
            "length of actions is  169\n",
            "167.77528880685725\n",
            "length of actions is  1000\n",
            "19.667481156037752\n",
            "length of actions is  136\n",
            "147.73723218640504\n",
            "length of actions is  1000\n",
            "154.08384758441812\n",
            "length of actions is  1000\n",
            "Your final reward is : 99.75\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3559])\n",
            "18.561894374970834\n",
            "length of actions is  174\n",
            "40.151777520559705\n",
            "length of actions is  152\n",
            "166.9277933001841\n",
            "length of actions is  1000\n",
            "275.2762689294443\n",
            "length of actions is  193\n",
            "280.5509782455371\n",
            "length of actions is  184\n",
            "Your final reward is : 156.29\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2403])\n",
            "14.956495432868152\n",
            "length of actions is  180\n",
            "28.26048043550287\n",
            "length of actions is  143\n",
            "44.193784725271\n",
            "length of actions is  159\n",
            "261.4041016903361\n",
            "length of actions is  172\n",
            "236.33828857942856\n",
            "length of actions is  178\n",
            "Your final reward is : 117.03\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2751])\n",
            "29.637197310736752\n",
            "length of actions is  176\n",
            "33.57122177369922\n",
            "length of actions is  141\n",
            "30.909812725822718\n",
            "length of actions is  154\n",
            "268.64085663592596\n",
            "length of actions is  222\n",
            "30.32271232247524\n",
            "length of actions is  177\n",
            "Your final reward is : 78.62\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2271])\n",
            "246.07899305390234\n",
            "length of actions is  234\n",
            "25.614934364841474\n",
            "length of actions is  135\n",
            "240.83158432468468\n",
            "length of actions is  385\n",
            "255.06166568707357\n",
            "length of actions is  752\n",
            "222.88105382515357\n",
            "length of actions is  302\n",
            "Your final reward is : 198.09\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2783])\n",
            "240.44608696484767\n",
            "length of actions is  271\n",
            "257.26231338551605\n",
            "length of actions is  202\n",
            "262.80532462646704\n",
            "length of actions is  217\n",
            "56.21918887530856\n",
            "length of actions is  119\n",
            "246.298927610099\n",
            "length of actions is  185\n",
            "Your final reward is : 212.61\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2944])\n",
            "229.51031342558719\n",
            "length of actions is  322\n",
            "246.10700988355893\n",
            "length of actions is  293\n",
            "50.191687667216286\n",
            "length of actions is  145\n",
            "19.95078445036677\n",
            "length of actions is  128\n",
            "240.6148942652929\n",
            "length of actions is  189\n",
            "Your final reward is : 157.27\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3929])\n",
            "232.31181971566514\n",
            "length of actions is  257\n",
            "250.5527237504683\n",
            "length of actions is  249\n",
            "251.6413529133782\n",
            "length of actions is  215\n",
            "283.4617065486323\n",
            "length of actions is  204\n",
            "123.15211050173154\n",
            "length of actions is  1000\n",
            "Your final reward is : 228.22\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3007])\n",
            "208.2946225387318\n",
            "length of actions is  282\n",
            "-6.335524971477639\n",
            "length of actions is  131\n",
            "18.723530919404723\n",
            "length of actions is  133\n",
            "247.06734315473582\n",
            "length of actions is  221\n",
            "243.2697452449725\n",
            "length of actions is  262\n",
            "Your final reward is : 142.20\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2776])\n",
            "222.08865055267248\n",
            "length of actions is  321\n",
            "2.251042441013624\n",
            "length of actions is  137\n",
            "234.35838571940107\n",
            "length of actions is  235\n",
            "14.851111926177353\n",
            "length of actions is  122\n",
            "229.02772747740525\n",
            "length of actions is  256\n",
            "Your final reward is : 140.52\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3253])\n",
            "193.49685571883552\n",
            "length of actions is  365\n",
            "252.41116541381004\n",
            "length of actions is  164\n",
            "230.01439256347425\n",
            "length of actions is  317\n",
            "249.74395036761362\n",
            "length of actions is  495\n",
            "-207.09665319849523\n",
            "length of actions is  201\n",
            "Your final reward is : 143.71\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3244])\n",
            "214.97678197033912\n",
            "length of actions is  308\n",
            "260.4817153432846\n",
            "length of actions is  309\n",
            "239.69833569941954\n",
            "length of actions is  292\n",
            "260.56130439062275\n",
            "length of actions is  276\n",
            "291.30314963374724\n",
            "length of actions is  181\n",
            "Your final reward is : 253.40\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2098])\n",
            "222.20151029248566\n",
            "length of actions is  309\n",
            "-0.47042936258489476\n",
            "length of actions is  131\n",
            "9.971157173667834\n",
            "length of actions is  140\n",
            "33.80607076707608\n",
            "length of actions is  116\n",
            "254.07304222437082\n",
            "length of actions is  293\n",
            "Your final reward is : 103.92\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2808])\n",
            "193.25541644824673\n",
            "length of actions is  328\n",
            "11.361946852880777\n",
            "length of actions is  124\n",
            "24.900533612789488\n",
            "length of actions is  132\n",
            "29.546938930256175\n",
            "length of actions is  120\n",
            "239.05197003563157\n",
            "length of actions is  285\n",
            "Your final reward is : 99.62\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2048])\n",
            "210.54394948976704\n",
            "length of actions is  286\n",
            "265.8474615457988\n",
            "length of actions is  281\n",
            "231.37196074073051\n",
            "length of actions is  299\n",
            "33.552734351792935\n",
            "length of actions is  126\n",
            "48.61814675879839\n",
            "length of actions is  125\n",
            "Your final reward is : 157.99\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2277])\n",
            "229.23556595468213\n",
            "length of actions is  277\n",
            "23.367470566378103\n",
            "length of actions is  121\n",
            "46.21392922705181\n",
            "length of actions is  152\n",
            "28.90045943527494\n",
            "length of actions is  121\n",
            "230.96690123767434\n",
            "length of actions is  237\n",
            "Your final reward is : 111.74\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2239])\n",
            "235.38940742682797\n",
            "length of actions is  265\n",
            "233.2085715133524\n",
            "length of actions is  279\n",
            "222.83049843139185\n",
            "length of actions is  270\n",
            "32.96875333622441\n",
            "length of actions is  125\n",
            "252.21962557619904\n",
            "length of actions is  228\n",
            "Your final reward is : 195.32\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1944])\n",
            "232.35711122065538\n",
            "length of actions is  253\n",
            "21.77079055448111\n",
            "length of actions is  116\n",
            "152.19451643069445\n",
            "length of actions is  1000\n",
            "21.926210417805507\n",
            "length of actions is  113\n",
            "-6.149925928495492\n",
            "length of actions is  129\n",
            "Your final reward is : 84.42\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3005])\n",
            "-171.80877562925832\n",
            "length of actions is  226\n",
            "41.18933902905914\n",
            "length of actions is  123\n",
            "17.86987585647077\n",
            "length of actions is  154\n",
            "119.59754752908772\n",
            "length of actions is  1000\n",
            "37.62608279954159\n",
            "length of actions is  105\n",
            "Your final reward is : 8.89\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2393])\n",
            "227.59281316082382\n",
            "length of actions is  229\n",
            "-8.491546903052182\n",
            "length of actions is  112\n",
            "15.5984144019355\n",
            "length of actions is  120\n",
            "230.29300162735865\n",
            "length of actions is  275\n",
            "33.28994335780246\n",
            "length of actions is  119\n",
            "Your final reward is : 99.66\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2579])\n",
            "12.954940927523737\n",
            "length of actions is  155\n",
            "252.748550288707\n",
            "length of actions is  269\n",
            "41.54224976348752\n",
            "length of actions is  110\n",
            "246.3543110292731\n",
            "length of actions is  255\n",
            "279.89716293087645\n",
            "length of actions is  162\n",
            "Your final reward is : 166.70\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2916])\n",
            "241.55135065884343\n",
            "length of actions is  196\n",
            "258.8790485574701\n",
            "length of actions is  254\n",
            "228.67087708603145\n",
            "length of actions is  245\n",
            "234.40483947028218\n",
            "length of actions is  191\n",
            "252.0643494824247\n",
            "length of actions is  564\n",
            "Your final reward is : 243.11\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1725])\n",
            "225.56648613404604\n",
            "length of actions is  242\n",
            "256.7035453529184\n",
            "length of actions is  168\n",
            "256.635356660415\n",
            "length of actions is  224\n",
            "143.3134662523836\n",
            "length of actions is  1000\n",
            "256.2098305882022\n",
            "length of actions is  162\n",
            "Your final reward is : 227.69\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1902])\n",
            "221.41053349926682\n",
            "length of actions is  234\n",
            "24.643571221252145\n",
            "length of actions is  122\n",
            "145.2413226926139\n",
            "length of actions is  1000\n",
            "254.50577868675668\n",
            "length of actions is  277\n",
            "155.15756351846693\n",
            "length of actions is  1000\n",
            "Your final reward is : 160.19\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2857])\n",
            "239.81273705210748\n",
            "length of actions is  220\n",
            "25.03501872053816\n",
            "length of actions is  118\n",
            "231.15488775094417\n",
            "length of actions is  265\n",
            "26.43843858932459\n",
            "length of actions is  119\n",
            "275.16262603726307\n",
            "length of actions is  237\n",
            "Your final reward is : 159.52\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3823])\n",
            "24.56082606410486\n",
            "length of actions is  138\n",
            "233.13551268991802\n",
            "length of actions is  219\n",
            "247.717728824215\n",
            "length of actions is  194\n",
            "34.63836698599195\n",
            "length of actions is  136\n",
            "232.3759685306034\n",
            "length of actions is  194\n",
            "Your final reward is : 154.49\n",
            "torch.from_numpy(rewards) looks like  torch.Size([4039])\n",
            "18.757344763701354\n",
            "length of actions is  149\n",
            "266.87424620888055\n",
            "length of actions is  176\n",
            "-23.82247674346732\n",
            "length of actions is  123\n",
            "251.75570729016852\n",
            "length of actions is  209\n",
            "58.26507481001772\n",
            "length of actions is  127\n",
            "Your final reward is : 114.37\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2588])\n",
            "241.4941753577477\n",
            "length of actions is  207\n",
            "259.00182140823324\n",
            "length of actions is  198\n",
            "284.8738174888621\n",
            "length of actions is  200\n",
            "250.92489105582237\n",
            "length of actions is  228\n",
            "21.22385193097496\n",
            "length of actions is  115\n",
            "Your final reward is : 211.50\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1961])\n",
            "9.426376775295637\n",
            "length of actions is  148\n",
            "52.91179642500663\n",
            "length of actions is  107\n",
            "247.9245904610583\n",
            "length of actions is  210\n",
            "138.3607989035253\n",
            "length of actions is  1000\n",
            "265.42978051382306\n",
            "length of actions is  164\n",
            "Your final reward is : 142.81\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3354])\n",
            "17.133341231512887\n",
            "length of actions is  137\n",
            "261.44846644867033\n",
            "length of actions is  236\n",
            "43.79005613050782\n",
            "length of actions is  164\n",
            "275.79858073036473\n",
            "length of actions is  216\n",
            "-8.526004782348622\n",
            "length of actions is  127\n",
            "Your final reward is : 117.93\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2480])\n",
            "29.021099031186935\n",
            "length of actions is  152\n",
            "52.519851564432656\n",
            "length of actions is  112\n",
            "5.49225815809848\n",
            "length of actions is  143\n",
            "269.8834688632759\n",
            "length of actions is  242\n",
            "249.75546421318433\n",
            "length of actions is  658\n",
            "Your final reward is : 121.33\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3610])\n",
            "230.544553994514\n",
            "length of actions is  222\n",
            "4.299574154751383\n",
            "length of actions is  118\n",
            "270.739154304518\n",
            "length of actions is  193\n",
            "242.91394068685975\n",
            "length of actions is  189\n",
            "278.6796540348734\n",
            "length of actions is  237\n",
            "Your final reward is : 205.44\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2906])\n",
            "20.405652059633965\n",
            "length of actions is  148\n",
            "38.67759087812021\n",
            "length of actions is  101\n",
            "266.3097830256495\n",
            "length of actions is  179\n",
            "255.8121627850922\n",
            "length of actions is  221\n",
            "261.8201094280628\n",
            "length of actions is  190\n",
            "Your final reward is : 168.61\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2745])\n",
            "20.047453979975813\n",
            "length of actions is  146\n",
            "254.24943581625894\n",
            "length of actions is  167\n",
            "-6.643627246273368\n",
            "length of actions is  131\n",
            "24.690204171012624\n",
            "length of actions is  122\n",
            "29.775009776612194\n",
            "length of actions is  103\n",
            "Your final reward is : 64.42\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2156])\n",
            "145.24773862380792\n",
            "length of actions is  1000\n",
            "243.6720822515642\n",
            "length of actions is  197\n",
            "34.05959656845579\n",
            "length of actions is  111\n",
            "243.27114686929272\n",
            "length of actions is  213\n",
            "42.87639388270529\n",
            "length of actions is  137\n",
            "Your final reward is : 141.83\n",
            "torch.from_numpy(rewards) looks like  torch.Size([5155])\n",
            "249.2977419197906\n",
            "length of actions is  210\n",
            "43.44849124668136\n",
            "length of actions is  126\n",
            "258.70535623559294\n",
            "length of actions is  237\n",
            "27.911308938215896\n",
            "length of actions is  167\n",
            "251.6750470611599\n",
            "length of actions is  187\n",
            "Your final reward is : 166.21\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3128])\n",
            "141.8558235590235\n",
            "length of actions is  1000\n",
            "128.78728463088322\n",
            "length of actions is  1000\n",
            "129.87944101440897\n",
            "length of actions is  1000\n",
            "285.22043529173493\n",
            "length of actions is  184\n",
            "246.61795714333448\n",
            "length of actions is  200\n",
            "Your final reward is : 186.47\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2548])\n",
            "143.36144485389713\n",
            "length of actions is  1000\n",
            "240.13275610826008\n",
            "length of actions is  197\n",
            "32.467249569666535\n",
            "length of actions is  114\n",
            "7.969285414680314\n",
            "length of actions is  147\n",
            "62.59742613927881\n",
            "length of actions is  184\n",
            "Your final reward is : 97.31\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2139])\n",
            "141.19392324778903\n",
            "length of actions is  1000\n",
            "219.97528709063016\n",
            "length of actions is  438\n",
            "23.92905408364335\n",
            "length of actions is  146\n",
            "279.20163081677674\n",
            "length of actions is  161\n",
            "28.464936001010585\n",
            "length of actions is  138\n",
            "Your final reward is : 138.55\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1912])\n",
            "138.5132564711977\n",
            "length of actions is  1000\n",
            "238.77912592958558\n",
            "length of actions is  232\n",
            "41.414169909268566\n",
            "length of actions is  134\n",
            "158.9794643314462\n",
            "length of actions is  1000\n",
            "274.2457782266697\n",
            "length of actions is  226\n",
            "Your final reward is : 170.39\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3908])\n",
            "57.96212221622508\n",
            "length of actions is  161\n",
            "20.85306878905584\n",
            "length of actions is  153\n",
            "265.24638482078285\n",
            "length of actions is  170\n",
            "21.323384430643912\n",
            "length of actions is  126\n",
            "252.93030664637226\n",
            "length of actions is  193\n",
            "Your final reward is : 123.66\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1611])\n",
            "152.49807787472548\n",
            "length of actions is  1000\n",
            "235.1600350615597\n",
            "length of actions is  923\n",
            "72.40600539162094\n",
            "length of actions is  133\n",
            "245.19426346813307\n",
            "length of actions is  197\n",
            "44.71595530803373\n",
            "length of actions is  115\n",
            "Your final reward is : 149.99\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2502])\n",
            "149.9355482434038\n",
            "length of actions is  1000\n",
            "231.34596765785912\n",
            "length of actions is  177\n",
            "233.28969974881588\n",
            "length of actions is  183\n",
            "257.7211391893811\n",
            "length of actions is  181\n",
            "268.89996195649655\n",
            "length of actions is  211\n",
            "Your final reward is : 228.24\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2618])\n",
            "156.00265370752442\n",
            "length of actions is  1000\n",
            "240.57463465562267\n",
            "length of actions is  191\n",
            "35.5560511700028\n",
            "length of actions is  128\n",
            "173.0038441201222\n",
            "length of actions is  1000\n",
            "156.4363721066505\n",
            "length of actions is  1000\n",
            "Your final reward is : 152.31\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2486])\n",
            "150.72506050795204\n",
            "length of actions is  1000\n",
            "227.70692047271532\n",
            "length of actions is  464\n",
            "290.1027691032331\n",
            "length of actions is  156\n",
            "272.94124698630947\n",
            "length of actions is  202\n",
            "165.7583177921042\n",
            "length of actions is  1000\n",
            "Your final reward is : 221.45\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2000])\n",
            "39.63994423336612\n",
            "length of actions is  164\n",
            "273.7280093952239\n",
            "length of actions is  183\n",
            "34.956981533592085\n",
            "length of actions is  115\n",
            "261.7824784592038\n",
            "length of actions is  208\n",
            "46.05630059605065\n",
            "length of actions is  152\n",
            "Your final reward is : 131.23\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2639])\n",
            "154.247152741455\n",
            "length of actions is  1000\n",
            "139.04326320089572\n",
            "length of actions is  1000\n",
            "257.22867719568546\n",
            "length of actions is  188\n",
            "267.80354811534283\n",
            "length of actions is  211\n",
            "248.72726790233145\n",
            "length of actions is  202\n",
            "Your final reward is : 213.41\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2593])\n",
            "155.7445146435829\n",
            "length of actions is  1000\n",
            "227.911712260671\n",
            "length of actions is  156\n",
            "280.6211626629065\n",
            "length of actions is  201\n",
            "269.6753164258124\n",
            "length of actions is  192\n",
            "260.98993729987706\n",
            "length of actions is  222\n",
            "Your final reward is : 238.99\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2318])\n",
            "154.00586561066342\n",
            "length of actions is  1000\n",
            "234.6212629290275\n",
            "length of actions is  143\n",
            "288.25811621043954\n",
            "length of actions is  357\n",
            "64.02636617825752\n",
            "length of actions is  126\n",
            "272.464152651296\n",
            "length of actions is  213\n",
            "Your final reward is : 202.68\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1935])\n",
            "36.55107954261305\n",
            "length of actions is  160\n",
            "245.51595923079915\n",
            "length of actions is  223\n",
            "269.5171144212645\n",
            "length of actions is  230\n",
            "17.122523978102706\n",
            "length of actions is  136\n",
            "283.04448178481596\n",
            "length of actions is  215\n",
            "Your final reward is : 170.35\n",
            "torch.from_numpy(rewards) looks like  torch.Size([4092])\n",
            "46.32758158984069\n",
            "length of actions is  163\n",
            "170.07098065737978\n",
            "length of actions is  528\n",
            "215.34473528651233\n",
            "length of actions is  316\n",
            "193.4529653553356\n",
            "length of actions is  394\n",
            "230.3552844260979\n",
            "length of actions is  202\n",
            "Your final reward is : 171.11\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2620])\n",
            "38.91717251114099\n",
            "length of actions is  165\n",
            "54.90054663262785\n",
            "length of actions is  126\n",
            "169.82689468263032\n",
            "length of actions is  1000\n",
            "197.197051321701\n",
            "length of actions is  425\n",
            "238.46434201447636\n",
            "length of actions is  150\n",
            "Your final reward is : 139.86\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2657])\n",
            "57.3361036927204\n",
            "length of actions is  170\n",
            "63.98116972925499\n",
            "length of actions is  188\n",
            "76.72239400276905\n",
            "length of actions is  158\n",
            "62.21051831323129\n",
            "length of actions is  118\n",
            "239.50859615519573\n",
            "length of actions is  191\n",
            "Your final reward is : 99.95\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1947])\n",
            "44.38629109887336\n",
            "length of actions is  167\n",
            "279.94025992128064\n",
            "length of actions is  174\n",
            "22.428214796648916\n",
            "length of actions is  128\n",
            "88.00833528998507\n",
            "length of actions is  170\n",
            "49.46486169815432\n",
            "length of actions is  127\n",
            "Your final reward is : 96.85\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2611])\n",
            "58.16870081974824\n",
            "length of actions is  166\n",
            "55.47066491148706\n",
            "length of actions is  153\n",
            "74.15742194655843\n",
            "length of actions is  149\n",
            "9.317549581928674\n",
            "length of actions is  143\n",
            "192.93959680520982\n",
            "length of actions is  459\n",
            "Your final reward is : 78.01\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2488])\n",
            "159.50284526941664\n",
            "length of actions is  1000\n",
            "225.7397346022847\n",
            "length of actions is  204\n",
            "255.45081556845764\n",
            "length of actions is  228\n",
            "51.45985178527408\n",
            "length of actions is  148\n",
            "35.76727786999291\n",
            "length of actions is  131\n",
            "Your final reward is : 145.58\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3528])\n",
            "61.139273460601345\n",
            "length of actions is  166\n",
            "43.30442480821159\n",
            "length of actions is  152\n",
            "75.97619727006114\n",
            "length of actions is  142\n",
            "60.15982490527705\n",
            "length of actions is  136\n",
            "20.895529966465517\n",
            "length of actions is  139\n",
            "Your final reward is : 52.30\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2973])\n",
            "62.2109469573999\n",
            "length of actions is  175\n",
            "36.90461340989802\n",
            "length of actions is  167\n",
            "59.65654512931724\n",
            "length of actions is  168\n",
            "223.73713569721025\n",
            "length of actions is  261\n",
            "139.46446501882386\n",
            "length of actions is  1000\n",
            "Your final reward is : 104.39\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1559])\n",
            "42.23718105125127\n",
            "length of actions is  164\n",
            "39.66960864585974\n",
            "length of actions is  129\n",
            "-15.350185012455427\n",
            "length of actions is  83\n",
            "31.256007587922625\n",
            "length of actions is  151\n",
            "254.34570967535478\n",
            "length of actions is  172\n",
            "Your final reward is : 70.43\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1513])\n",
            "48.5620927371794\n",
            "length of actions is  168\n",
            "25.40560642221621\n",
            "length of actions is  151\n",
            "64.59736781497253\n",
            "length of actions is  147\n",
            "63.84593152365639\n",
            "length of actions is  172\n",
            "18.033361483405642\n",
            "length of actions is  121\n",
            "Your final reward is : 44.09\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1274])\n",
            "46.401563266998096\n",
            "length of actions is  174\n",
            "66.13831716968119\n",
            "length of actions is  156\n",
            "64.17357898462302\n",
            "length of actions is  113\n",
            "67.06535237646378\n",
            "length of actions is  161\n",
            "39.80309165742992\n",
            "length of actions is  158\n",
            "Your final reward is : 56.72\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2515])\n",
            "51.61273488617758\n",
            "length of actions is  172\n",
            "1.87288768676936\n",
            "length of actions is  126\n",
            "31.40176543639828\n",
            "length of actions is  119\n",
            "219.2452154519197\n",
            "length of actions is  305\n",
            "48.13271731285968\n",
            "length of actions is  138\n",
            "Your final reward is : 70.45\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2651])\n",
            "61.35112547650783\n",
            "length of actions is  174\n",
            "51.82709357280825\n",
            "length of actions is  157\n",
            "-30.366562711118874\n",
            "length of actions is  75\n",
            "57.09928991321124\n",
            "length of actions is  107\n",
            "42.013150347985885\n",
            "length of actions is  135\n",
            "Your final reward is : 36.38\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2399])\n",
            "47.66872301123817\n",
            "length of actions is  170\n",
            "53.55502178086931\n",
            "length of actions is  188\n",
            "52.025392521170744\n",
            "length of actions is  173\n",
            "-0.6887588991462081\n",
            "length of actions is  81\n",
            "56.02371647128993\n",
            "length of actions is  169\n",
            "Your final reward is : 41.72\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1406])\n",
            "48.072494454717884\n",
            "length of actions is  171\n",
            "50.84663444159338\n",
            "length of actions is  194\n",
            "43.642663732946886\n",
            "length of actions is  110\n",
            "269.4940091998027\n",
            "length of actions is  182\n",
            "66.46790335240865\n",
            "length of actions is  146\n",
            "Your final reward is : 95.70\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1404])\n",
            "50.59780995371932\n",
            "length of actions is  168\n",
            "25.695581250286565\n",
            "length of actions is  148\n",
            "3.736694146986167\n",
            "length of actions is  116\n",
            "189.89471575339564\n",
            "length of actions is  346\n",
            "43.17071371906047\n",
            "length of actions is  158\n",
            "Your final reward is : 62.62\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1525])\n",
            "40.958390683556985\n",
            "length of actions is  164\n",
            "25.85171296524615\n",
            "length of actions is  125\n",
            "66.44708773213239\n",
            "length of actions is  161\n",
            "4.074945605561027\n",
            "length of actions is  118\n",
            "25.84793790994054\n",
            "length of actions is  135\n",
            "Your final reward is : 32.64\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1388])\n",
            "53.49667971265822\n",
            "length of actions is  167\n",
            "22.31546567984533\n",
            "length of actions is  81\n",
            "-6.12337037316226\n",
            "length of actions is  98\n",
            "49.43290693876304\n",
            "length of actions is  155\n",
            "202.31828863508787\n",
            "length of actions is  219\n",
            "Your final reward is : 64.29\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1857])\n",
            "46.534958312623104\n",
            "length of actions is  165\n",
            "34.666217997048534\n",
            "length of actions is  116\n",
            "122.7037022600417\n",
            "length of actions is  1000\n",
            "45.97748348589846\n",
            "length of actions is  124\n",
            "6.976184302678519\n",
            "length of actions is  114\n",
            "Your final reward is : 51.37\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1465])\n",
            "46.964167510360596\n",
            "length of actions is  174\n",
            "49.15942776141833\n",
            "length of actions is  146\n",
            "-31.119860010061544\n",
            "length of actions is  118\n",
            "32.81175144838761\n",
            "length of actions is  114\n",
            "28.768738331278342\n",
            "length of actions is  153\n",
            "Your final reward is : 25.32\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1424])\n",
            "37.85464991705442\n",
            "length of actions is  169\n",
            "46.403639260521715\n",
            "length of actions is  127\n",
            "-0.335107764733408\n",
            "length of actions is  90\n",
            "-8.101474386045155\n",
            "length of actions is  109\n",
            "2.3684089474136982\n",
            "length of actions is  103\n",
            "Your final reward is : 15.64\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1214])\n",
            "53.56831619500477\n",
            "length of actions is  177\n",
            "56.93734768816134\n",
            "length of actions is  160\n",
            "225.77624272281452\n",
            "length of actions is  236\n",
            "55.32432549671208\n",
            "length of actions is  200\n",
            "30.788841849216055\n",
            "length of actions is  100\n",
            "Your final reward is : 84.48\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1260])\n",
            "46.60543857504328\n",
            "length of actions is  173\n",
            "13.68462157955068\n",
            "length of actions is  99\n",
            "-9.48389155153734\n",
            "length of actions is  111\n",
            "63.236714273915766\n",
            "length of actions is  157\n",
            "29.970624846133433\n",
            "length of actions is  135\n",
            "Your final reward is : 28.80\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1289])\n",
            "43.663994671452144\n",
            "length of actions is  173\n",
            "20.522905491431573\n",
            "length of actions is  104\n",
            "62.12650749560959\n",
            "length of actions is  192\n",
            "71.44670779569955\n",
            "length of actions is  187\n",
            "10.14086566044054\n",
            "length of actions is  103\n",
            "Your final reward is : 41.58\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1347])\n",
            "43.30532836548764\n",
            "length of actions is  171\n",
            "53.753098296230746\n",
            "length of actions is  199\n",
            "-6.614778171335658\n",
            "length of actions is  107\n",
            "55.12450101011598\n",
            "length of actions is  102\n",
            "-39.43274221907954\n",
            "length of actions is  95\n",
            "Your final reward is : 21.23\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1145])\n",
            "49.260490036084974\n",
            "length of actions is  173\n",
            "9.830672168257962\n",
            "length of actions is  101\n",
            "72.83430886037766\n",
            "length of actions is  145\n",
            "-39.93509332427966\n",
            "length of actions is  87\n",
            "30.124655513932254\n",
            "length of actions is  130\n",
            "Your final reward is : 24.42\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1089])\n",
            "46.960289632431056\n",
            "length of actions is  179\n",
            "5.1597773736131245\n",
            "length of actions is  121\n",
            "57.82915214415229\n",
            "length of actions is  156\n",
            "19.55573545395373\n",
            "length of actions is  244\n",
            "-27.403741043931817\n",
            "length of actions is  106\n",
            "Your final reward is : 20.42\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1758])\n",
            "44.52407861879007\n",
            "length of actions is  175\n",
            "39.38979883996478\n",
            "length of actions is  173\n",
            "46.18551396570149\n",
            "length of actions is  171\n",
            "-2.123009517106439\n",
            "length of actions is  105\n",
            "9.521769796213817\n",
            "length of actions is  107\n",
            "Your final reward is : 27.50\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1640])\n",
            "51.60265957786925\n",
            "length of actions is  180\n",
            "55.20237828550566\n",
            "length of actions is  154\n",
            "19.48772491571755\n",
            "length of actions is  136\n",
            "26.207846121712862\n",
            "length of actions is  124\n",
            "33.21197096141421\n",
            "length of actions is  148\n",
            "Your final reward is : 37.14\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1384])\n",
            "55.84667324550793\n",
            "length of actions is  176\n",
            "74.5750517419545\n",
            "length of actions is  158\n",
            "33.62813409830716\n",
            "length of actions is  137\n",
            "215.30346235860338\n",
            "length of actions is  267\n",
            "219.18956325138478\n",
            "length of actions is  212\n",
            "Your final reward is : 119.71\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1153])\n",
            "61.908445228762986\n",
            "length of actions is  183\n",
            "34.17108264741802\n",
            "length of actions is  157\n",
            "14.172237439396753\n",
            "length of actions is  129\n",
            "298.6795840592391\n",
            "length of actions is  268\n",
            "10.7754503748412\n",
            "length of actions is  112\n",
            "Your final reward is : 83.94\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1706])\n",
            "45.69972730797494\n",
            "length of actions is  183\n",
            "25.608165486408822\n",
            "length of actions is  155\n",
            "15.382110023263706\n",
            "length of actions is  127\n",
            "52.73762994985967\n",
            "length of actions is  159\n",
            "10.471773762395472\n",
            "length of actions is  110\n",
            "Your final reward is : 29.98\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1655])\n",
            "42.0722308363292\n",
            "length of actions is  184\n",
            "69.73847902453159\n",
            "length of actions is  156\n",
            "9.52601596590209\n",
            "length of actions is  128\n",
            "-65.94914404367884\n",
            "length of actions is  120\n",
            "-25.95398938894712\n",
            "length of actions is  62\n",
            "Your final reward is : 5.89\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1533])\n",
            "47.784413821170546\n",
            "length of actions is  173\n",
            "2.10176637509511\n",
            "length of actions is  112\n",
            "50.8962784998138\n",
            "length of actions is  124\n",
            "36.26868714879353\n",
            "length of actions is  109\n",
            "281.70853872601725\n",
            "length of actions is  204\n",
            "Your final reward is : 83.75\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1252])\n",
            "41.85267152531043\n",
            "length of actions is  181\n",
            "-35.22293080030458\n",
            "length of actions is  73\n",
            "27.164158100647867\n",
            "length of actions is  148\n",
            "31.256096130125883\n",
            "length of actions is  119\n",
            "51.964663023987015\n",
            "length of actions is  198\n",
            "Your final reward is : 23.40\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1400])\n",
            "279.8955218253565\n",
            "length of actions is  264\n",
            "-62.3596742322187\n",
            "length of actions is  94\n",
            "58.34533748145054\n",
            "length of actions is  185\n",
            "-24.734226381511448\n",
            "length of actions is  105\n",
            "-81.11045908022201\n",
            "length of actions is  97\n",
            "Your final reward is : 34.01\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1507])\n",
            "41.448261562854896\n",
            "length of actions is  189\n",
            "-68.85065712951543\n",
            "length of actions is  96\n",
            "64.48925870409272\n",
            "length of actions is  132\n",
            "-18.671466456109798\n",
            "length of actions is  113\n",
            "66.6733344263466\n",
            "length of actions is  181\n",
            "Your final reward is : 17.02\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1329])\n",
            "45.76885211917437\n",
            "length of actions is  186\n",
            "-11.875231906146539\n",
            "length of actions is  100\n",
            "-17.453800994752683\n",
            "length of actions is  83\n",
            "-77.33176822311077\n",
            "length of actions is  96\n",
            "-41.65116513594131\n",
            "length of actions is  73\n",
            "Your final reward is : -20.51\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1581])\n",
            "52.73475828577304\n",
            "length of actions is  195\n",
            "-31.931747754409713\n",
            "length of actions is  68\n",
            "-6.4109960596993005\n",
            "length of actions is  117\n",
            "-29.173796687136246\n",
            "length of actions is  82\n",
            "35.15507490935525\n",
            "length of actions is  133\n",
            "Your final reward is : 4.07\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1673])\n",
            "281.26336805772564\n",
            "length of actions is  267\n",
            "284.9171005100852\n",
            "length of actions is  291\n",
            "-11.131251028160918\n",
            "length of actions is  77\n",
            "28.06553889999057\n",
            "length of actions is  148\n",
            "-9.511506406712243\n",
            "length of actions is  109\n",
            "Your final reward is : 114.72\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1593])\n",
            "279.75120991096185\n",
            "length of actions is  243\n",
            "55.99161513784625\n",
            "length of actions is  121\n",
            "-12.20234147355248\n",
            "length of actions is  117\n",
            "168.57430032054347\n",
            "length of actions is  1000\n",
            "-70.90555019050834\n",
            "length of actions is  116\n",
            "Your final reward is : 84.24\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1870])\n",
            "280.17640625256075\n",
            "length of actions is  319\n",
            "-64.38970377931196\n",
            "length of actions is  81\n",
            "5.359663375255209\n",
            "length of actions is  76\n",
            "-28.271905696103772\n",
            "length of actions is  101\n",
            "49.26601234920261\n",
            "length of actions is  203\n",
            "Your final reward is : 48.43\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1581])\n",
            "279.2766279914591\n",
            "length of actions is  250\n",
            "6.615922633399322\n",
            "length of actions is  136\n",
            "-41.811510411932105\n",
            "length of actions is  98\n",
            "-71.61987632689073\n",
            "length of actions is  84\n",
            "32.65890245953898\n",
            "length of actions is  142\n",
            "Your final reward is : 41.02\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1660])\n",
            "274.7489054331785\n",
            "length of actions is  252\n",
            "-14.482813789081163\n",
            "length of actions is  102\n",
            "42.93238439912565\n",
            "length of actions is  180\n",
            "32.328244561776245\n",
            "length of actions is  157\n",
            "-13.980962949948562\n",
            "length of actions is  112\n",
            "Your final reward is : 64.31\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1577])\n",
            "275.8175528616904\n",
            "length of actions is  245\n",
            "-67.2440495144518\n",
            "length of actions is  80\n",
            "-57.75661419011618\n",
            "length of actions is  81\n",
            "45.45840120585078\n",
            "length of actions is  107\n",
            "25.541350143143532\n",
            "length of actions is  127\n",
            "Your final reward is : 44.36\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1564])\n",
            "277.0964992170708\n",
            "length of actions is  247\n",
            "295.4085453971544\n",
            "length of actions is  263\n",
            "17.323875099997267\n",
            "length of actions is  91\n",
            "54.82398177830933\n",
            "length of actions is  136\n",
            "7.350138529307557\n",
            "length of actions is  121\n",
            "Your final reward is : 130.40\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2028])\n",
            "282.88577642506516\n",
            "length of actions is  265\n",
            "284.30853027905965\n",
            "length of actions is  278\n",
            "25.318337253431366\n",
            "length of actions is  130\n",
            "-36.487312421112364\n",
            "length of actions is  81\n",
            "296.0917159523813\n",
            "length of actions is  261\n",
            "Your final reward is : 170.42\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1517])\n",
            "278.1382910932891\n",
            "length of actions is  237\n",
            "288.00049525773625\n",
            "length of actions is  236\n",
            "44.348773482857695\n",
            "length of actions is  157\n",
            "56.231104797216545\n",
            "length of actions is  179\n",
            "-39.58661729400967\n",
            "length of actions is  101\n",
            "Your final reward is : 125.43\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1225])\n",
            "282.8548061290223\n",
            "length of actions is  255\n",
            "44.64652561075354\n",
            "length of actions is  159\n",
            "47.58676309960197\n",
            "length of actions is  112\n",
            "62.180103322259555\n",
            "length of actions is  142\n",
            "49.86048422917594\n",
            "length of actions is  150\n",
            "Your final reward is : 97.43\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1211])\n",
            "280.2543406057026\n",
            "length of actions is  239\n",
            "3.134083099444112\n",
            "length of actions is  82\n",
            "284.12555556460745\n",
            "length of actions is  251\n",
            "-35.9043795600338\n",
            "length of actions is  85\n",
            "311.7249114164972\n",
            "length of actions is  233\n",
            "Your final reward is : 168.67\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1366])\n",
            "282.9136174711907\n",
            "length of actions is  246\n",
            "300.8030271185621\n",
            "length of actions is  225\n",
            "-13.274544642226303\n",
            "length of actions is  97\n",
            "17.86685636388853\n",
            "length of actions is  140\n",
            "44.55612605048654\n",
            "length of actions is  140\n",
            "Your final reward is : 126.57\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1523])\n",
            "281.40408927344185\n",
            "length of actions is  253\n",
            "-25.565976967757038\n",
            "length of actions is  94\n",
            "-10.973783779530208\n",
            "length of actions is  89\n",
            "255.65512839769417\n",
            "length of actions is  222\n",
            "42.32783815919626\n",
            "length of actions is  159\n",
            "Your final reward is : 108.57\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2500])\n",
            "270.2506079384307\n",
            "length of actions is  265\n",
            "299.6461220159591\n",
            "length of actions is  238\n",
            "-36.16317648111264\n",
            "length of actions is  124\n",
            "56.64825190885304\n",
            "length of actions is  186\n",
            "-68.44715964658462\n",
            "length of actions is  94\n",
            "Your final reward is : 104.39\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2134])\n",
            "278.8337306317183\n",
            "length of actions is  226\n",
            "73.11964904330134\n",
            "length of actions is  156\n",
            "305.5795133099748\n",
            "length of actions is  245\n",
            "52.07329647764399\n",
            "length of actions is  181\n",
            "44.58911971006569\n",
            "length of actions is  155\n",
            "Your final reward is : 150.84\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1747])\n",
            "158.31462234441176\n",
            "length of actions is  1000\n",
            "-6.805198911579723\n",
            "length of actions is  105\n",
            "9.664503148199685\n",
            "length of actions is  133\n",
            "-23.899597314121237\n",
            "length of actions is  90\n",
            "-0.711760692727978\n",
            "length of actions is  111\n",
            "Your final reward is : 27.31\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2565])\n",
            "161.7978179205581\n",
            "length of actions is  1000\n",
            "24.1279714292794\n",
            "length of actions is  113\n",
            "59.72191864181434\n",
            "length of actions is  123\n",
            "-5.297267551428419\n",
            "length of actions is  94\n",
            "-32.15854916666622\n",
            "length of actions is  100\n",
            "Your final reward is : 41.64\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2285])\n",
            "276.6033860713876\n",
            "length of actions is  236\n",
            "193.25116438280298\n",
            "length of actions is  1000\n",
            "281.5457239324859\n",
            "length of actions is  243\n",
            "23.050658160244453\n",
            "length of actions is  142\n",
            "44.31343663861338\n",
            "length of actions is  178\n",
            "Your final reward is : 163.75\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1743])\n",
            "277.6933183687305\n",
            "length of actions is  244\n",
            "45.2211272570332\n",
            "length of actions is  156\n",
            "19.892467663890656\n",
            "length of actions is  85\n",
            "156.9271363954024\n",
            "length of actions is  1000\n",
            "-8.980984457678005\n",
            "length of actions is  145\n",
            "Your final reward is : 98.15\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2335])\n",
            "276.2061452627697\n",
            "length of actions is  303\n",
            "236.57666103842158\n",
            "length of actions is  221\n",
            "67.67941064098954\n",
            "length of actions is  139\n",
            "64.12670256343364\n",
            "length of actions is  149\n",
            "68.6953916124993\n",
            "length of actions is  191\n",
            "Your final reward is : 142.66\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3727])\n",
            "280.53007558423053\n",
            "length of actions is  250\n",
            "134.38329700609376\n",
            "length of actions is  1000\n",
            "18.454662372761305\n",
            "length of actions is  148\n",
            "43.59805778157744\n",
            "length of actions is  180\n",
            "-41.562427730176054\n",
            "length of actions is  102\n",
            "Your final reward is : 87.08\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1904])\n",
            "170.70870369390911\n",
            "length of actions is  1000\n",
            "224.6397545571881\n",
            "length of actions is  200\n",
            "-11.326293095987893\n",
            "length of actions is  76\n",
            "247.86257426623374\n",
            "length of actions is  259\n",
            "69.68041591626479\n",
            "length of actions is  170\n",
            "Your final reward is : 140.31\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2080])\n",
            "168.3487090043656\n",
            "length of actions is  1000\n",
            "4.749481118471891\n",
            "length of actions is  112\n",
            "229.61969817079174\n",
            "length of actions is  339\n",
            "-42.19251118661806\n",
            "length of actions is  82\n",
            "0.29366854789398644\n",
            "length of actions is  83\n",
            "Your final reward is : 72.16\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1944])\n",
            "281.4724759387358\n",
            "length of actions is  244\n",
            "53.37215710898542\n",
            "length of actions is  156\n",
            "245.5052153829563\n",
            "length of actions is  168\n",
            "28.850156328168993\n",
            "length of actions is  147\n",
            "64.48109635008689\n",
            "length of actions is  178\n",
            "Your final reward is : 134.74\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2458])\n",
            "277.6470546054462\n",
            "length of actions is  343\n",
            "56.060376806531906\n",
            "length of actions is  177\n",
            "276.4401074026575\n",
            "length of actions is  274\n",
            "251.73880128406225\n",
            "length of actions is  238\n",
            "-8.409002585692491\n",
            "length of actions is  140\n",
            "Your final reward is : 170.70\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2173])\n",
            "55.13392507958716\n",
            "length of actions is  183\n",
            "154.13613866465823\n",
            "length of actions is  1000\n",
            "44.04263579058221\n",
            "length of actions is  149\n",
            "292.4472264893866\n",
            "length of actions is  240\n",
            "244.13394901608993\n",
            "length of actions is  228\n",
            "Your final reward is : 157.98\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3959])\n",
            "279.3682770911553\n",
            "length of actions is  267\n",
            "282.0240874434697\n",
            "length of actions is  256\n",
            "195.903908939622\n",
            "length of actions is  512\n",
            "201.76307191961587\n",
            "length of actions is  374\n",
            "235.2082593304225\n",
            "length of actions is  419\n",
            "Your final reward is : 238.85\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2720])\n",
            "145.05387271429078\n",
            "length of actions is  1000\n",
            "210.90966282723184\n",
            "length of actions is  522\n",
            "127.22079709739165\n",
            "length of actions is  1000\n",
            "164.8445373553992\n",
            "length of actions is  1000\n",
            "172.15201374872345\n",
            "length of actions is  1000\n",
            "Your final reward is : 164.04\n",
            "torch.from_numpy(rewards) looks like  torch.Size([5113])\n",
            "49.10145065535761\n",
            "length of actions is  184\n",
            "64.46000075448472\n",
            "length of actions is  152\n",
            "285.2112370699778\n",
            "length of actions is  261\n",
            "72.6594458895776\n",
            "length of actions is  1000\n",
            "221.42279143007943\n",
            "length of actions is  203\n",
            "Your final reward is : 138.57\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3122])\n",
            "281.9220302381408\n",
            "length of actions is  248\n",
            "166.23430876116015\n",
            "length of actions is  607\n",
            "200.09774366481602\n",
            "length of actions is  394\n",
            "200.91116389770434\n",
            "length of actions is  564\n",
            "275.46473239579416\n",
            "length of actions is  229\n",
            "Your final reward is : 224.93\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3577])\n",
            "281.1246825154065\n",
            "length of actions is  261\n",
            "229.69579288936185\n",
            "length of actions is  252\n",
            "282.9849814027731\n",
            "length of actions is  261\n",
            "54.50429846946321\n",
            "length of actions is  178\n",
            "26.73517233046205\n",
            "length of actions is  151\n",
            "Your final reward is : 175.01\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2621])\n",
            "282.84166380015074\n",
            "length of actions is  247\n",
            "64.93612597697205\n",
            "length of actions is  159\n",
            "271.4287936682931\n",
            "length of actions is  238\n",
            "254.16050477565548\n",
            "length of actions is  333\n",
            "224.00883149013157\n",
            "length of actions is  670\n",
            "Your final reward is : 219.48\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2742])\n",
            "158.60640314845486\n",
            "length of actions is  1000\n",
            "230.46978618787193\n",
            "length of actions is  695\n",
            "123.91631627387298\n",
            "length of actions is  1000\n",
            "258.938100386266\n",
            "length of actions is  220\n",
            "225.76151839323884\n",
            "length of actions is  578\n",
            "Your final reward is : 199.54\n",
            "torch.from_numpy(rewards) looks like  torch.Size([4536])\n",
            "159.13487050421801\n",
            "length of actions is  1000\n",
            "236.48475996408905\n",
            "length of actions is  198\n",
            "126.9895346150236\n",
            "length of actions is  1000\n",
            "13.95920576013151\n",
            "length of actions is  160\n",
            "271.53996550949563\n",
            "length of actions is  214\n",
            "Your final reward is : 161.62\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3296])\n",
            "278.1852223325754\n",
            "length of actions is  228\n",
            "170.54102731365714\n",
            "length of actions is  561\n",
            "173.45406133231177\n",
            "length of actions is  1000\n",
            "131.98233669733094\n",
            "length of actions is  1000\n",
            "-169.4894403340349\n",
            "length of actions is  363\n",
            "Your final reward is : 116.93\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2906])\n",
            "277.7475164310908\n",
            "length of actions is  241\n",
            "41.239296714726805\n",
            "length of actions is  136\n",
            "152.46187510516714\n",
            "length of actions is  504\n",
            "4.805226742158737\n",
            "length of actions is  194\n",
            "298.35280556563214\n",
            "length of actions is  265\n",
            "Your final reward is : 154.92\n",
            "torch.from_numpy(rewards) looks like  torch.Size([4880])\n",
            "170.15519248457016\n",
            "length of actions is  1000\n",
            "11.102900326219086\n",
            "length of actions is  141\n",
            "83.90243141901124\n",
            "length of actions is  173\n",
            "289.7196728249414\n",
            "length of actions is  249\n",
            "69.32588365839024\n",
            "length of actions is  169\n",
            "Your final reward is : 124.84\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2601])\n",
            "277.33957156477334\n",
            "length of actions is  264\n",
            "21.931985205594884\n",
            "length of actions is  208\n",
            "12.648603450979621\n",
            "length of actions is  172\n",
            "272.7837905495595\n",
            "length of actions is  208\n",
            "42.18927528819967\n",
            "length of actions is  156\n",
            "Your final reward is : 125.38\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2694])\n",
            "279.5082380844606\n",
            "length of actions is  234\n",
            "23.71568259368557\n",
            "length of actions is  197\n",
            "24.859517391370318\n",
            "length of actions is  196\n",
            "62.001074224448985\n",
            "length of actions is  186\n",
            "12.168184181916729\n",
            "length of actions is  182\n",
            "Your final reward is : 80.45\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2076])\n",
            "277.33369183159925\n",
            "length of actions is  241\n",
            "41.33703072872626\n",
            "length of actions is  142\n",
            "44.245023069183674\n",
            "length of actions is  178\n",
            "255.2201229472401\n",
            "length of actions is  254\n",
            "133.88068160210713\n",
            "length of actions is  1000\n",
            "Your final reward is : 150.40\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2968])\n",
            "275.311829464352\n",
            "length of actions is  233\n",
            "-174.07585671773936\n",
            "length of actions is  181\n",
            "46.006534589993095\n",
            "length of actions is  144\n",
            "-171.03966421558016\n",
            "length of actions is  219\n",
            "133.31158553216522\n",
            "length of actions is  1000\n",
            "Your final reward is : 21.90\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3248])\n",
            "277.3891979133708\n",
            "length of actions is  228\n",
            "43.17730413499572\n",
            "length of actions is  196\n",
            "263.6196706649008\n",
            "length of actions is  256\n",
            "288.127491683024\n",
            "length of actions is  239\n",
            "56.20016414850713\n",
            "length of actions is  191\n",
            "Your final reward is : 185.70\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2643])\n",
            "277.8562710153491\n",
            "length of actions is  233\n",
            "286.84540912314924\n",
            "length of actions is  266\n",
            "300.39181518396487\n",
            "length of actions is  539\n",
            "303.33607451846933\n",
            "length of actions is  454\n",
            "65.71686867150515\n",
            "length of actions is  134\n",
            "Your final reward is : 246.83\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2924])\n",
            "273.9250056891923\n",
            "length of actions is  238\n",
            "255.86886650131473\n",
            "length of actions is  240\n",
            "257.16021398674206\n",
            "length of actions is  216\n",
            "40.33884657936355\n",
            "length of actions is  192\n",
            "62.320339761076326\n",
            "length of actions is  145\n",
            "Your final reward is : 177.92\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2306])\n",
            "276.8661403118019\n",
            "length of actions is  242\n",
            "75.08615464351627\n",
            "length of actions is  143\n",
            "236.45187774014738\n",
            "length of actions is  462\n",
            "155.06639037520347\n",
            "length of actions is  1000\n",
            "265.1395988272956\n",
            "length of actions is  219\n",
            "Your final reward is : 201.72\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2208])\n",
            "255.90780692249416\n",
            "length of actions is  490\n",
            "310.82322235027766\n",
            "length of actions is  226\n",
            "256.62332063577526\n",
            "length of actions is  219\n",
            "289.59872423350635\n",
            "length of actions is  250\n",
            "314.48084320200076\n",
            "length of actions is  201\n",
            "Your final reward is : 285.49\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2306])\n",
            "280.2542291378097\n",
            "length of actions is  241\n",
            "272.0637278443743\n",
            "length of actions is  200\n",
            "268.7111525590765\n",
            "length of actions is  291\n",
            "244.18183414969303\n",
            "length of actions is  418\n",
            "291.3233544742966\n",
            "length of actions is  226\n",
            "Your final reward is : 271.31\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2399])\n",
            "274.49514080759343\n",
            "length of actions is  245\n",
            "67.76336622920866\n",
            "length of actions is  188\n",
            "280.84066146729583\n",
            "length of actions is  186\n",
            "44.63729246244276\n",
            "length of actions is  200\n",
            "257.07544674803063\n",
            "length of actions is  196\n",
            "Your final reward is : 184.96\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2396])\n",
            "275.5873013039036\n",
            "length of actions is  240\n",
            "48.563723442296464\n",
            "length of actions is  186\n",
            "281.30133661806553\n",
            "length of actions is  174\n",
            "259.8036688692706\n",
            "length of actions is  212\n",
            "299.7454163039961\n",
            "length of actions is  260\n",
            "Your final reward is : 233.00\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2393])\n",
            "274.58986340801573\n",
            "length of actions is  225\n",
            "305.29025001000934\n",
            "length of actions is  285\n",
            "290.0264755750537\n",
            "length of actions is  219\n",
            "292.3375878113783\n",
            "length of actions is  255\n",
            "278.9909791429511\n",
            "length of actions is  220\n",
            "Your final reward is : 288.25\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2234])\n",
            "271.9429945885747\n",
            "length of actions is  250\n",
            "247.01999110505005\n",
            "length of actions is  179\n",
            "269.6171067303158\n",
            "length of actions is  199\n",
            "268.5284946072916\n",
            "length of actions is  249\n",
            "307.9092268509593\n",
            "length of actions is  223\n",
            "Your final reward is : 273.00\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2745])\n",
            "274.5561908371918\n",
            "length of actions is  227\n",
            "52.60707950553652\n",
            "length of actions is  182\n",
            "147.6454109228767\n",
            "length of actions is  1000\n",
            "268.15606675753145\n",
            "length of actions is  236\n",
            "275.999284939563\n",
            "length of actions is  235\n",
            "Your final reward is : 203.79\n",
            "torch.from_numpy(rewards) looks like  torch.Size([4308])\n",
            "273.26867216449216\n",
            "length of actions is  221\n",
            "259.13275514980944\n",
            "length of actions is  197\n",
            "217.032745785388\n",
            "length of actions is  442\n",
            "276.08710327351537\n",
            "length of actions is  180\n",
            "282.1884008098748\n",
            "length of actions is  234\n",
            "Your final reward is : 261.54\n",
            "torch.from_numpy(rewards) looks like  torch.Size([6792])\n",
            "207.40730514273997\n",
            "length of actions is  638\n",
            "189.42471114686938\n",
            "length of actions is  1000\n",
            "132.42365933446797\n",
            "length of actions is  1000\n",
            "261.4326135833296\n",
            "length of actions is  297\n",
            "109.11442833820118\n",
            "length of actions is  871\n",
            "Your final reward is : 179.96\n",
            "torch.from_numpy(rewards) looks like  torch.Size([4947])\n",
            "263.8877169665341\n",
            "length of actions is  257\n",
            "227.93221521799143\n",
            "length of actions is  412\n",
            "317.3223565124761\n",
            "length of actions is  213\n",
            "289.7071060236335\n",
            "length of actions is  283\n",
            "-36.558317559594734\n",
            "length of actions is  1000\n",
            "Your final reward is : 212.46\n",
            "torch.from_numpy(rewards) looks like  torch.Size([4928])\n",
            "265.3369502015709\n",
            "length of actions is  244\n",
            "254.3335631119187\n",
            "length of actions is  269\n",
            "159.73584019163704\n",
            "length of actions is  1000\n",
            "253.7989060068108\n",
            "length of actions is  211\n",
            "253.56939008371467\n",
            "length of actions is  294\n",
            "Your final reward is : 237.35\n",
            "torch.from_numpy(rewards) looks like  torch.Size([6452])\n",
            "156.05580571010728\n",
            "length of actions is  1000\n",
            "112.84410939201821\n",
            "length of actions is  1000\n",
            "227.0762638494346\n",
            "length of actions is  662\n",
            "157.1277968258751\n",
            "length of actions is  1000\n",
            "125.58540772446052\n",
            "length of actions is  1000\n",
            "Your final reward is : 155.74\n",
            "torch.from_numpy(rewards) looks like  torch.Size([4619])\n",
            "158.86786099107698\n",
            "length of actions is  1000\n",
            "186.8673262032516\n",
            "length of actions is  570\n",
            "270.04474396668536\n",
            "length of actions is  213\n",
            "215.48221335906385\n",
            "length of actions is  507\n",
            "-6.629407404282825\n",
            "length of actions is  1000\n",
            "Your final reward is : 164.93\n",
            "torch.from_numpy(rewards) looks like  torch.Size([4073])\n",
            "47.477575027693604\n",
            "length of actions is  150\n",
            "56.89473964853897\n",
            "length of actions is  182\n",
            "44.557775722960685\n",
            "length of actions is  136\n",
            "97.87753154797285\n",
            "length of actions is  1000\n",
            "108.9562608514413\n",
            "length of actions is  1000\n",
            "Your final reward is : 71.15\n",
            "torch.from_numpy(rewards) looks like  torch.Size([4109])\n",
            "159.64521368309877\n",
            "length of actions is  1000\n",
            "220.9645505496557\n",
            "length of actions is  356\n",
            "157.35529316104612\n",
            "length of actions is  1000\n",
            "283.4965410123827\n",
            "length of actions is  211\n",
            "290.0027016080414\n",
            "length of actions is  322\n",
            "Your final reward is : 222.29\n",
            "torch.from_numpy(rewards) looks like  torch.Size([4784])\n",
            "263.916116063637\n",
            "length of actions is  207\n",
            "199.18164388235147\n",
            "length of actions is  501\n",
            "62.13590489814095\n",
            "length of actions is  102\n",
            "294.63888413749385\n",
            "length of actions is  252\n",
            "268.631080186727\n",
            "length of actions is  212\n",
            "Your final reward is : 217.70\n",
            "torch.from_numpy(rewards) looks like  torch.Size([4091])\n",
            "50.4885028931929\n",
            "length of actions is  146\n",
            "176.432627397018\n",
            "length of actions is  623\n",
            "307.85404119448384\n",
            "length of actions is  276\n",
            "211.30172394066753\n",
            "length of actions is  546\n",
            "271.8405281968668\n",
            "length of actions is  391\n",
            "Your final reward is : 203.58\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3610])\n",
            "256.2715050495692\n",
            "length of actions is  185\n",
            "187.5288593021964\n",
            "length of actions is  588\n",
            "281.37048966508087\n",
            "length of actions is  227\n",
            "36.32756026530248\n",
            "length of actions is  104\n",
            "289.5386903607607\n",
            "length of actions is  244\n",
            "Your final reward is : 210.21\n",
            "torch.from_numpy(rewards) looks like  torch.Size([4140])\n",
            "259.72293629939696\n",
            "length of actions is  182\n",
            "142.86951484769395\n",
            "length of actions is  916\n",
            "43.99115059697607\n",
            "length of actions is  127\n",
            "243.01340191726908\n",
            "length of actions is  344\n",
            "106.91590613995892\n",
            "length of actions is  931\n",
            "Your final reward is : 159.30\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3274])\n",
            "143.41453589367825\n",
            "length of actions is  1000\n",
            "187.4733125484936\n",
            "length of actions is  537\n",
            "244.45317213646172\n",
            "length of actions is  354\n",
            "205.90524300760993\n",
            "length of actions is  430\n",
            "184.53561760019517\n",
            "length of actions is  520\n",
            "Your final reward is : 193.16\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3161])\n",
            "260.18688108904115\n",
            "length of actions is  192\n",
            "250.39309188571127\n",
            "length of actions is  161\n",
            "223.46576941433682\n",
            "length of actions is  361\n",
            "254.55582861147178\n",
            "length of actions is  325\n",
            "243.37070559877787\n",
            "length of actions is  360\n",
            "Your final reward is : 246.39\n",
            "torch.from_numpy(rewards) looks like  torch.Size([4571])\n",
            "251.70964422788978\n",
            "length of actions is  179\n",
            "213.78434970590297\n",
            "length of actions is  345\n",
            "232.5752060371938\n",
            "length of actions is  402\n",
            "227.14023142021384\n",
            "length of actions is  448\n",
            "180.49425494709683\n",
            "length of actions is  463\n",
            "Your final reward is : 221.14\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3412])\n",
            "218.13244056113598\n",
            "length of actions is  349\n",
            "69.41952266294248\n",
            "length of actions is  145\n",
            "253.12377430371072\n",
            "length of actions is  409\n",
            "230.99391008260784\n",
            "length of actions is  482\n",
            "231.13927106694277\n",
            "length of actions is  464\n",
            "Your final reward is : 200.56\n",
            "torch.from_numpy(rewards) looks like  torch.Size([4652])\n",
            "248.6581235508998\n",
            "length of actions is  253\n",
            "153.67011491307824\n",
            "length of actions is  1000\n",
            "159.25670334770265\n",
            "length of actions is  1000\n",
            "178.85102639537223\n",
            "length of actions is  1000\n",
            "218.57655906395203\n",
            "length of actions is  351\n",
            "Your final reward is : 191.80\n",
            "torch.from_numpy(rewards) looks like  torch.Size([4483])\n",
            "222.4696709882714\n",
            "length of actions is  312\n",
            "281.61558348246376\n",
            "length of actions is  213\n",
            "207.4703409904219\n",
            "length of actions is  571\n",
            "287.5980381058002\n",
            "length of actions is  303\n",
            "309.8760610071927\n",
            "length of actions is  185\n",
            "Your final reward is : 261.81\n",
            "torch.from_numpy(rewards) looks like  torch.Size([6267])\n",
            "29.228486453211502\n",
            "length of actions is  115\n",
            "208.9808101511031\n",
            "length of actions is  1000\n",
            "168.22420928649447\n",
            "length of actions is  1000\n",
            "286.3005742664649\n",
            "length of actions is  180\n",
            "279.68753834153387\n",
            "length of actions is  227\n",
            "Your final reward is : 194.48\n",
            "torch.from_numpy(rewards) looks like  torch.Size([5716])\n",
            "220.45252127776655\n",
            "length of actions is  304\n",
            "282.78647105588107\n",
            "length of actions is  222\n",
            "143.36165550895518\n",
            "length of actions is  1000\n",
            "126.63004836802055\n",
            "length of actions is  1000\n",
            "255.34389763024808\n",
            "length of actions is  485\n",
            "Your final reward is : 205.71\n",
            "torch.from_numpy(rewards) looks like  torch.Size([6829])\n",
            "229.55405504727253\n",
            "length of actions is  260\n",
            "130.76084396387273\n",
            "length of actions is  1000\n",
            "-10.056071750881031\n",
            "length of actions is  255\n",
            "151.80411506636148\n",
            "length of actions is  1000\n",
            "70.20212950935937\n",
            "length of actions is  144\n",
            "Your final reward is : 114.45\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3019])\n",
            "241.025703512101\n",
            "length of actions is  220\n",
            "274.475073807615\n",
            "length of actions is  182\n",
            "-22.73666983384714\n",
            "length of actions is  1000\n",
            "-7.989636783616082\n",
            "length of actions is  1000\n",
            "-9.688207265122434\n",
            "length of actions is  1000\n",
            "Your final reward is : 95.02\n",
            "torch.from_numpy(rewards) looks like  torch.Size([5043])\n",
            "261.15089512213143\n",
            "length of actions is  176\n",
            "38.56483524367482\n",
            "length of actions is  87\n",
            "160.8498682815706\n",
            "length of actions is  1000\n",
            "128.10611204207507\n",
            "length of actions is  1000\n",
            "280.5540956282574\n",
            "length of actions is  157\n",
            "Your final reward is : 173.85\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3259])\n",
            "248.3298975027405\n",
            "length of actions is  198\n",
            "285.18339341032697\n",
            "length of actions is  285\n",
            "286.8972833559401\n",
            "length of actions is  186\n",
            "274.9579830461259\n",
            "length of actions is  207\n",
            "271.25291805365566\n",
            "length of actions is  381\n",
            "Your final reward is : 273.32\n",
            "torch.from_numpy(rewards) looks like  torch.Size([4275])\n",
            "260.64784081342015\n",
            "length of actions is  169\n",
            "286.74009806353615\n",
            "length of actions is  150\n",
            "30.022612388809364\n",
            "length of actions is  85\n",
            "251.75311521775143\n",
            "length of actions is  182\n",
            "167.35866328606255\n",
            "length of actions is  1000\n",
            "Your final reward is : 199.30\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1906])\n",
            "239.097954874176\n",
            "length of actions is  254\n",
            "-175.42229882154626\n",
            "length of actions is  479\n",
            "63.000091298824685\n",
            "length of actions is  141\n",
            "190.46862792108658\n",
            "length of actions is  530\n",
            "243.77589520922794\n",
            "length of actions is  157\n",
            "Your final reward is : 112.18\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2234])\n",
            "256.6008166866528\n",
            "length of actions is  168\n",
            "209.4941673513606\n",
            "length of actions is  382\n",
            "38.61789009718322\n",
            "length of actions is  139\n",
            "4.022504070444512\n",
            "length of actions is  94\n",
            "249.65574987079447\n",
            "length of actions is  143\n",
            "Your final reward is : 151.68\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3063])\n",
            "258.1837212784835\n",
            "length of actions is  166\n",
            "223.54351316360598\n",
            "length of actions is  344\n",
            "73.4641710357883\n",
            "length of actions is  120\n",
            "18.26525974936311\n",
            "length of actions is  103\n",
            "287.26862584957826\n",
            "length of actions is  245\n",
            "Your final reward is : 172.15\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2418])\n",
            "196.2353088805259\n",
            "length of actions is  321\n",
            "5.876309734849642\n",
            "length of actions is  93\n",
            "151.67225823786413\n",
            "length of actions is  1000\n",
            "155.04449220230873\n",
            "length of actions is  1000\n",
            "150.8996558159298\n",
            "length of actions is  1000\n",
            "Your final reward is : 131.95\n",
            "torch.from_numpy(rewards) looks like  torch.Size([4066])\n",
            "-56.0073800538688\n",
            "length of actions is  267\n",
            "217.96402595025984\n",
            "length of actions is  393\n",
            "53.07869031303554\n",
            "length of actions is  150\n",
            "31.023881472640284\n",
            "length of actions is  126\n",
            "171.46327738816274\n",
            "length of actions is  461\n",
            "Your final reward is : 83.50\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2288])\n",
            "58.87188315431733\n",
            "length of actions is  1000\n",
            "130.32184711246535\n",
            "length of actions is  1000\n",
            "221.87083082197512\n",
            "length of actions is  549\n",
            "50.19812390762698\n",
            "length of actions is  142\n",
            "271.17754268874285\n",
            "length of actions is  179\n",
            "Your final reward is : 146.49\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2124])\n",
            "60.14238905129159\n",
            "length of actions is  1000\n",
            "255.18879573060013\n",
            "length of actions is  176\n",
            "51.210524452001465\n",
            "length of actions is  138\n",
            "243.52314956985776\n",
            "length of actions is  227\n",
            "45.52519490272289\n",
            "length of actions is  151\n",
            "Your final reward is : 131.12\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2533])\n",
            "229.0716123217578\n",
            "length of actions is  221\n",
            "95.46615844815925\n",
            "length of actions is  1000\n",
            "41.27252505587151\n",
            "length of actions is  82\n",
            "58.142629727480454\n",
            "length of actions is  138\n",
            "35.26619647675102\n",
            "length of actions is  107\n",
            "Your final reward is : 91.84\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1281])\n",
            "220.07739000692106\n",
            "length of actions is  230\n",
            "7.022427410529403\n",
            "length of actions is  102\n",
            "-11.216134737350018\n",
            "length of actions is  77\n",
            "266.05180659784605\n",
            "length of actions is  261\n",
            "268.37776061663766\n",
            "length of actions is  521\n",
            "Your final reward is : 150.06\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2400])\n",
            "243.98120273591613\n",
            "length of actions is  193\n",
            "66.80550199707505\n",
            "length of actions is  146\n",
            "211.47036782123925\n",
            "length of actions is  325\n",
            "141.4767969363063\n",
            "length of actions is  1000\n",
            "48.185916554418384\n",
            "length of actions is  116\n",
            "Your final reward is : 142.38\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2915])\n",
            "36.91203674932348\n",
            "length of actions is  157\n",
            "31.608169568630274\n",
            "length of actions is  134\n",
            "51.14726541560441\n",
            "length of actions is  121\n",
            "245.98788210685873\n",
            "length of actions is  227\n",
            "-4.897155914004458\n",
            "length of actions is  76\n",
            "Your final reward is : 72.15\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2797])\n",
            "243.68621287553364\n",
            "length of actions is  193\n",
            "82.40550453549699\n",
            "length of actions is  152\n",
            "25.067411098811462\n",
            "length of actions is  116\n",
            "222.525992615528\n",
            "length of actions is  231\n",
            "66.77227587415823\n",
            "length of actions is  87\n",
            "Your final reward is : 128.09\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3057])\n",
            "20.67163072076876\n",
            "length of actions is  151\n",
            "45.94595004349412\n",
            "length of actions is  119\n",
            "55.28969526003212\n",
            "length of actions is  124\n",
            "153.95939979032255\n",
            "length of actions is  1000\n",
            "96.50851272176936\n",
            "length of actions is  1000\n",
            "Your final reward is : 74.48\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2020])\n",
            "214.35859120580727\n",
            "length of actions is  230\n",
            "9.598450161881985\n",
            "length of actions is  102\n",
            "-18.39131294586251\n",
            "length of actions is  77\n",
            "274.5900185608292\n",
            "length of actions is  190\n",
            "40.60441873003171\n",
            "length of actions is  132\n",
            "Your final reward is : 104.15\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2662])\n",
            "212.70520095023053\n",
            "length of actions is  240\n",
            "53.6338749386814\n",
            "length of actions is  135\n",
            "283.67484533745085\n",
            "length of actions is  192\n",
            "43.37412113721251\n",
            "length of actions is  147\n",
            "54.680839753695466\n",
            "length of actions is  148\n",
            "Your final reward is : 129.61\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2850])\n",
            "218.27085498782998\n",
            "length of actions is  222\n",
            "48.9196097402984\n",
            "length of actions is  143\n",
            "276.28018008699166\n",
            "length of actions is  170\n",
            "42.09318999740992\n",
            "length of actions is  147\n",
            "59.78096568202298\n",
            "length of actions is  114\n",
            "Your final reward is : 129.07\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2433])\n",
            "174.08520280302156\n",
            "length of actions is  772\n",
            "262.9189698109916\n",
            "length of actions is  192\n",
            "32.09792791887568\n",
            "length of actions is  100\n",
            "257.8705874244978\n",
            "length of actions is  200\n",
            "4.400055429975325\n",
            "length of actions is  113\n",
            "Your final reward is : 146.27\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1691])\n",
            "36.38491021601803\n",
            "length of actions is  155\n",
            "260.3081285833554\n",
            "length of actions is  497\n",
            "283.57161549883165\n",
            "length of actions is  157\n",
            "238.3009694222481\n",
            "length of actions is  284\n",
            "118.80215300894261\n",
            "length of actions is  1000\n",
            "Your final reward is : 187.47\n",
            "torch.from_numpy(rewards) looks like  torch.Size([4040])\n",
            "153.01307021568005\n",
            "length of actions is  991\n",
            "261.76085277626544\n",
            "length of actions is  193\n",
            "79.51414626712463\n",
            "length of actions is  177\n",
            "125.00217835058965\n",
            "length of actions is  1000\n",
            "102.0061622344576\n",
            "length of actions is  1000\n",
            "Your final reward is : 144.26\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2689])\n",
            "236.80391828723162\n",
            "length of actions is  206\n",
            "5.244105220010766\n",
            "length of actions is  97\n",
            "268.9517599110005\n",
            "length of actions is  197\n",
            "242.31630410462083\n",
            "length of actions is  223\n",
            "42.671298112319306\n",
            "length of actions is  123\n",
            "Your final reward is : 159.20\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1998])\n",
            "7.338967082242192\n",
            "length of actions is  168\n",
            "220.32321857591506\n",
            "length of actions is  309\n",
            "-187.56367974048612\n",
            "length of actions is  218\n",
            "234.43571892882056\n",
            "length of actions is  214\n",
            "258.9912027317204\n",
            "length of actions is  225\n",
            "Your final reward is : 106.71\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2487])\n",
            "-0.24963725147796367\n",
            "length of actions is  168\n",
            "230.33826791179257\n",
            "length of actions is  235\n",
            "74.50671281272352\n",
            "length of actions is  116\n",
            "266.48887962145886\n",
            "length of actions is  195\n",
            "51.19408131764541\n",
            "length of actions is  153\n",
            "Your final reward is : 124.46\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3014])\n",
            "212.51721636914976\n",
            "length of actions is  233\n",
            "57.016602140940165\n",
            "length of actions is  132\n",
            "170.79230647615339\n",
            "length of actions is  1000\n",
            "263.87131527958854\n",
            "length of actions is  223\n",
            "150.8526006040552\n",
            "length of actions is  1000\n",
            "Your final reward is : 171.01\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2742])\n",
            "230.75860573795305\n",
            "length of actions is  216\n",
            "237.47073250871475\n",
            "length of actions is  195\n",
            "46.84507803215453\n",
            "length of actions is  135\n",
            "130.56414644009885\n",
            "length of actions is  1000\n",
            "50.080038241337235\n",
            "length of actions is  226\n",
            "Your final reward is : 139.14\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3526])\n",
            "20.010639410175074\n",
            "length of actions is  168\n",
            "225.76224961200415\n",
            "length of actions is  280\n",
            "269.5082810606059\n",
            "length of actions is  208\n",
            "68.56991218938808\n",
            "length of actions is  137\n",
            "229.88123416470987\n",
            "length of actions is  270\n",
            "Your final reward is : 162.75\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1782])\n",
            "8.951286303763155\n",
            "length of actions is  171\n",
            "254.29399866508874\n",
            "length of actions is  243\n",
            "285.98281841523294\n",
            "length of actions is  161\n",
            "48.718030902576885\n",
            "length of actions is  130\n",
            "42.916420401746905\n",
            "length of actions is  149\n",
            "Your final reward is : 128.17\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2042])\n",
            "215.34229787954268\n",
            "length of actions is  240\n",
            "298.6953081622429\n",
            "length of actions is  189\n",
            "277.01426975464955\n",
            "length of actions is  172\n",
            "257.8037122423111\n",
            "length of actions is  218\n",
            "259.95512332536\n",
            "length of actions is  152\n",
            "Your final reward is : 261.76\n",
            "torch.from_numpy(rewards) looks like  torch.Size([4408])\n",
            "1.7205048800969394\n",
            "length of actions is  173\n",
            "151.77400810560488\n",
            "length of actions is  1000\n",
            "153.8922230085487\n",
            "length of actions is  1000\n",
            "223.0750234308424\n",
            "length of actions is  500\n",
            "297.0781249054349\n",
            "length of actions is  229\n",
            "Your final reward is : 165.51\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2485])\n",
            "17.204080788953206\n",
            "length of actions is  167\n",
            "72.11624459475769\n",
            "length of actions is  125\n",
            "218.60662028173863\n",
            "length of actions is  350\n",
            "77.17271294648583\n",
            "length of actions is  126\n",
            "222.8258251992265\n",
            "length of actions is  266\n",
            "Your final reward is : 121.59\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2941])\n",
            "233.51756568298393\n",
            "length of actions is  251\n",
            "252.38051360796663\n",
            "length of actions is  172\n",
            "1.0966392391677147\n",
            "length of actions is  116\n",
            "51.754813844155336\n",
            "length of actions is  133\n",
            "257.78505753642696\n",
            "length of actions is  279\n",
            "Your final reward is : 159.31\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2037])\n",
            "226.1844554570714\n",
            "length of actions is  244\n",
            "147.69187492725786\n",
            "length of actions is  1000\n",
            "63.521947490940676\n",
            "length of actions is  145\n",
            "56.613234224734924\n",
            "length of actions is  170\n",
            "119.2129916890719\n",
            "length of actions is  1000\n",
            "Your final reward is : 122.64\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2445])\n",
            "0.557089581961904\n",
            "length of actions is  215\n",
            "85.30567448540052\n",
            "length of actions is  119\n",
            "241.20493403645193\n",
            "length of actions is  182\n",
            "284.96568710199085\n",
            "length of actions is  147\n",
            "31.448644787712055\n",
            "length of actions is  122\n",
            "Your final reward is : 128.70\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2262])\n",
            "227.46108327664638\n",
            "length of actions is  289\n",
            "60.6012406043275\n",
            "length of actions is  152\n",
            "64.00257530884966\n",
            "length of actions is  159\n",
            "43.651120505506924\n",
            "length of actions is  126\n",
            "211.01389634875267\n",
            "length of actions is  248\n",
            "Your final reward is : 121.35\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3467])\n",
            "246.25208510277955\n",
            "length of actions is  221\n",
            "217.92091640435592\n",
            "length of actions is  382\n",
            "257.09415232598406\n",
            "length of actions is  150\n",
            "277.38000416936563\n",
            "length of actions is  206\n",
            "231.60841901957187\n",
            "length of actions is  244\n",
            "Your final reward is : 246.05\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2161])\n",
            "-22.513497118009255\n",
            "length of actions is  227\n",
            "228.02311652248818\n",
            "length of actions is  855\n",
            "261.63825392864146\n",
            "length of actions is  229\n",
            "73.80682595877389\n",
            "length of actions is  206\n",
            "52.49513074139807\n",
            "length of actions is  121\n",
            "Your final reward is : 118.69\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3182])\n",
            "141.83089338621159\n",
            "length of actions is  1000\n",
            "252.98534208527533\n",
            "length of actions is  200\n",
            "45.73039578060255\n",
            "length of actions is  127\n",
            "235.20974623017466\n",
            "length of actions is  395\n",
            "57.527140511661884\n",
            "length of actions is  137\n",
            "Your final reward is : 146.66\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3567])\n",
            "197.49602752921385\n",
            "length of actions is  334\n",
            "54.18114060036487\n",
            "length of actions is  128\n",
            "274.3648321045153\n",
            "length of actions is  183\n",
            "232.70105438797802\n",
            "length of actions is  687\n",
            "40.6650994154748\n",
            "length of actions is  142\n",
            "Your final reward is : 159.88\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3618])\n",
            "241.40109320438265\n",
            "length of actions is  226\n",
            "165.6801575009918\n",
            "length of actions is  1000\n",
            "119.75750854930621\n",
            "length of actions is  1000\n",
            "255.00265637678905\n",
            "length of actions is  221\n",
            "292.3355697226415\n",
            "length of actions is  192\n",
            "Your final reward is : 214.84\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3492])\n",
            "247.23585342926518\n",
            "length of actions is  207\n",
            "139.50758614422725\n",
            "length of actions is  1000\n",
            "135.66208255392255\n",
            "length of actions is  1000\n",
            "222.43161078380479\n",
            "length of actions is  280\n",
            "283.51338411518725\n",
            "length of actions is  263\n",
            "Your final reward is : 205.67\n",
            "torch.from_numpy(rewards) looks like  torch.Size([5239])\n",
            "213.57863854593663\n",
            "length of actions is  292\n",
            "126.44662885731772\n",
            "length of actions is  1000\n",
            "29.567665561118247\n",
            "length of actions is  152\n",
            "250.13183757535504\n",
            "length of actions is  197\n",
            "29.477964465645613\n",
            "length of actions is  144\n",
            "Your final reward is : 129.84\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3868])\n",
            "212.4312802081666\n",
            "length of actions is  308\n",
            "261.1254561876527\n",
            "length of actions is  262\n",
            "144.41749536966256\n",
            "length of actions is  1000\n",
            "286.2222881302473\n",
            "length of actions is  197\n",
            "15.464431105469785\n",
            "length of actions is  167\n",
            "Your final reward is : 183.93\n",
            "torch.from_numpy(rewards) looks like  torch.Size([4738])\n",
            "152.6360794389428\n",
            "length of actions is  1000\n",
            "123.42278228328435\n",
            "length of actions is  1000\n",
            "243.3607725017774\n",
            "length of actions is  355\n",
            "141.791230696474\n",
            "length of actions is  1000\n",
            "247.92661598945526\n",
            "length of actions is  228\n",
            "Your final reward is : 181.83\n",
            "torch.from_numpy(rewards) looks like  torch.Size([6046])\n",
            "159.45633315252448\n",
            "length of actions is  1000\n",
            "109.87990362967632\n",
            "length of actions is  1000\n",
            "239.46115760939216\n",
            "length of actions is  332\n",
            "221.87120726084476\n",
            "length of actions is  326\n",
            "141.09784351196\n",
            "length of actions is  1000\n",
            "Your final reward is : 174.35\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2941])\n",
            "156.6023182884962\n",
            "length of actions is  1000\n",
            "118.97760551400371\n",
            "length of actions is  1000\n",
            "228.7575762107036\n",
            "length of actions is  304\n",
            "260.26822735762613\n",
            "length of actions is  186\n",
            "42.40273711355624\n",
            "length of actions is  157\n",
            "Your final reward is : 161.40\n",
            "torch.from_numpy(rewards) looks like  torch.Size([4624])\n",
            "246.10948552424577\n",
            "length of actions is  273\n",
            "71.01009579322141\n",
            "length of actions is  159\n",
            "112.9994527330318\n",
            "length of actions is  1000\n",
            "153.11593334329632\n",
            "length of actions is  1000\n",
            "47.15014189505945\n",
            "length of actions is  180\n",
            "Your final reward is : 126.08\n",
            "torch.from_numpy(rewards) looks like  torch.Size([4403])\n",
            "155.3683605008254\n",
            "length of actions is  1000\n",
            "256.5248545493405\n",
            "length of actions is  149\n",
            "61.00945976725163\n",
            "length of actions is  166\n",
            "250.85633692686244\n",
            "length of actions is  199\n",
            "284.9885743572521\n",
            "length of actions is  249\n",
            "Your final reward is : 201.75\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2106])\n",
            "157.53941441930397\n",
            "length of actions is  1000\n",
            "233.9209264564306\n",
            "length of actions is  263\n",
            "273.2306477555695\n",
            "length of actions is  195\n",
            "258.56937510228954\n",
            "length of actions is  191\n",
            "60.89909296599214\n",
            "length of actions is  181\n",
            "Your final reward is : 196.83\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2635])\n",
            "149.97946314980024\n",
            "length of actions is  1000\n",
            "222.87318565976815\n",
            "length of actions is  324\n",
            "292.88133058230187\n",
            "length of actions is  192\n",
            "55.112333112296454\n",
            "length of actions is  133\n",
            "52.62270635753299\n",
            "length of actions is  174\n",
            "Your final reward is : 154.69\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2693])\n",
            "234.29683587520887\n",
            "length of actions is  249\n",
            "76.43642988278671\n",
            "length of actions is  127\n",
            "242.7478202547867\n",
            "length of actions is  318\n",
            "285.13695038817866\n",
            "length of actions is  234\n",
            "40.30132966817678\n",
            "length of actions is  112\n",
            "Your final reward is : 175.78\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2012])\n",
            "148.7279008571731\n",
            "length of actions is  1000\n",
            "237.35771453675895\n",
            "length of actions is  248\n",
            "254.5189123780046\n",
            "length of actions is  178\n",
            "37.69144262763058\n",
            "length of actions is  153\n",
            "287.02861226390735\n",
            "length of actions is  157\n",
            "Your final reward is : 193.06\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2039])\n",
            "19.642144823091968\n",
            "length of actions is  136\n",
            "253.1226817298852\n",
            "length of actions is  192\n",
            "65.54404955910584\n",
            "length of actions is  117\n",
            "172.5027583430931\n",
            "length of actions is  1000\n",
            "155.6880241363088\n",
            "length of actions is  1000\n",
            "Your final reward is : 133.30\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2154])\n",
            "253.79680509279672\n",
            "length of actions is  214\n",
            "154.93323547071324\n",
            "length of actions is  1000\n",
            "43.28517983838648\n",
            "length of actions is  156\n",
            "262.41061302305036\n",
            "length of actions is  256\n",
            "48.75654136864054\n",
            "length of actions is  168\n",
            "Your final reward is : 152.64\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2520])\n",
            "154.51656522672246\n",
            "length of actions is  1000\n",
            "241.32991293229844\n",
            "length of actions is  210\n",
            "40.502561495542096\n",
            "length of actions is  162\n",
            "44.215564422827924\n",
            "length of actions is  128\n",
            "156.64408904945245\n",
            "length of actions is  1000\n",
            "Your final reward is : 127.44\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1827])\n",
            "30.125962492699642\n",
            "length of actions is  149\n",
            "160.05890518812356\n",
            "length of actions is  1000\n",
            "166.3520131087786\n",
            "length of actions is  1000\n",
            "53.88869280662351\n",
            "length of actions is  177\n",
            "289.62135474789386\n",
            "length of actions is  189\n",
            "Your final reward is : 140.01\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1884])\n",
            "21.99350987777514\n",
            "length of actions is  151\n",
            "156.01867336574395\n",
            "length of actions is  1000\n",
            "254.6691583330445\n",
            "length of actions is  275\n",
            "26.528543384380185\n",
            "length of actions is  147\n",
            "279.62898692597275\n",
            "length of actions is  753\n",
            "Your final reward is : 147.77\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1870])\n",
            "136.3271386532674\n",
            "length of actions is  1000\n",
            "258.8395209741244\n",
            "length of actions is  143\n",
            "25.420269690015928\n",
            "length of actions is  158\n",
            "22.99635903968654\n",
            "length of actions is  152\n",
            "10.125363911632775\n",
            "length of actions is  144\n",
            "Your final reward is : 90.74\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3652])\n",
            "140.64772376831291\n",
            "length of actions is  1000\n",
            "258.3803757559013\n",
            "length of actions is  145\n",
            "259.4298463037032\n",
            "length of actions is  173\n",
            "59.619959821027294\n",
            "length of actions is  114\n",
            "289.74434142917517\n",
            "length of actions is  166\n",
            "Your final reward is : 201.56\n",
            "torch.from_numpy(rewards) looks like  torch.Size([4275])\n",
            "18.928472929241735\n",
            "length of actions is  150\n",
            "281.9142412132003\n",
            "length of actions is  432\n",
            "66.26583979341706\n",
            "length of actions is  121\n",
            "26.403543923235063\n",
            "length of actions is  157\n",
            "45.597189194766\n",
            "length of actions is  105\n",
            "Your final reward is : 87.82\n",
            "torch.from_numpy(rewards) looks like  torch.Size([4192])\n",
            "36.09212073383139\n",
            "length of actions is  150\n",
            "279.334398689417\n",
            "length of actions is  276\n",
            "170.42895234653827\n",
            "length of actions is  1000\n",
            "11.22457116597242\n",
            "length of actions is  148\n",
            "55.90940518545111\n",
            "length of actions is  114\n",
            "Your final reward is : 110.60\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2252])\n",
            "19.77006380996633\n",
            "length of actions is  147\n",
            "171.83697294574\n",
            "length of actions is  1000\n",
            "53.71453815029602\n",
            "length of actions is  139\n",
            "53.233000004685834\n",
            "length of actions is  106\n",
            "18.13974352752777\n",
            "length of actions is  147\n",
            "Your final reward is : 63.34\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1548])\n",
            "30.421312324502253\n",
            "length of actions is  154\n",
            "282.98169255902417\n",
            "length of actions is  167\n",
            "257.6555537941645\n",
            "length of actions is  287\n",
            "70.07252116348619\n",
            "length of actions is  146\n",
            "44.85648425154395\n",
            "length of actions is  121\n",
            "Your final reward is : 137.20\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1875])\n",
            "21.737169416736066\n",
            "length of actions is  138\n",
            "252.77017965070047\n",
            "length of actions is  167\n",
            "53.77718771681674\n",
            "length of actions is  163\n",
            "265.8403900065172\n",
            "length of actions is  169\n",
            "253.6727413795383\n",
            "length of actions is  188\n",
            "Your final reward is : 169.56\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1682])\n",
            "20.3646972054149\n",
            "length of actions is  150\n",
            "57.71889330102829\n",
            "length of actions is  164\n",
            "34.7480014838994\n",
            "length of actions is  84\n",
            "284.7469764736519\n",
            "length of actions is  195\n",
            "274.65491144432394\n",
            "length of actions is  179\n",
            "Your final reward is : 134.45\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2268])\n",
            "15.960009483974432\n",
            "length of actions is  153\n",
            "52.937559874737104\n",
            "length of actions is  109\n",
            "12.462926283214443\n",
            "length of actions is  168\n",
            "37.63635914762324\n",
            "length of actions is  125\n",
            "-0.18720577897940416\n",
            "length of actions is  124\n",
            "Your final reward is : 23.76\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1440])\n",
            "22.216211603364712\n",
            "length of actions is  147\n",
            "51.89963731276754\n",
            "length of actions is  104\n",
            "51.60015155384281\n",
            "length of actions is  144\n",
            "85.76994625550458\n",
            "length of actions is  111\n",
            "268.17795771872744\n",
            "length of actions is  195\n",
            "Your final reward is : 95.93\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1367])\n",
            "15.16550248249736\n",
            "length of actions is  152\n",
            "72.88296214108689\n",
            "length of actions is  109\n",
            "145.20119129399066\n",
            "length of actions is  1000\n",
            "253.7794747635912\n",
            "length of actions is  189\n",
            "137.225532571985\n",
            "length of actions is  1000\n",
            "Your final reward is : 124.85\n",
            "torch.from_numpy(rewards) looks like  torch.Size([5044])\n",
            "20.2562858006917\n",
            "length of actions is  142\n",
            "19.899800050162312\n",
            "length of actions is  152\n",
            "24.452690435153144\n",
            "length of actions is  127\n",
            "172.0192966928823\n",
            "length of actions is  1000\n",
            "29.030536535638646\n",
            "length of actions is  144\n",
            "Your final reward is : 53.13\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1819])\n",
            "-1.486599082362062\n",
            "length of actions is  141\n",
            "37.90118120579527\n",
            "length of actions is  109\n",
            "282.16200675391093\n",
            "length of actions is  210\n",
            "161.11780084340492\n",
            "length of actions is  1000\n",
            "70.65042029986088\n",
            "length of actions is  101\n",
            "Your final reward is : 110.07\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1751])\n",
            "7.002747668746011\n",
            "length of actions is  147\n",
            "47.02727820844103\n",
            "length of actions is  100\n",
            "23.01948395594323\n",
            "length of actions is  114\n",
            "82.74018097368204\n",
            "length of actions is  91\n",
            "47.122183987200714\n",
            "length of actions is  104\n",
            "Your final reward is : 41.38\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1233])\n",
            "11.68505689676384\n",
            "length of actions is  142\n",
            "237.01809066982742\n",
            "length of actions is  227\n",
            "77.6754317897699\n",
            "length of actions is  87\n",
            "27.78938465606427\n",
            "length of actions is  180\n",
            "43.917995340930815\n",
            "length of actions is  93\n",
            "Your final reward is : 79.62\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1296])\n",
            "16.918323056644354\n",
            "length of actions is  138\n",
            "250.30014207432424\n",
            "length of actions is  174\n",
            "62.37095504700912\n",
            "length of actions is  106\n",
            "289.05863509103403\n",
            "length of actions is  170\n",
            "73.60877378022539\n",
            "length of actions is  109\n",
            "Your final reward is : 138.45\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1389])\n",
            "15.32892720640875\n",
            "length of actions is  137\n",
            "21.67136391298608\n",
            "length of actions is  125\n",
            "3.714728523205565\n",
            "length of actions is  164\n",
            "295.3348440673275\n",
            "length of actions is  162\n",
            "68.44343262494553\n",
            "length of actions is  110\n",
            "Your final reward is : 80.90\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1694])\n",
            "22.06564446021376\n",
            "length of actions is  143\n",
            "51.839973131256954\n",
            "length of actions is  100\n",
            "37.276214078938835\n",
            "length of actions is  94\n",
            "22.61563228265952\n",
            "length of actions is  181\n",
            "41.78056143871501\n",
            "length of actions is  106\n",
            "Your final reward is : 35.12\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2988])\n",
            "140.87089412594514\n",
            "length of actions is  806\n",
            "17.75154681413865\n",
            "length of actions is  181\n",
            "286.1019593907439\n",
            "length of actions is  225\n",
            "252.1103907137439\n",
            "length of actions is  205\n",
            "255.1848641483372\n",
            "length of actions is  164\n",
            "Your final reward is : 190.40\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1872])\n",
            "19.116098639516395\n",
            "length of actions is  143\n",
            "51.2155658107572\n",
            "length of actions is  98\n",
            "38.01387722274933\n",
            "length of actions is  111\n",
            "52.571999886014254\n",
            "length of actions is  113\n",
            "84.81277589124329\n",
            "length of actions is  127\n",
            "Your final reward is : 49.15\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1108])\n",
            "1.9540492989027172\n",
            "length of actions is  146\n",
            "20.568438253685954\n",
            "length of actions is  110\n",
            "67.6147943728179\n",
            "length of actions is  149\n",
            "40.11380275624026\n",
            "length of actions is  123\n",
            "11.282643982410008\n",
            "length of actions is  98\n",
            "Your final reward is : 28.31\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1288])\n",
            "-0.3633512193277397\n",
            "length of actions is  145\n",
            "41.06332973030868\n",
            "length of actions is  122\n",
            "42.066885833961635\n",
            "length of actions is  118\n",
            "64.36229116043137\n",
            "length of actions is  146\n",
            "62.03136550161318\n",
            "length of actions is  117\n",
            "Your final reward is : 41.83\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1228])\n",
            "9.600782356089084\n",
            "length of actions is  151\n",
            "17.949118503448517\n",
            "length of actions is  95\n",
            "12.712607106819547\n",
            "length of actions is  181\n",
            "38.127827512404764\n",
            "length of actions is  91\n",
            "40.4209600516279\n",
            "length of actions is  105\n",
            "Your final reward is : 23.76\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1313])\n",
            "11.096814798481574\n",
            "length of actions is  146\n",
            "-1.4724220126066712\n",
            "length of actions is  105\n",
            "56.006044876932805\n",
            "length of actions is  135\n",
            "39.88963611572328\n",
            "length of actions is  99\n",
            "-23.90449686754313\n",
            "length of actions is  171\n",
            "Your final reward is : 16.32\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1181])\n",
            "4.028042221119961\n",
            "length of actions is  139\n",
            "36.74304226918807\n",
            "length of actions is  116\n",
            "31.10655564249319\n",
            "length of actions is  106\n",
            "63.066799178300755\n",
            "length of actions is  84\n",
            "17.754898890057603\n",
            "length of actions is  93\n",
            "Your final reward is : 30.54\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1207])\n",
            "11.740302699167358\n",
            "length of actions is  143\n",
            "34.469783950959254\n",
            "length of actions is  92\n",
            "57.248715413904335\n",
            "length of actions is  85\n",
            "53.729151915227504\n",
            "length of actions is  91\n",
            "53.75784943708925\n",
            "length of actions is  132\n",
            "Your final reward is : 42.19\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1272])\n",
            "11.419760484865776\n",
            "length of actions is  156\n",
            "18.536803358031435\n",
            "length of actions is  94\n",
            "50.297701913669556\n",
            "length of actions is  118\n",
            "2.015035448116265\n",
            "length of actions is  170\n",
            "163.25780276738718\n",
            "length of actions is  1000\n",
            "Your final reward is : 49.11\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1169])\n",
            "-3.700289167525682\n",
            "length of actions is  176\n",
            "43.02769370988079\n",
            "length of actions is  111\n",
            "59.5901897091901\n",
            "length of actions is  84\n",
            "19.5178402830595\n",
            "length of actions is  130\n",
            "48.444490110770204\n",
            "length of actions is  106\n",
            "Your final reward is : 33.38\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1195])\n",
            "8.473370594970234\n",
            "length of actions is  138\n",
            "6.399767023858487\n",
            "length of actions is  93\n",
            "48.470688107827755\n",
            "length of actions is  96\n",
            "26.194819244867503\n",
            "length of actions is  143\n",
            "36.58962808281507\n",
            "length of actions is  133\n",
            "Your final reward is : 25.23\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1324])\n",
            "11.892661041273868\n",
            "length of actions is  139\n",
            "40.55740421152058\n",
            "length of actions is  115\n",
            "41.02314182578931\n",
            "length of actions is  120\n",
            "27.773049487752914\n",
            "length of actions is  167\n",
            "49.80863552979534\n",
            "length of actions is  128\n",
            "Your final reward is : 34.21\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1254])\n",
            "-0.1350050841520698\n",
            "length of actions is  142\n",
            "-0.38412196283832145\n",
            "length of actions is  153\n",
            "23.288433439362436\n",
            "length of actions is  104\n",
            "-2.594392294132888\n",
            "length of actions is  96\n",
            "4.705951345591657\n",
            "length of actions is  89\n",
            "Your final reward is : 4.98\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1018])\n",
            "6.473289779865169\n",
            "length of actions is  142\n",
            "9.845238661756156\n",
            "length of actions is  150\n",
            "13.581736964798722\n",
            "length of actions is  170\n",
            "32.201024476530165\n",
            "length of actions is  123\n",
            "60.4737620180197\n",
            "length of actions is  103\n",
            "Your final reward is : 24.52\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1101])\n",
            "-3.3376970525210226\n",
            "length of actions is  149\n",
            "22.459053360765907\n",
            "length of actions is  103\n",
            "53.3633885374021\n",
            "length of actions is  136\n",
            "11.32826290256888\n",
            "length of actions is  187\n",
            "9.230678825329093\n",
            "length of actions is  184\n",
            "Your final reward is : 18.61\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1166])\n",
            "11.317383272178915\n",
            "length of actions is  144\n",
            "28.188530484748753\n",
            "length of actions is  110\n",
            "16.92679237896654\n",
            "length of actions is  115\n",
            "56.22297061874792\n",
            "length of actions is  114\n",
            "43.51292085783268\n",
            "length of actions is  119\n",
            "Your final reward is : 31.23\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1210])\n",
            "5.129211621443403\n",
            "length of actions is  151\n",
            "10.857976227148399\n",
            "length of actions is  92\n",
            "15.88506241382882\n",
            "length of actions is  84\n",
            "22.499705815510424\n",
            "length of actions is  134\n",
            "17.142053359217556\n",
            "length of actions is  159\n",
            "Your final reward is : 14.30\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1344])\n",
            "0.02228584940266387\n",
            "length of actions is  147\n",
            "45.117363701806966\n",
            "length of actions is  101\n",
            "8.849616834471533\n",
            "length of actions is  79\n",
            "12.714249213680276\n",
            "length of actions is  129\n",
            "0.631948132104597\n",
            "length of actions is  92\n",
            "Your final reward is : 13.47\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1188])\n",
            "4.543084595640977\n",
            "length of actions is  143\n",
            "37.579420616173934\n",
            "length of actions is  90\n",
            "19.118315500631596\n",
            "length of actions is  80\n",
            "33.902056173650465\n",
            "length of actions is  163\n",
            "22.01181506135667\n",
            "length of actions is  128\n",
            "Your final reward is : 23.43\n",
            "torch.from_numpy(rewards) looks like  torch.Size([978])\n",
            "6.226493243362114\n",
            "length of actions is  143\n",
            "34.76393330128394\n",
            "length of actions is  86\n",
            "10.015947459043304\n",
            "length of actions is  153\n",
            "38.686127813990225\n",
            "length of actions is  110\n",
            "25.12426100688151\n",
            "length of actions is  151\n",
            "Your final reward is : 22.96\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1239])\n",
            "2.6370073504978677\n",
            "length of actions is  147\n",
            "33.66612575167338\n",
            "length of actions is  99\n",
            "13.988205389883376\n",
            "length of actions is  165\n",
            "7.959192950197917\n",
            "length of actions is  154\n",
            "17.667144700329217\n",
            "length of actions is  195\n",
            "Your final reward is : 15.18\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1299])\n",
            "3.689229333975618\n",
            "length of actions is  147\n",
            "28.657536917937023\n",
            "length of actions is  98\n",
            "36.993861006759914\n",
            "length of actions is  113\n",
            "28.054681241421093\n",
            "length of actions is  108\n",
            "26.44485890479025\n",
            "length of actions is  120\n",
            "Your final reward is : 24.77\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1046])\n",
            "5.323137027141428\n",
            "length of actions is  147\n",
            "21.508485439352953\n",
            "length of actions is  98\n",
            "31.915205657818518\n",
            "length of actions is  112\n",
            "50.727845596016635\n",
            "length of actions is  81\n",
            "10.774092197191365\n",
            "length of actions is  107\n",
            "Your final reward is : 24.05\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1034])\n",
            "6.3991460872232295\n",
            "length of actions is  147\n",
            "20.226358061192045\n",
            "length of actions is  98\n",
            "29.433244724747993\n",
            "length of actions is  111\n",
            "38.63323774804215\n",
            "length of actions is  119\n",
            "-9.212163222678768\n",
            "length of actions is  178\n",
            "Your final reward is : 17.10\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1036])\n",
            "1.6707353943975676\n",
            "length of actions is  142\n",
            "7.436896663637583\n",
            "length of actions is  149\n",
            "36.39632639411036\n",
            "length of actions is  90\n",
            "14.601183373680044\n",
            "length of actions is  127\n",
            "59.91389230282772\n",
            "length of actions is  83\n",
            "Your final reward is : 24.00\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1167])\n",
            "0.677200524678355\n",
            "length of actions is  141\n",
            "31.755077186330027\n",
            "length of actions is  111\n",
            "27.802891448800523\n",
            "length of actions is  130\n",
            "29.134145239129907\n",
            "length of actions is  110\n",
            "6.088237613302994\n",
            "length of actions is  143\n",
            "Your final reward is : 19.09\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1120])\n",
            "3.336422903513352\n",
            "length of actions is  139\n",
            "37.41152955311398\n",
            "length of actions is  114\n",
            "12.084892313068934\n",
            "length of actions is  89\n",
            "10.850245051058863\n",
            "length of actions is  91\n",
            "43.858055002877364\n",
            "length of actions is  127\n",
            "Your final reward is : 21.51\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1018])\n",
            "-2.6954309994687122\n",
            "length of actions is  150\n",
            "33.02206038623254\n",
            "length of actions is  133\n",
            "-6.938448922637136\n",
            "length of actions is  77\n",
            "4.660259632202255\n",
            "length of actions is  120\n",
            "41.80987580633098\n",
            "length of actions is  122\n",
            "Your final reward is : 13.97\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1041])\n",
            "-2.7503049165333096\n",
            "length of actions is  147\n",
            "25.414153323677297\n",
            "length of actions is  95\n",
            "7.491427945218177\n",
            "length of actions is  94\n",
            "20.051325080979538\n",
            "length of actions is  86\n",
            "13.625740052118957\n",
            "length of actions is  128\n",
            "Your final reward is : 12.77\n",
            "torch.from_numpy(rewards) looks like  torch.Size([903])\n",
            "-7.252408796674686\n",
            "length of actions is  148\n",
            "37.15534148783618\n",
            "length of actions is  86\n",
            "19.423905861206322\n",
            "length of actions is  114\n",
            "16.115487192443382\n",
            "length of actions is  98\n",
            "8.572655430082094\n",
            "length of actions is  72\n",
            "Your final reward is : 14.80\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1074])\n",
            "-9.510353175273238\n",
            "length of actions is  148\n",
            "19.050655827764686\n",
            "length of actions is  84\n",
            "22.22497172190053\n",
            "length of actions is  118\n",
            "5.149286090514309\n",
            "length of actions is  137\n",
            "-13.030346648219194\n",
            "length of actions is  96\n",
            "Your final reward is : 4.78\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1006])\n",
            "-9.969759030479835\n",
            "length of actions is  145\n",
            "-7.752406714801182\n",
            "length of actions is  97\n",
            "14.136120081691914\n",
            "length of actions is  93\n",
            "22.241571864243994\n",
            "length of actions is  114\n",
            "21.58625973336605\n",
            "length of actions is  102\n",
            "Your final reward is : 8.05\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1165])\n",
            "-8.2981287769869\n",
            "length of actions is  146\n",
            "-5.158876668079046\n",
            "length of actions is  89\n",
            "28.453963858349738\n",
            "length of actions is  74\n",
            "32.92023456391834\n",
            "length of actions is  127\n",
            "4.225798612867621\n",
            "length of actions is  109\n",
            "Your final reward is : 10.43\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1089])\n",
            "-11.308797136556407\n",
            "length of actions is  145\n",
            "-3.5818397355326397\n",
            "length of actions is  96\n",
            "20.74238762688853\n",
            "length of actions is  121\n",
            "-22.011085061474205\n",
            "length of actions is  81\n",
            "-4.261471677729261\n",
            "length of actions is  97\n",
            "Your final reward is : -4.08\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1249])\n",
            "-12.072354496511295\n",
            "length of actions is  148\n",
            "27.41269053714977\n",
            "length of actions is  84\n",
            "21.856989014565073\n",
            "length of actions is  116\n",
            "3.542119949163066\n",
            "length of actions is  93\n",
            "4.515620192227743\n",
            "length of actions is  94\n",
            "Your final reward is : 9.05\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1059])\n",
            "0.49834777163590616\n",
            "length of actions is  143\n",
            "13.393901806962319\n",
            "length of actions is  76\n",
            "-18.63452162308934\n",
            "length of actions is  114\n",
            "28.111812778613455\n",
            "length of actions is  108\n",
            "-6.38742508279698\n",
            "length of actions is  94\n",
            "Your final reward is : 3.40\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1036])\n",
            "-5.7071021528039125\n",
            "length of actions is  144\n",
            "3.243840452232064\n",
            "length of actions is  92\n",
            "6.691459841533856\n",
            "length of actions is  106\n",
            "-10.451715028268367\n",
            "length of actions is  88\n",
            "5.446327390399873\n",
            "length of actions is  76\n",
            "Your final reward is : -0.16\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1077])\n",
            "-7.779187059776419\n",
            "length of actions is  140\n",
            "0.1478828568003081\n",
            "length of actions is  121\n",
            "6.8521843916829965\n",
            "length of actions is  76\n",
            "6.290150405975169\n",
            "length of actions is  152\n",
            "19.528398767385212\n",
            "length of actions is  83\n",
            "Your final reward is : 5.01\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1169])\n",
            "-9.586218840006723\n",
            "length of actions is  142\n",
            "-18.112384019229168\n",
            "length of actions is  140\n",
            "-4.213376071100782\n",
            "length of actions is  142\n",
            "-21.51444330340709\n",
            "length of actions is  88\n",
            "14.188906088419799\n",
            "length of actions is  106\n",
            "Your final reward is : -7.85\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1059])\n",
            "-5.209938715907555\n",
            "length of actions is  145\n",
            "-12.82701577101814\n",
            "length of actions is  93\n",
            "7.1288047046838585\n",
            "length of actions is  116\n",
            "24.773150288542666\n",
            "length of actions is  114\n",
            "-3.5235135863290026\n",
            "length of actions is  74\n",
            "Your final reward is : 2.07\n",
            "torch.from_numpy(rewards) looks like  torch.Size([936])\n",
            "-16.781566828682145\n",
            "length of actions is  142\n",
            "-28.698968567513617\n",
            "length of actions is  148\n",
            "-30.717866140104263\n",
            "length of actions is  89\n",
            "-4.019689565447422\n",
            "length of actions is  100\n",
            "-1.8774765705510674\n",
            "length of actions is  91\n",
            "Your final reward is : -16.42\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1041])\n",
            "-20.800343302231653\n",
            "length of actions is  152\n",
            "14.35973358973942\n",
            "length of actions is  75\n",
            "22.662697440543738\n",
            "length of actions is  78\n",
            "1.3095385208631853\n",
            "length of actions is  140\n",
            "-21.86570283119579\n",
            "length of actions is  77\n",
            "Your final reward is : -0.87\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1013])\n",
            "-18.589535239509573\n",
            "length of actions is  138\n",
            "-26.872536795785948\n",
            "length of actions is  82\n",
            "-19.548214596757177\n",
            "length of actions is  104\n",
            "-19.915898266701404\n",
            "length of actions is  128\n",
            "9.322458014954535\n",
            "length of actions is  101\n",
            "Your final reward is : -15.12\n",
            "torch.from_numpy(rewards) looks like  torch.Size([962])\n",
            "-31.188464930311824\n",
            "length of actions is  136\n",
            "-9.746129273657132\n",
            "length of actions is  91\n",
            "10.031750334962467\n",
            "length of actions is  76\n",
            "-11.46821068646662\n",
            "length of actions is  107\n",
            "22.141465707118527\n",
            "length of actions is  72\n",
            "Your final reward is : -4.05\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1036])\n",
            "-26.57734486987198\n",
            "length of actions is  145\n",
            "-6.865104109423498\n",
            "length of actions is  91\n",
            "-13.576427466358666\n",
            "length of actions is  105\n",
            "0.2803799796449482\n",
            "length of actions is  150\n",
            "6.439722143779136\n",
            "length of actions is  67\n",
            "Your final reward is : -8.06\n",
            "torch.from_numpy(rewards) looks like  torch.Size([977])\n",
            "-40.09745658463171\n",
            "length of actions is  144\n",
            "-7.854712493448687\n",
            "length of actions is  85\n",
            "-15.804994216662877\n",
            "length of actions is  142\n",
            "-16.098358784282155\n",
            "length of actions is  127\n",
            "-4.152626837509729\n",
            "length of actions is  143\n",
            "Your final reward is : -16.80\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1007])\n",
            "-37.15270268894195\n",
            "length of actions is  147\n",
            "1.3536868093678578\n",
            "length of actions is  85\n",
            "-8.904518659297992\n",
            "length of actions is  109\n",
            "-2.685064339205894\n",
            "length of actions is  151\n",
            "-14.972150244354893\n",
            "length of actions is  137\n",
            "Your final reward is : -12.47\n",
            "torch.from_numpy(rewards) looks like  torch.Size([924])\n",
            "-27.264467069582096\n",
            "length of actions is  149\n",
            "-26.001100729328783\n",
            "length of actions is  80\n",
            "-12.05067654211328\n",
            "length of actions is  145\n",
            "-15.995033449656901\n",
            "length of actions is  149\n",
            "1.9391285024406386\n",
            "length of actions is  85\n",
            "Your final reward is : -15.87\n",
            "torch.from_numpy(rewards) looks like  torch.Size([938])\n",
            "-27.430106466988946\n",
            "length of actions is  148\n",
            "-0.20015420815862228\n",
            "length of actions is  77\n",
            "-8.497300768995686\n",
            "length of actions is  99\n",
            "-17.999674927162005\n",
            "length of actions is  131\n",
            "-24.95213266625072\n",
            "length of actions is  94\n",
            "Your final reward is : -15.82\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1074])\n",
            "-37.057913179420666\n",
            "length of actions is  146\n",
            "-14.705470285663793\n",
            "length of actions is  85\n",
            "0.9361154580158626\n",
            "length of actions is  72\n",
            "-16.473685164007392\n",
            "length of actions is  105\n",
            "-19.22597276693351\n",
            "length of actions is  84\n",
            "Your final reward is : -17.31\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1015])\n",
            "-27.16059180073954\n",
            "length of actions is  145\n",
            "-13.36016537170326\n",
            "length of actions is  91\n",
            "-21.69540248696771\n",
            "length of actions is  98\n",
            "-15.464929183897297\n",
            "length of actions is  120\n",
            "-14.109696433473772\n",
            "length of actions is  101\n",
            "Your final reward is : -18.36\n",
            "torch.from_numpy(rewards) looks like  torch.Size([966])\n",
            "-37.311310746741285\n",
            "length of actions is  139\n",
            "30.76428650647219\n",
            "length of actions is  108\n",
            "-28.84733142967424\n",
            "length of actions is  108\n",
            "-26.081482118056968\n",
            "length of actions is  140\n",
            "-0.640576871692744\n",
            "length of actions is  79\n",
            "Your final reward is : -12.42\n",
            "torch.from_numpy(rewards) looks like  torch.Size([951])\n",
            "-28.330269815660486\n",
            "length of actions is  142\n",
            "-38.366221327528336\n",
            "length of actions is  148\n",
            "-33.454470463048864\n",
            "length of actions is  85\n",
            "-18.57349486889055\n",
            "length of actions is  113\n",
            "-15.360488942139511\n",
            "length of actions is  91\n",
            "Your final reward is : -26.82\n",
            "torch.from_numpy(rewards) looks like  torch.Size([976])\n",
            "-37.78740614834386\n",
            "length of actions is  137\n",
            "-27.140830914974515\n",
            "length of actions is  117\n",
            "-24.85985922592495\n",
            "length of actions is  107\n",
            "22.972029927520538\n",
            "length of actions is  68\n",
            "-4.011213579756443\n",
            "length of actions is  75\n",
            "Your final reward is : -14.17\n",
            "torch.from_numpy(rewards) looks like  torch.Size([953])\n",
            "-33.842040639968445\n",
            "length of actions is  155\n",
            "-9.753409145679782\n",
            "length of actions is  108\n",
            "-0.596245302968299\n",
            "length of actions is  100\n",
            "-11.939334097925581\n",
            "length of actions is  118\n",
            "7.021399982402187\n",
            "length of actions is  76\n",
            "Your final reward is : -9.82\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1038])\n",
            "-22.803633446484085\n",
            "length of actions is  152\n",
            "14.682478971902839\n",
            "length of actions is  86\n",
            "-0.371691804144362\n",
            "length of actions is  98\n",
            "12.343275661405741\n",
            "length of actions is  90\n",
            "-5.282484115321623\n",
            "length of actions is  149\n",
            "Your final reward is : -0.29\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1070])\n",
            "-38.37970375228177\n",
            "length of actions is  140\n",
            "-2.236672727264363\n",
            "length of actions is  101\n",
            "-2.708211425677746\n",
            "length of actions is  106\n",
            "32.91552631997399\n",
            "length of actions is  73\n",
            "9.746459209966545\n",
            "length of actions is  97\n",
            "Your final reward is : -0.13\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1066])\n",
            "-24.16849679624805\n",
            "length of actions is  139\n",
            "33.15718845015155\n",
            "length of actions is  111\n",
            "-5.773449321671876\n",
            "length of actions is  98\n",
            "-6.216253756130911\n",
            "length of actions is  91\n",
            "-6.781533838150338\n",
            "length of actions is  108\n",
            "Your final reward is : -1.96\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1093])\n",
            "-33.484833940488855\n",
            "length of actions is  168\n",
            "1.0013515247233897\n",
            "length of actions is  103\n",
            "-21.00561222032627\n",
            "length of actions is  122\n",
            "-22.7227759904017\n",
            "length of actions is  169\n",
            "-9.529196842847483\n",
            "length of actions is  115\n",
            "Your final reward is : -17.15\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1160])\n",
            "-27.261610823969917\n",
            "length of actions is  145\n",
            "-2.9446556738455314\n",
            "length of actions is  98\n",
            "6.893944098932437\n",
            "length of actions is  83\n",
            "-16.161889255914062\n",
            "length of actions is  107\n",
            "-17.658236534720274\n",
            "length of actions is  110\n",
            "Your final reward is : -11.43\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1095])\n",
            "-24.23338353756803\n",
            "length of actions is  172\n",
            "16.890273355154164\n",
            "length of actions is  101\n",
            "-1.5306669808892366\n",
            "length of actions is  109\n",
            "6.460687367585848\n",
            "length of actions is  107\n",
            "1.1318654649218018\n",
            "length of actions is  89\n",
            "Your final reward is : -0.26\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1002])\n",
            "-13.790417600887949\n",
            "length of actions is  172\n",
            "20.09552089649884\n",
            "length of actions is  101\n",
            "-10.12590047526416\n",
            "length of actions is  108\n",
            "-12.926770523652536\n",
            "length of actions is  129\n",
            "-0.04156223039377949\n",
            "length of actions is  111\n",
            "Your final reward is : -3.36\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1286])\n",
            "-23.48999546235251\n",
            "length of actions is  184\n",
            "27.198064916063714\n",
            "length of actions is  110\n",
            "23.488199061706993\n",
            "length of actions is  147\n",
            "-18.204449396748274\n",
            "length of actions is  117\n",
            "2.2537647019751432\n",
            "length of actions is  102\n",
            "Your final reward is : 2.25\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1337])\n",
            "-11.063592457575297\n",
            "length of actions is  182\n",
            "42.41716613671002\n",
            "length of actions is  90\n",
            "15.462473170332899\n",
            "length of actions is  117\n",
            "-14.362795806877685\n",
            "length of actions is  121\n",
            "2.034271705943752\n",
            "length of actions is  120\n",
            "Your final reward is : 6.90\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1098])\n",
            "-14.400090258771058\n",
            "length of actions is  197\n",
            "22.315073281464393\n",
            "length of actions is  171\n",
            "-19.734024192497742\n",
            "length of actions is  127\n",
            "19.91263483247903\n",
            "length of actions is  109\n",
            "25.726277871824692\n",
            "length of actions is  175\n",
            "Your final reward is : 6.76\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1354])\n",
            "-34.47833252819704\n",
            "length of actions is  197\n",
            "18.772716347785604\n",
            "length of actions is  166\n",
            "-9.20038405123492\n",
            "length of actions is  195\n",
            "16.651171058352986\n",
            "length of actions is  93\n",
            "36.57032104772739\n",
            "length of actions is  224\n",
            "Your final reward is : 5.66\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1220])\n",
            "-31.636120886733195\n",
            "length of actions is  193\n",
            "-26.144801756585466\n",
            "length of actions is  126\n",
            "44.1053297693619\n",
            "length of actions is  156\n",
            "42.037799771821796\n",
            "length of actions is  101\n",
            "12.18737096962576\n",
            "length of actions is  108\n",
            "Your final reward is : 8.11\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1208])\n",
            "-39.50345432843369\n",
            "length of actions is  207\n",
            "19.901970772700025\n",
            "length of actions is  107\n",
            "8.76454979081548\n",
            "length of actions is  109\n",
            "15.585626848164509\n",
            "length of actions is  117\n",
            "20.75040042443281\n",
            "length of actions is  134\n",
            "Your final reward is : 5.10\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1430])\n",
            "-40.71892414289741\n",
            "length of actions is  197\n",
            "6.823422182870203\n",
            "length of actions is  174\n",
            "28.091247723252536\n",
            "length of actions is  172\n",
            "12.726664232871997\n",
            "length of actions is  130\n",
            "3.7116272759892013\n",
            "length of actions is  192\n",
            "Your final reward is : 2.13\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1533])\n",
            "-50.45698747390128\n",
            "length of actions is  196\n",
            "8.170532899811022\n",
            "length of actions is  213\n",
            "14.197575793462434\n",
            "length of actions is  112\n",
            "8.547698577557242\n",
            "length of actions is  117\n",
            "1.045282490245853\n",
            "length of actions is  129\n",
            "Your final reward is : -3.70\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1321])\n",
            "-47.51293338761603\n",
            "length of actions is  216\n",
            "-7.270365909688607\n",
            "length of actions is  134\n",
            "-38.268207100728205\n",
            "length of actions is  125\n",
            "36.94191687177394\n",
            "length of actions is  98\n",
            "15.527275403594388\n",
            "length of actions is  111\n",
            "Your final reward is : -8.12\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1424])\n",
            "-62.59067077115071\n",
            "length of actions is  223\n",
            "5.2708879782758515\n",
            "length of actions is  112\n",
            "7.24676668931636\n",
            "length of actions is  196\n",
            "27.341090261765743\n",
            "length of actions is  108\n",
            "46.2083312296823\n",
            "length of actions is  151\n",
            "Your final reward is : 4.70\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1424])\n",
            "-56.49461284872994\n",
            "length of actions is  218\n",
            "32.267957616899224\n",
            "length of actions is  114\n",
            "2.7883665578012113\n",
            "length of actions is  200\n",
            "17.039114408930345\n",
            "length of actions is  119\n",
            "12.38094223929724\n",
            "length of actions is  226\n",
            "Your final reward is : 1.60\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1318])\n",
            "-80.086268483008\n",
            "length of actions is  222\n",
            "14.61316595813419\n",
            "length of actions is  134\n",
            "-22.342489940009088\n",
            "length of actions is  141\n",
            "-6.90724511626415\n",
            "length of actions is  120\n",
            "28.143506362853145\n",
            "length of actions is  106\n",
            "Your final reward is : -13.32\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1460])\n",
            "-59.86344495661288\n",
            "length of actions is  215\n",
            "34.73813473923943\n",
            "length of actions is  102\n",
            "-7.291006781885841\n",
            "length of actions is  128\n",
            "6.7063831609416695\n",
            "length of actions is  134\n",
            "3.4079373706858433\n",
            "length of actions is  129\n",
            "Your final reward is : -4.46\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1561])\n",
            "-72.83875389093969\n",
            "length of actions is  232\n",
            "2.110380936029344\n",
            "length of actions is  121\n",
            "-44.96978155521077\n",
            "length of actions is  186\n",
            "16.08916068676467\n",
            "length of actions is  116\n",
            "43.12548379004011\n",
            "length of actions is  154\n",
            "Your final reward is : -11.30\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1571])\n",
            "-90.4127391189307\n",
            "length of actions is  230\n",
            "-31.318251252862737\n",
            "length of actions is  222\n",
            "-3.841707047667967\n",
            "length of actions is  120\n",
            "9.420997186732933\n",
            "length of actions is  129\n",
            "-7.280633000848098\n",
            "length of actions is  201\n",
            "Your final reward is : -24.69\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1278])\n",
            "-85.2441862118372\n",
            "length of actions is  229\n",
            "26.837976446570437\n",
            "length of actions is  116\n",
            "28.595425136082213\n",
            "length of actions is  228\n",
            "31.856703589245257\n",
            "length of actions is  238\n",
            "-20.313680294892478\n",
            "length of actions is  197\n",
            "Your final reward is : -3.65\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1693])\n",
            "-75.17315705680068\n",
            "length of actions is  234\n",
            "-9.676924606821274\n",
            "length of actions is  123\n",
            "-6.669670350707236\n",
            "length of actions is  127\n",
            "1.8807869746184878\n",
            "length of actions is  129\n",
            "1.0596712484668274\n",
            "length of actions is  115\n",
            "Your final reward is : -17.72\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1441])\n",
            "-47.86838506309205\n",
            "length of actions is  218\n",
            "35.17042552887952\n",
            "length of actions is  106\n",
            "13.733692222100217\n",
            "length of actions is  162\n",
            "52.475149610845136\n",
            "length of actions is  160\n",
            "34.828501488837844\n",
            "length of actions is  159\n",
            "Your final reward is : 17.67\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1511])\n",
            "-53.604970298439994\n",
            "length of actions is  228\n",
            "13.9020134652569\n",
            "length of actions is  141\n",
            "18.85386358252198\n",
            "length of actions is  114\n",
            "-4.7886113159362935\n",
            "length of actions is  250\n",
            "35.49215336922356\n",
            "length of actions is  228\n",
            "Your final reward is : 1.97\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1619])\n",
            "-64.67714235490632\n",
            "length of actions is  216\n",
            "-17.093375124618916\n",
            "length of actions is  153\n",
            "10.90996889402409\n",
            "length of actions is  108\n",
            "17.530692591835077\n",
            "length of actions is  113\n",
            "12.923679662426224\n",
            "length of actions is  131\n",
            "Your final reward is : -8.08\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1539])\n",
            "-89.60060771356846\n",
            "length of actions is  229\n",
            "9.777952842597202\n",
            "length of actions is  117\n",
            "-42.23700935111131\n",
            "length of actions is  226\n",
            "12.421590297573587\n",
            "length of actions is  138\n",
            "31.578394375181972\n",
            "length of actions is  233\n",
            "Your final reward is : -15.61\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1516])\n",
            "-86.70230608026533\n",
            "length of actions is  242\n",
            "-28.77857985873763\n",
            "length of actions is  191\n",
            "23.684202228875023\n",
            "length of actions is  160\n",
            "24.42809193047728\n",
            "length of actions is  167\n",
            "-5.333843514521746\n",
            "length of actions is  234\n",
            "Your final reward is : -14.54\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1556])\n",
            "-83.59007805927955\n",
            "length of actions is  234\n",
            "-10.909473428078002\n",
            "length of actions is  121\n",
            "4.466439105930775\n",
            "length of actions is  117\n",
            "14.760972895989013\n",
            "length of actions is  112\n",
            "17.788597218160163\n",
            "length of actions is  138\n",
            "Your final reward is : -11.50\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1540])\n",
            "-67.95208851701888\n",
            "length of actions is  219\n",
            "-33.05415403223813\n",
            "length of actions is  141\n",
            "13.753639605138204\n",
            "length of actions is  120\n",
            "24.73887519687446\n",
            "length of actions is  120\n",
            "35.70781434637951\n",
            "length of actions is  119\n",
            "Your final reward is : -5.36\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1708])\n",
            "-92.9144229680739\n",
            "length of actions is  254\n",
            "20.23038694364054\n",
            "length of actions is  233\n",
            "4.09616580199274\n",
            "length of actions is  132\n",
            "12.19887237886303\n",
            "length of actions is  155\n",
            "12.308108488477288\n",
            "length of actions is  120\n",
            "Your final reward is : -8.82\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1367])\n",
            "-72.73904098544618\n",
            "length of actions is  234\n",
            "-10.895715091335163\n",
            "length of actions is  122\n",
            "-7.8747293884204055\n",
            "length of actions is  179\n",
            "26.36690699003499\n",
            "length of actions is  146\n",
            "16.009266188735737\n",
            "length of actions is  230\n",
            "Your final reward is : -9.83\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1647])\n",
            "-46.63172071877122\n",
            "length of actions is  243\n",
            "15.488677228251802\n",
            "length of actions is  152\n",
            "-15.865583414451748\n",
            "length of actions is  143\n",
            "16.936544766037315\n",
            "length of actions is  227\n",
            "9.927127574728644\n",
            "length of actions is  241\n",
            "Your final reward is : -4.03\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1567])\n",
            "-38.38904707471147\n",
            "length of actions is  239\n",
            "46.09848203263036\n",
            "length of actions is  113\n",
            "-17.772566336089568\n",
            "length of actions is  240\n",
            "5.334979082510358\n",
            "length of actions is  144\n",
            "11.830250979340747\n",
            "length of actions is  132\n",
            "Your final reward is : 1.42\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1648])\n",
            "-58.74293314002182\n",
            "length of actions is  247\n",
            "-27.04991591797514\n",
            "length of actions is  203\n",
            "-22.584518925972475\n",
            "length of actions is  147\n",
            "23.922496012473673\n",
            "length of actions is  128\n",
            "-1.6805402004509915\n",
            "length of actions is  221\n",
            "Your final reward is : -17.23\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1756])\n",
            "-57.50076664544174\n",
            "length of actions is  244\n",
            "-9.127091781814315\n",
            "length of actions is  185\n",
            "17.46865466912797\n",
            "length of actions is  131\n",
            "0.834557195220043\n",
            "length of actions is  237\n",
            "-7.901179460934316\n",
            "length of actions is  187\n",
            "Your final reward is : -11.25\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2012])\n",
            "-50.55890911780473\n",
            "length of actions is  246\n",
            "34.06366689674937\n",
            "length of actions is  180\n",
            "5.713343248013004\n",
            "length of actions is  165\n",
            "5.038158093148326\n",
            "length of actions is  218\n",
            "1.2977163599225037\n",
            "length of actions is  132\n",
            "Your final reward is : -0.89\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1657])\n",
            "-11.124314620448075\n",
            "length of actions is  226\n",
            "23.0905229540039\n",
            "length of actions is  187\n",
            "9.284579178813914\n",
            "length of actions is  194\n",
            "26.901565174257513\n",
            "length of actions is  139\n",
            "16.74152616203763\n",
            "length of actions is  137\n",
            "Your final reward is : 12.98\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1671])\n",
            "-33.39617178100437\n",
            "length of actions is  238\n",
            "-15.91670010701938\n",
            "length of actions is  209\n",
            "41.0767520882533\n",
            "length of actions is  110\n",
            "34.7726782128361\n",
            "length of actions is  202\n",
            "-23.64868571010129\n",
            "length of actions is  157\n",
            "Your final reward is : 0.58\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1963])\n",
            "-13.308536299875328\n",
            "length of actions is  242\n",
            "50.60411935537903\n",
            "length of actions is  179\n",
            "-1.0920964938189286\n",
            "length of actions is  201\n",
            "22.926276711566672\n",
            "length of actions is  93\n",
            "24.692986675128694\n",
            "length of actions is  232\n",
            "Your final reward is : 16.76\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1859])\n",
            "-15.95899807346781\n",
            "length of actions is  237\n",
            "9.982441808611881\n",
            "length of actions is  248\n",
            "25.987489301601357\n",
            "length of actions is  144\n",
            "-3.351925253259793\n",
            "length of actions is  211\n",
            "-17.972923828802635\n",
            "length of actions is  204\n",
            "Your final reward is : -0.26\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1880])\n",
            "7.4216325845210775\n",
            "length of actions is  250\n",
            "-11.966403580514282\n",
            "length of actions is  207\n",
            "-26.198255210953988\n",
            "length of actions is  199\n",
            "37.33809927602596\n",
            "length of actions is  140\n",
            "22.509844499009574\n",
            "length of actions is  153\n",
            "Your final reward is : 5.82\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1799])\n",
            "-38.8274577387844\n",
            "length of actions is  299\n",
            "45.741694219827\n",
            "length of actions is  123\n",
            "-2.7550433056576935\n",
            "length of actions is  204\n",
            "-15.861857024444035\n",
            "length of actions is  217\n",
            "6.3762001538769795\n",
            "length of actions is  211\n",
            "Your final reward is : -1.07\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1917])\n",
            "-17.98974323050838\n",
            "length of actions is  259\n",
            "44.9923080550588\n",
            "length of actions is  160\n",
            "27.358105944401345\n",
            "length of actions is  262\n",
            "12.589135569513687\n",
            "length of actions is  221\n",
            "16.812271279694272\n",
            "length of actions is  148\n",
            "Your final reward is : 16.75\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1807])\n",
            "-20.685294357912625\n",
            "length of actions is  280\n",
            "2.022542463723937\n",
            "length of actions is  179\n",
            "-17.729542700066432\n",
            "length of actions is  212\n",
            "51.896308922062474\n",
            "length of actions is  135\n",
            "23.905358522980492\n",
            "length of actions is  245\n",
            "Your final reward is : 7.88\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1886])\n",
            "-13.302859567191078\n",
            "length of actions is  275\n",
            "25.11446919283719\n",
            "length of actions is  203\n",
            "-4.288466911428102\n",
            "length of actions is  193\n",
            "46.02826457938477\n",
            "length of actions is  132\n",
            "35.768259169003755\n",
            "length of actions is  164\n",
            "Your final reward is : 17.86\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2290])\n",
            "-0.312434102878143\n",
            "length of actions is  275\n",
            "31.56932434383515\n",
            "length of actions is  218\n",
            "251.76672748494582\n",
            "length of actions is  349\n",
            "24.91105152670866\n",
            "length of actions is  173\n",
            "44.443845115807676\n",
            "length of actions is  172\n",
            "Your final reward is : 70.48\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2905])\n",
            "-49.263122554436194\n",
            "length of actions is  310\n",
            "37.742149326373635\n",
            "length of actions is  153\n",
            "263.5386256460404\n",
            "length of actions is  244\n",
            "239.24166968688877\n",
            "length of actions is  281\n",
            "251.43158785513484\n",
            "length of actions is  329\n",
            "Your final reward is : 148.54\n",
            "torch.from_numpy(rewards) looks like  torch.Size([2796])\n",
            "-22.004264273984518\n",
            "length of actions is  322\n",
            "234.028417665335\n",
            "length of actions is  258\n",
            "258.25129672395053\n",
            "length of actions is  317\n",
            "36.67682739000358\n",
            "length of actions is  142\n",
            "-5.77292101897757\n",
            "length of actions is  275\n",
            "Your final reward is : 100.24\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3302])\n",
            "-230.12991514077498\n",
            "length of actions is  541\n",
            "184.89445527437869\n",
            "length of actions is  472\n",
            "49.39175084706508\n",
            "length of actions is  170\n",
            "257.455869486958\n",
            "length of actions is  309\n",
            "282.25032820880995\n",
            "length of actions is  250\n",
            "Your final reward is : 108.77\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3024])\n",
            "-26.74757280302954\n",
            "length of actions is  335\n",
            "60.233970297581834\n",
            "length of actions is  153\n",
            "-6.384626336912248\n",
            "length of actions is  274\n",
            "275.2435692864351\n",
            "length of actions is  301\n",
            "-14.915995945951508\n",
            "length of actions is  374\n",
            "Your final reward is : 57.49\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3563])\n",
            "-26.529780155400815\n",
            "length of actions is  376\n",
            "-46.92029705733157\n",
            "length of actions is  384\n",
            "228.69600187305457\n",
            "length of actions is  359\n",
            "5.235546003569539\n",
            "length of actions is  298\n",
            "-34.868148583578886\n",
            "length of actions is  375\n",
            "Your final reward is : 25.12\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3717])\n",
            "-50.660688114497304\n",
            "length of actions is  527\n",
            "-17.508716088022368\n",
            "length of actions is  473\n",
            "-10.824915223800133\n",
            "length of actions is  375\n",
            "-19.356695473205463\n",
            "length of actions is  425\n",
            "269.29615686927724\n",
            "length of actions is  322\n",
            "Your final reward is : 34.19\n",
            "torch.from_numpy(rewards) looks like  torch.Size([3420])\n",
            "226.93036981555747\n",
            "length of actions is  500\n",
            "299.16518715241807\n",
            "length of actions is  272\n",
            "8.995743827625631\n",
            "length of actions is  302\n",
            "-1.155485930462632\n",
            "length of actions is  337\n",
            "285.63335798240627\n",
            "length of actions is  333\n",
            "Your final reward is : 163.91\n",
            "torch.from_numpy(rewards) looks like  torch.Size([4061])\n",
            "220.19140846296807\n",
            "length of actions is  489\n",
            "73.4330742729089\n",
            "length of actions is  117\n",
            "217.24879109057395\n",
            "length of actions is  456\n",
            "-5.834099979364538\n",
            "length of actions is  343\n",
            "213.66517849139814\n",
            "length of actions is  434\n",
            "Your final reward is : 143.74\n",
            "torch.from_numpy(rewards) looks like  torch.Size([4276])\n",
            "225.46296024085197\n",
            "length of actions is  521\n",
            "214.86891211599038\n",
            "length of actions is  590\n",
            "183.06683109407226\n",
            "length of actions is  502\n",
            "258.7568748250754\n",
            "length of actions is  332\n",
            "204.77339461976032\n",
            "length of actions is  413\n",
            "Your final reward is : 217.39\n",
            "torch.from_numpy(rewards) looks like  torch.Size([4574])\n",
            "220.66498397381957\n",
            "length of actions is  603\n",
            "269.62038363952047\n",
            "length of actions is  398\n",
            "307.130171183345\n",
            "length of actions is  217\n",
            "212.12229213250563\n",
            "length of actions is  519\n",
            "217.08302984892947\n",
            "length of actions is  483\n",
            "Your final reward is : 245.32\n",
            "torch.from_numpy(rewards) looks like  torch.Size([4345])\n",
            "218.84673256678073\n",
            "length of actions is  606\n",
            "220.47934647155526\n",
            "length of actions is  518\n",
            "237.53565604490865\n",
            "length of actions is  510\n",
            "236.23136716293752\n",
            "length of actions is  475\n",
            "231.69740385410734\n",
            "length of actions is  482\n",
            "Your final reward is : 228.96\n",
            "torch.from_numpy(rewards) looks like  torch.Size([5980])\n",
            "203.08072604672003\n",
            "length of actions is  632\n",
            "224.66584897857865\n",
            "length of actions is  570\n",
            "188.7848688237134\n",
            "length of actions is  609\n",
            "283.1875418047183\n",
            "length of actions is  327\n",
            "248.68045330864624\n",
            "length of actions is  442\n",
            "Your final reward is : 229.68\n",
            "torch.from_numpy(rewards) looks like  torch.Size([6215])\n",
            "191.73354518175495\n",
            "length of actions is  707\n",
            "292.96544860579843\n",
            "length of actions is  297\n",
            "190.16787976193532\n",
            "length of actions is  674\n",
            "193.49763573736666\n",
            "length of actions is  689\n",
            "227.87784108799497\n",
            "length of actions is  592\n",
            "Your final reward is : 219.25\n",
            "torch.from_numpy(rewards) looks like  torch.Size([6419])\n",
            "194.76239435060626\n",
            "length of actions is  651\n",
            "193.83248963594696\n",
            "length of actions is  621\n",
            "194.65975133515545\n",
            "length of actions is  737\n",
            "214.48441289838132\n",
            "length of actions is  505\n",
            "189.1608100056252\n",
            "length of actions is  692\n",
            "Your final reward is : 197.38\n",
            "torch.from_numpy(rewards) looks like  torch.Size([6134])\n",
            "213.40932869368265\n",
            "length of actions is  565\n",
            "194.8897443407866\n",
            "length of actions is  632\n",
            "70.02173607785355\n",
            "length of actions is  118\n",
            "189.52150420737735\n",
            "length of actions is  461\n",
            "76.77439309927664\n",
            "length of actions is  1000\n",
            "Your final reward is : 148.92\n",
            "torch.from_numpy(rewards) looks like  torch.Size([6351])\n",
            "216.57008459872918\n",
            "length of actions is  534\n",
            "162.7821475280996\n",
            "length of actions is  718\n",
            "263.7193788975675\n",
            "length of actions is  436\n",
            "294.6456473575745\n",
            "length of actions is  302\n",
            "179.32125983083716\n",
            "length of actions is  500\n",
            "Your final reward is : 223.41\n",
            "torch.from_numpy(rewards) looks like  torch.Size([6236])\n",
            "192.7604141671517\n",
            "length of actions is  665\n",
            "304.30624227652294\n",
            "length of actions is  263\n",
            "199.3750673905069\n",
            "length of actions is  511\n",
            "207.94959702902128\n",
            "length of actions is  616\n",
            "160.61989766994293\n",
            "length of actions is  629\n",
            "Your final reward is : 213.00\n",
            "torch.from_numpy(rewards) looks like  torch.Size([6303])\n",
            "116.35172812239598\n",
            "length of actions is  1000\n",
            "110.59024060608078\n",
            "length of actions is  911\n",
            "207.6049806877635\n",
            "length of actions is  541\n",
            "70.25519193573989\n",
            "length of actions is  1000\n",
            "296.8062632467752\n",
            "length of actions is  274\n",
            "Your final reward is : 160.32\n",
            "torch.from_numpy(rewards) looks like  torch.Size([7405])\n",
            "188.79960970382\n",
            "length of actions is  665\n",
            "301.03968361578325\n",
            "length of actions is  218\n",
            "-98.13703656393395\n",
            "length of actions is  810\n",
            "190.02613889529576\n",
            "length of actions is  755\n",
            "237.2897433081355\n",
            "length of actions is  583\n",
            "Your final reward is : 163.80\n",
            "torch.from_numpy(rewards) looks like  torch.Size([7442])\n",
            "128.8944738116998\n",
            "length of actions is  944\n",
            "244.7777505189863\n",
            "length of actions is  444\n",
            "-49.924375695658114\n",
            "length of actions is  1000\n",
            "-12.031137131060362\n",
            "length of actions is  1000\n",
            "40.057704087314754\n",
            "length of actions is  1000\n",
            "Your final reward is : 70.35\n",
            "torch.from_numpy(rewards) looks like  torch.Size([7259])\n",
            "184.11720134735663\n",
            "length of actions is  706\n",
            "269.2497996037012\n",
            "length of actions is  344\n",
            "73.96475712380177\n",
            "length of actions is  1000\n",
            "120.27575381583009\n",
            "length of actions is  927\n",
            "21.881969904224693\n",
            "length of actions is  1000\n",
            "Your final reward is : 133.90\n",
            "torch.from_numpy(rewards) looks like  torch.Size([7294])\n",
            "176.88382966738692\n",
            "length of actions is  748\n",
            "127.4203669610911\n",
            "length of actions is  917\n",
            "292.4551241498302\n",
            "length of actions is  392\n",
            "203.094845667809\n",
            "length of actions is  942\n",
            "72.74825960570553\n",
            "length of actions is  102\n",
            "Your final reward is : 174.52\n",
            "torch.from_numpy(rewards) looks like  torch.Size([8361])\n",
            "53.948331633676254\n",
            "length of actions is  1000\n",
            "-16.866358096727495\n",
            "length of actions is  1000\n",
            "90.03713451021521\n",
            "length of actions is  950\n",
            "254.46773491317143\n",
            "length of actions is  392\n",
            "-72.35464517688379\n",
            "length of actions is  1000\n",
            "Your final reward is : 61.85\n",
            "torch.from_numpy(rewards) looks like  torch.Size([8260])\n",
            "159.00855168316514\n",
            "length of actions is  924\n",
            "-44.74862847163472\n",
            "length of actions is  1000\n",
            "-9.058892869828066\n",
            "length of actions is  1000\n",
            "153.8141433181654\n",
            "length of actions is  822\n",
            "-15.139425815394002\n",
            "length of actions is  1000\n",
            "Your final reward is : 48.78\n",
            "torch.from_numpy(rewards) looks like  torch.Size([9086])\n",
            "115.0749850949303\n",
            "length of actions is  915\n",
            "162.04934798375137\n",
            "length of actions is  767\n",
            "144.16083914924192\n",
            "length of actions is  851\n",
            "18.723114052538268\n",
            "length of actions is  1000\n",
            "117.53705363688213\n",
            "length of actions is  963\n",
            "Your final reward is : 111.51\n",
            "torch.from_numpy(rewards) looks like  torch.Size([8587])\n",
            "-65.54534027389931\n",
            "length of actions is  1000\n",
            "-42.62003248015051\n",
            "length of actions is  1000\n",
            "-41.218066086208445\n",
            "length of actions is  1000\n",
            "180.68055774855037\n",
            "length of actions is  778\n",
            "149.93831998039536\n",
            "length of actions is  833\n",
            "Your final reward is : 36.25\n",
            "torch.from_numpy(rewards) looks like  torch.Size([7978])\n",
            "122.57152799907735\n",
            "length of actions is  926\n",
            "120.56524272471202\n",
            "length of actions is  886\n",
            "90.44461847780225\n",
            "length of actions is  1000\n",
            "126.6187957902612\n",
            "length of actions is  804\n",
            "99.54284279838645\n",
            "length of actions is  990\n",
            "Your final reward is : 111.95\n",
            "torch.from_numpy(rewards) looks like  torch.Size([9624])\n",
            "-27.634028999653765\n",
            "length of actions is  1000\n",
            "102.30170015770068\n",
            "length of actions is  960\n",
            "-29.7019675594668\n",
            "length of actions is  1000\n",
            "-25.77736458963318\n",
            "length of actions is  1000\n",
            "148.12306493002677\n",
            "length of actions is  900\n",
            "Your final reward is : 33.46\n",
            "torch.from_numpy(rewards) looks like  torch.Size([9699])\n",
            "-30.095670121839635\n",
            "length of actions is  1000\n",
            "-46.74092471864425\n",
            "length of actions is  1000\n",
            "-39.06822424687311\n",
            "length of actions is  1000\n",
            "-9.60501275266239\n",
            "length of actions is  1000\n",
            "-4.592538655164064\n",
            "length of actions is  1000\n",
            "Your final reward is : -26.02\n",
            "torch.from_numpy(rewards) looks like  torch.Size([10000])\n",
            "-21.721910265893495\n",
            "length of actions is  1000\n",
            "-46.93877279513168\n",
            "length of actions is  1000\n",
            "-38.78329926322379\n",
            "length of actions is  1000\n",
            "-11.33528595720199\n",
            "length of actions is  1000\n",
            "-3.032778090649291\n",
            "length of actions is  1000\n",
            "Your final reward is : -24.36\n",
            "torch.from_numpy(rewards) looks like  torch.Size([10000])\n",
            "-28.36652772404171\n",
            "length of actions is  1000\n",
            "-48.43925538774142\n",
            "length of actions is  1000\n",
            "-40.95714104958144\n",
            "length of actions is  1000\n",
            "-15.447880623321382\n",
            "length of actions is  1000\n",
            "-0.9182455908192597\n",
            "length of actions is  1000\n",
            "Your final reward is : -26.83\n",
            "torch.from_numpy(rewards) looks like  torch.Size([10000])\n",
            "-26.766391619173866\n",
            "length of actions is  1000\n",
            "-53.625565685870534\n",
            "length of actions is  1000\n",
            "-41.81645400041375\n",
            "length of actions is  1000\n",
            "-15.24109073704022\n",
            "length of actions is  1000\n",
            "-9.672491883019283\n",
            "length of actions is  1000\n",
            "Your final reward is : -29.42\n",
            "torch.from_numpy(rewards) looks like  torch.Size([10000])\n",
            "-23.297185190641006\n",
            "length of actions is  1000\n",
            "-56.72703197042842\n",
            "length of actions is  1000\n",
            "-49.029835610367954\n",
            "length of actions is  1000\n",
            "-14.21774631942471\n",
            "length of actions is  1000\n",
            "-12.653120082743403\n",
            "length of actions is  1000\n",
            "Your final reward is : -31.18\n",
            "torch.from_numpy(rewards) looks like  torch.Size([10000])\n",
            "-30.8038463198558\n",
            "length of actions is  1000\n",
            "-59.14658627024615\n",
            "length of actions is  1000\n",
            "-54.2320920952104\n",
            "length of actions is  1000\n",
            "-24.17064208806379\n",
            "length of actions is  1000\n",
            "-17.537853704734378\n",
            "length of actions is  1000\n",
            "Your final reward is : -37.18\n",
            "torch.from_numpy(rewards) looks like  torch.Size([10000])\n",
            "-38.27924168927824\n",
            "length of actions is  1000\n",
            "-65.14000602175051\n",
            "length of actions is  1000\n",
            "-58.96866864756953\n",
            "length of actions is  1000\n",
            "-23.028442891105914\n",
            "length of actions is  1000\n",
            "-20.215231103256002\n",
            "length of actions is  1000\n",
            "Your final reward is : -41.13\n",
            "torch.from_numpy(rewards) looks like  torch.Size([10000])\n",
            "-46.381462417063815\n",
            "length of actions is  1000\n",
            "-80.65730125831647\n",
            "length of actions is  1000\n",
            "-61.210704399019015\n",
            "length of actions is  1000\n",
            "-37.84325040021608\n",
            "length of actions is  1000\n",
            "-16.852622291110954\n",
            "length of actions is  1000\n",
            "Your final reward is : -48.59\n",
            "torch.from_numpy(rewards) looks like  torch.Size([10000])\n",
            "-56.575282617687726\n",
            "length of actions is  1000\n",
            "-101.55367505636089\n",
            "length of actions is  1000\n",
            "-121.42085429311348\n",
            "length of actions is  1000\n",
            "-38.07538701806213\n",
            "length of actions is  1000\n",
            "-39.77590818101946\n",
            "length of actions is  1000\n",
            "Your final reward is : -71.48\n",
            "torch.from_numpy(rewards) looks like  torch.Size([10000])\n",
            "-71.93294305191505\n",
            "length of actions is  1000\n",
            "-71.69487351718362\n",
            "length of actions is  1000\n",
            "-77.48737317012585\n",
            "length of actions is  1000\n",
            "-65.02920073390156\n",
            "length of actions is  1000\n",
            "-58.14328199941233\n",
            "length of actions is  1000\n",
            "Your final reward is : -68.86\n",
            "torch.from_numpy(rewards) looks like  torch.Size([10000])\n",
            "-76.97844570286775\n",
            "length of actions is  1000\n",
            "-93.16148161400163\n",
            "length of actions is  1000\n",
            "-113.0586784667475\n",
            "length of actions is  1000\n",
            "-46.89830978143074\n",
            "length of actions is  1000\n",
            "-55.654260535013236\n",
            "length of actions is  1000\n",
            "Your final reward is : -77.15\n",
            "torch.from_numpy(rewards) looks like  torch.Size([10000])\n",
            "-79.29352702673094\n",
            "length of actions is  1000\n",
            "-103.22180680462058\n",
            "length of actions is  1000\n",
            "-99.55360339790188\n",
            "length of actions is  1000\n",
            "-51.584112177623716\n",
            "length of actions is  1000\n",
            "-49.51395100980191\n",
            "length of actions is  1000\n",
            "Your final reward is : -76.63\n",
            "torch.from_numpy(rewards) looks like  torch.Size([9615])\n",
            "-160.07777135523412\n",
            "length of actions is  711\n",
            "-139.40727427816557\n",
            "length of actions is  1000\n",
            "-128.48479741383352\n",
            "length of actions is  1000\n",
            "-75.56258953757958\n",
            "length of actions is  1000\n",
            "-91.23127710196982\n",
            "length of actions is  1000\n",
            "Your final reward is : -118.95\n",
            "torch.from_numpy(rewards) looks like  torch.Size([10000])\n",
            "-109.88521441649382\n",
            "length of actions is  1000\n",
            "-122.49645861542663\n",
            "length of actions is  1000\n",
            "-116.63900971673601\n",
            "length of actions is  1000\n",
            "-71.36479127967478\n",
            "length of actions is  1000\n",
            "-82.76415494874664\n",
            "length of actions is  1000\n",
            "Your final reward is : -100.63\n",
            "torch.from_numpy(rewards) looks like  torch.Size([9591])\n",
            "-172.70599169925782\n",
            "length of actions is  758\n",
            "-104.89377701331667\n",
            "length of actions is  1000\n",
            "-97.34139110066134\n",
            "length of actions is  1000\n",
            "-91.07910419000248\n",
            "length of actions is  1000\n",
            "-152.6820678315188\n",
            "length of actions is  547\n",
            "Your final reward is : -123.74\n",
            "torch.from_numpy(rewards) looks like  torch.Size([8252])\n",
            "220.1121704815671\n",
            "length of actions is  412\n",
            "150.53912632752724\n",
            "length of actions is  682\n",
            "-117.62791408307125\n",
            "length of actions is  567\n",
            "-186.9047211475908\n",
            "length of actions is  909\n",
            "-116.64145273096679\n",
            "length of actions is  1000\n",
            "Your final reward is : -10.10\n",
            "torch.from_numpy(rewards) looks like  torch.Size([8819])\n",
            "-176.1996131942222\n",
            "length of actions is  738\n",
            "-75.51679499487126\n",
            "length of actions is  1000\n",
            "-207.5849882991565\n",
            "length of actions is  900\n",
            "-79.88471330756245\n",
            "length of actions is  1000\n",
            "-204.15047365367485\n",
            "length of actions is  932\n",
            "Your final reward is : -148.67\n",
            "torch.from_numpy(rewards) looks like  torch.Size([8791])\n",
            "159.0614759814979\n",
            "length of actions is  536\n",
            "-155.54301470535523\n",
            "length of actions is  561\n",
            "-90.17795216589528\n",
            "length of actions is  1000\n",
            "67.53855585354897\n",
            "length of actions is  707\n",
            "75.17966511379124\n",
            "length of actions is  865\n",
            "Your final reward is : 11.21\n",
            "torch.from_numpy(rewards) looks like  torch.Size([8994])\n",
            "-214.97113690276387\n",
            "length of actions is  965\n",
            "-184.05582591232078\n",
            "length of actions is  781\n",
            "-22.19968844481284\n",
            "length of actions is  1000\n",
            "-76.4932540057679\n",
            "length of actions is  1000\n",
            "-171.7517810405737\n",
            "length of actions is  737\n",
            "Your final reward is : -133.89\n",
            "torch.from_numpy(rewards) looks like  torch.Size([9164])\n",
            "-32.21418811578509\n",
            "length of actions is  1000\n",
            "-153.34967380795223\n",
            "length of actions is  403\n",
            "71.63481763630595\n",
            "length of actions is  1000\n",
            "-79.96327595634612\n",
            "length of actions is  1000\n",
            "-96.10164048506401\n",
            "length of actions is  1000\n",
            "Your final reward is : -58.00\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-b4ccb7a39aa3>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m       \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_q_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-704c2db20546>\u001b[0m in \u001b[0;36mupdate_q_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnon_final_next_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_minibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpected_state_action_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_state_action_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_main_q_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-704c2db20546>\u001b[0m in \u001b[0;36mget_expected_state_action_values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     self.state_action_values = self.main_q_network(\n\u001b[0;32m---> 59\u001b[0;31m         self.state_batch).gather(1, self.action_batch)\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     non_final_mask = torch.BoolTensor(tuple(map(lambda s: s is not None,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg5rxBBaf38_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1b7926708a3a47839be22ae2ac4e14ed",
            "00026535ab9e49f88c97fa0f3711183c",
            "981cf0ff0ba14c098f9c6ed4c1cf0b5e",
            "a257cb4fe8dc431ea51ad879ae91c494",
            "b9c076fd23274f1dbc74bb504d6688f2",
            "d0d778949e074108b1a37c29e5f49b9f",
            "64b4a1461bbb48dc917914015605f484",
            "a609bf3ce4a34088828127a024b1b684",
            "d433874cd5d7498f858057cb84e61523",
            "5d7aad2b2d1344a89a2e8f50602b093c",
            "1ed1cbfb63e04f83b907acddb3474ac5"
          ]
        },
        "outputId": "e24b22a6-e795-4eb6-f083-18b37a4bd4f6"
      },
      "source": [
        "# agent.network.train()  # Switch network into training mode\n",
        "# EPISODE_PER_BATCH = 5  # update the  agent every 5 episode\n",
        "# NUM_BATCH = 100        # totally update the agent for 500 time\n",
        "\n",
        "# avg_total_rewards, avg_final_rewards = [], []\n",
        "\n",
        "# prg_bar = tqdm(range(NUM_BATCH))\n",
        "# for batch in prg_bar:\n",
        "\n",
        "#     log_probs, rewards = [], []\n",
        "#     total_rewards, final_rewards = [], []\n",
        "\n",
        "#     # collect trajectory\n",
        "#     for episode in range(EPISODE_PER_BATCH):\n",
        "\n",
        "#         state = env.reset()\n",
        "#         total_reward, total_step = 0, 0\n",
        "#         seq_rewards = []\n",
        "#         while True:\n",
        "\n",
        "#             action, log_prob = agent.sample(state) # at, log(at|st)\n",
        "#             next_state, reward, done, _ = env.step(action)\n",
        "\n",
        "#             log_probs.append(log_prob) # [log(a1|s1), log(a2|s2), ...., log(at|st)]\n",
        "#             # seq_rewards.append(reward)\n",
        "#             state = next_state\n",
        "#             total_reward += reward\n",
        "#             total_step += 1\n",
        "#             rewards.append(reward) # change here\n",
        "#             # ! IMPORTANT !\n",
        "#             # Current reward implementation: immediate reward,  given action_list : a1, a2, a3 ......\n",
        "#             #                                                         rewards :     r1, r2 ,r3 ......\n",
        "#             # medium：change \"rewards\" to accumulative decaying reward, given action_list : a1,                           a2,                           a3, ......\n",
        "#             #                                                           rewards :           r1+0.99*r2+0.99^2*r3+......, r2+0.99*r3+0.99^2*r4+...... ,  r3+0.99*r4+0.99^2*r5+ ......\n",
        "#             # hard : implement Actor-Critic\n",
        "#             if done:\n",
        "#                 final_rewards.append(reward)\n",
        "#                 total_rewards.append(total_reward)\n",
        "\n",
        "#                 break\n",
        "\n",
        "#     print(f\"rewards looks like \", np.shape(rewards))\n",
        "#     #print(f\"log_probs looks like \", np.shape(log_probs))\n",
        "#     # record training process\n",
        "#     avg_total_reward = sum(total_rewards) / len(total_rewards)\n",
        "#     avg_final_reward = sum(final_rewards) / len(final_rewards)\n",
        "#     avg_total_rewards.append(avg_total_reward)\n",
        "#     avg_final_rewards.append(avg_final_reward)\n",
        "#     prg_bar.set_description(f\"Total: {avg_total_reward: 4.1f}, Final: {avg_final_reward: 4.1f}\")\n",
        "\n",
        "#     # update agent\n",
        "#     # rewards = np.concatenate(rewards, axis=0)\n",
        "#     rewards = (rewards - np.mean(rewards)) / (np.std(rewards) + 1e-9)  # normalize the reward\n",
        "#     agent.learn(torch.stack(log_probs), torch.from_numpy(rewards))\n",
        "#     print(\"logs prob looks like \", torch.stack(log_probs).size())\n",
        "#     print(\"torch.from_numpy(rewards) looks like \", torch.from_numpy(rewards).size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b7926708a3a47839be22ae2ac4e14ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rewards looks like  (510,)\n",
            "logs prob looks like  torch.Size([510])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([510])\n",
            "rewards looks like  (491,)\n",
            "logs prob looks like  torch.Size([491])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([491])\n",
            "rewards looks like  (1358,)\n",
            "logs prob looks like  torch.Size([1358])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1358])\n",
            "rewards looks like  (500,)\n",
            "logs prob looks like  torch.Size([500])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([500])\n",
            "rewards looks like  (452,)\n",
            "logs prob looks like  torch.Size([452])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([452])\n",
            "rewards looks like  (388,)\n",
            "logs prob looks like  torch.Size([388])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([388])\n",
            "rewards looks like  (465,)\n",
            "logs prob looks like  torch.Size([465])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([465])\n",
            "rewards looks like  (540,)\n",
            "logs prob looks like  torch.Size([540])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([540])\n",
            "rewards looks like  (411,)\n",
            "logs prob looks like  torch.Size([411])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([411])\n",
            "rewards looks like  (559,)\n",
            "logs prob looks like  torch.Size([559])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([559])\n",
            "rewards looks like  (488,)\n",
            "logs prob looks like  torch.Size([488])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([488])\n",
            "rewards looks like  (487,)\n",
            "logs prob looks like  torch.Size([487])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([487])\n",
            "rewards looks like  (489,)\n",
            "logs prob looks like  torch.Size([489])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([489])\n",
            "rewards looks like  (531,)\n",
            "logs prob looks like  torch.Size([531])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([531])\n",
            "rewards looks like  (694,)\n",
            "logs prob looks like  torch.Size([694])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([694])\n",
            "rewards looks like  (442,)\n",
            "logs prob looks like  torch.Size([442])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([442])\n",
            "rewards looks like  (519,)\n",
            "logs prob looks like  torch.Size([519])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([519])\n",
            "rewards looks like  (492,)\n",
            "logs prob looks like  torch.Size([492])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([492])\n",
            "rewards looks like  (429,)\n",
            "logs prob looks like  torch.Size([429])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([429])\n",
            "rewards looks like  (574,)\n",
            "logs prob looks like  torch.Size([574])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([574])\n",
            "rewards looks like  (489,)\n",
            "logs prob looks like  torch.Size([489])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([489])\n",
            "rewards looks like  (454,)\n",
            "logs prob looks like  torch.Size([454])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([454])\n",
            "rewards looks like  (443,)\n",
            "logs prob looks like  torch.Size([443])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([443])\n",
            "rewards looks like  (541,)\n",
            "logs prob looks like  torch.Size([541])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([541])\n",
            "rewards looks like  (578,)\n",
            "logs prob looks like  torch.Size([578])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([578])\n",
            "rewards looks like  (518,)\n",
            "logs prob looks like  torch.Size([518])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([518])\n",
            "rewards looks like  (597,)\n",
            "logs prob looks like  torch.Size([597])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([597])\n",
            "rewards looks like  (692,)\n",
            "logs prob looks like  torch.Size([692])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([692])\n",
            "rewards looks like  (484,)\n",
            "logs prob looks like  torch.Size([484])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([484])\n",
            "rewards looks like  (549,)\n",
            "logs prob looks like  torch.Size([549])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([549])\n",
            "rewards looks like  (620,)\n",
            "logs prob looks like  torch.Size([620])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([620])\n",
            "rewards looks like  (579,)\n",
            "logs prob looks like  torch.Size([579])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([579])\n",
            "rewards looks like  (617,)\n",
            "logs prob looks like  torch.Size([617])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([617])\n",
            "rewards looks like  (492,)\n",
            "logs prob looks like  torch.Size([492])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([492])\n",
            "rewards looks like  (526,)\n",
            "logs prob looks like  torch.Size([526])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([526])\n",
            "rewards looks like  (545,)\n",
            "logs prob looks like  torch.Size([545])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([545])\n",
            "rewards looks like  (475,)\n",
            "logs prob looks like  torch.Size([475])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([475])\n",
            "rewards looks like  (592,)\n",
            "logs prob looks like  torch.Size([592])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([592])\n",
            "rewards looks like  (645,)\n",
            "logs prob looks like  torch.Size([645])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([645])\n",
            "rewards looks like  (602,)\n",
            "logs prob looks like  torch.Size([602])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([602])\n",
            "rewards looks like  (503,)\n",
            "logs prob looks like  torch.Size([503])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([503])\n",
            "rewards looks like  (850,)\n",
            "logs prob looks like  torch.Size([850])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([850])\n",
            "rewards looks like  (626,)\n",
            "logs prob looks like  torch.Size([626])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([626])\n",
            "rewards looks like  (589,)\n",
            "logs prob looks like  torch.Size([589])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([589])\n",
            "rewards looks like  (614,)\n",
            "logs prob looks like  torch.Size([614])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([614])\n",
            "rewards looks like  (424,)\n",
            "logs prob looks like  torch.Size([424])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([424])\n",
            "rewards looks like  (478,)\n",
            "logs prob looks like  torch.Size([478])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([478])\n",
            "rewards looks like  (540,)\n",
            "logs prob looks like  torch.Size([540])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([540])\n",
            "rewards looks like  (633,)\n",
            "logs prob looks like  torch.Size([633])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([633])\n",
            "rewards looks like  (550,)\n",
            "logs prob looks like  torch.Size([550])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([550])\n",
            "rewards looks like  (529,)\n",
            "logs prob looks like  torch.Size([529])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([529])\n",
            "rewards looks like  (623,)\n",
            "logs prob looks like  torch.Size([623])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([623])\n",
            "rewards looks like  (590,)\n",
            "logs prob looks like  torch.Size([590])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([590])\n",
            "rewards looks like  (777,)\n",
            "logs prob looks like  torch.Size([777])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([777])\n",
            "rewards looks like  (651,)\n",
            "logs prob looks like  torch.Size([651])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([651])\n",
            "rewards looks like  (626,)\n",
            "logs prob looks like  torch.Size([626])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([626])\n",
            "rewards looks like  (593,)\n",
            "logs prob looks like  torch.Size([593])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([593])\n",
            "rewards looks like  (586,)\n",
            "logs prob looks like  torch.Size([586])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([586])\n",
            "rewards looks like  (680,)\n",
            "logs prob looks like  torch.Size([680])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([680])\n",
            "rewards looks like  (548,)\n",
            "logs prob looks like  torch.Size([548])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([548])\n",
            "rewards looks like  (644,)\n",
            "logs prob looks like  torch.Size([644])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([644])\n",
            "rewards looks like  (470,)\n",
            "logs prob looks like  torch.Size([470])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([470])\n",
            "rewards looks like  (672,)\n",
            "logs prob looks like  torch.Size([672])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([672])\n",
            "rewards looks like  (654,)\n",
            "logs prob looks like  torch.Size([654])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([654])\n",
            "rewards looks like  (661,)\n",
            "logs prob looks like  torch.Size([661])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([661])\n",
            "rewards looks like  (820,)\n",
            "logs prob looks like  torch.Size([820])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([820])\n",
            "rewards looks like  (658,)\n",
            "logs prob looks like  torch.Size([658])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([658])\n",
            "rewards looks like  (775,)\n",
            "logs prob looks like  torch.Size([775])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([775])\n",
            "rewards looks like  (929,)\n",
            "logs prob looks like  torch.Size([929])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([929])\n",
            "rewards looks like  (748,)\n",
            "logs prob looks like  torch.Size([748])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([748])\n",
            "rewards looks like  (847,)\n",
            "logs prob looks like  torch.Size([847])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([847])\n",
            "rewards looks like  (650,)\n",
            "logs prob looks like  torch.Size([650])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([650])\n",
            "rewards looks like  (750,)\n",
            "logs prob looks like  torch.Size([750])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([750])\n",
            "rewards looks like  (592,)\n",
            "logs prob looks like  torch.Size([592])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([592])\n",
            "rewards looks like  (674,)\n",
            "logs prob looks like  torch.Size([674])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([674])\n",
            "rewards looks like  (713,)\n",
            "logs prob looks like  torch.Size([713])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([713])\n",
            "rewards looks like  (637,)\n",
            "logs prob looks like  torch.Size([637])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([637])\n",
            "rewards looks like  (802,)\n",
            "logs prob looks like  torch.Size([802])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([802])\n",
            "rewards looks like  (918,)\n",
            "logs prob looks like  torch.Size([918])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([918])\n",
            "rewards looks like  (1007,)\n",
            "logs prob looks like  torch.Size([1007])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1007])\n",
            "rewards looks like  (749,)\n",
            "logs prob looks like  torch.Size([749])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([749])\n",
            "rewards looks like  (700,)\n",
            "logs prob looks like  torch.Size([700])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([700])\n",
            "rewards looks like  (840,)\n",
            "logs prob looks like  torch.Size([840])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([840])\n",
            "rewards looks like  (878,)\n",
            "logs prob looks like  torch.Size([878])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([878])\n",
            "rewards looks like  (718,)\n",
            "logs prob looks like  torch.Size([718])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([718])\n",
            "rewards looks like  (828,)\n",
            "logs prob looks like  torch.Size([828])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([828])\n",
            "rewards looks like  (833,)\n",
            "logs prob looks like  torch.Size([833])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([833])\n",
            "rewards looks like  (952,)\n",
            "logs prob looks like  torch.Size([952])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([952])\n",
            "rewards looks like  (624,)\n",
            "logs prob looks like  torch.Size([624])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([624])\n",
            "rewards looks like  (646,)\n",
            "logs prob looks like  torch.Size([646])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([646])\n",
            "rewards looks like  (1028,)\n",
            "logs prob looks like  torch.Size([1028])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1028])\n",
            "rewards looks like  (1266,)\n",
            "logs prob looks like  torch.Size([1266])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1266])\n",
            "rewards looks like  (976,)\n",
            "logs prob looks like  torch.Size([976])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([976])\n",
            "rewards looks like  (1333,)\n",
            "logs prob looks like  torch.Size([1333])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1333])\n",
            "rewards looks like  (609,)\n",
            "logs prob looks like  torch.Size([609])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([609])\n",
            "rewards looks like  (572,)\n",
            "logs prob looks like  torch.Size([572])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([572])\n",
            "rewards looks like  (733,)\n",
            "logs prob looks like  torch.Size([733])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([733])\n",
            "rewards looks like  (1003,)\n",
            "logs prob looks like  torch.Size([1003])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1003])\n",
            "rewards looks like  (1688,)\n",
            "logs prob looks like  torch.Size([1688])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1688])\n",
            "rewards looks like  (1429,)\n",
            "logs prob looks like  torch.Size([1429])\n",
            "torch.from_numpy(rewards) looks like  torch.Size([1429])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNb_tuFYhKVK"
      },
      "source": [
        "### Training Result\n",
        "During the training process, we recorded `avg_total_reward`, which represents the average total reward of episodes before updating the policy network.\n",
        "\n",
        "Theoretically, if the agent becomes better, the `avg_total_reward` will increase.\n",
        "The visualization of the training process is shown below:  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZYOI8H10SHN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "da104eb3-dc64-40ef-ae0c-dc55ec6fc811"
      },
      "source": [
        "plt.plot(avg_total_rewards)\n",
        "plt.title(\"Total Rewards\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mV5jj4dThz0Y"
      },
      "source": [
        "In addition, `avg_final_reward` represents average final rewards of episodes. To be specific, final rewards is the last reward received in one episode, indicating whether the craft lands successfully or not.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txDZ5vlGWz5w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "958f1ad0-04b2-4c6b-a578-56e103896f69"
      },
      "source": [
        "plt.plot(avg_final_rewards)\n",
        "plt.title(\"Final Rewards\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2HaGRVEYGQS"
      },
      "source": [
        "## Testing\n",
        "The testing result will be the average reward of 5 testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yFuUKKRYH73"
      },
      "source": [
        "# fix(env, seed)\n",
        "# agent.network.eval()  # set the network into evaluation mode\n",
        "# NUM_OF_TEST = 5 # Do not revise this !!!\n",
        "# test_total_reward = []\n",
        "# action_list = []\n",
        "# for i in range(NUM_OF_TEST):\n",
        "#   actions = []\n",
        "#   state = env.reset()\n",
        "\n",
        "#   img = plt.imshow(env.render(mode='rgb_array'))\n",
        "\n",
        "#   total_reward = 0\n",
        "\n",
        "#   done = False\n",
        "#   while not done:\n",
        "#       action, _ = agent.sample(state)\n",
        "#       actions.append(action)\n",
        "#       state, reward, done, _ = env.step(action)\n",
        "\n",
        "#       total_reward += reward\n",
        "\n",
        "#       img.set_data(env.render(mode='rgb_array'))\n",
        "#       display.display(plt.gcf())\n",
        "#       display.clear_output(wait=True)\n",
        "\n",
        "#   print(total_reward)\n",
        "#   test_total_reward.append(total_reward)\n",
        "\n",
        "#   action_list.append(actions) # save the result of testing\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aex7mcKr0J01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ead1fc52-4dea-44d3-bc31-a89eee134ead"
      },
      "source": [
        "print(test_total_reward)\n",
        "print(np.mean(test_total_reward))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[277.5713884852359, 249.8725182292896, 253.72760937740912, 261.9768367382054, 85.56346320983471]\n",
            "225.74236320799497\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leyebGYRpqsF"
      },
      "source": [
        "Action list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGAH4YWDpp4u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2920aa9-423a-4559-be8d-c9382ddac1ef"
      },
      "source": [
        "print(\"Action list looks like \", action_list)\n",
        "print(\"Action list's shape looks like \", np.shape(action_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action list looks like  [[3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 0, 1, 3, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1, 2, 1, 2, 1, 1, 2, 2, 2, 1, 2, 0, 0, 0, 2, 0, 2, 3, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 3, 2, 2, 1, 2, 3, 1, 3, 2, 1, 3, 2, 2, 1, 3, 2, 1, 3, 2, 2, 2, 2, 1, 2, 3, 2, 1, 2, 3, 2, 2, 2, 2, 3, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 3, 2, 2, 2, 2, 2, 3, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 3, 3, 2, 2, 2, 1, 2, 2, 1, 3, 0, 2, 2, 2, 1, 0, 0, 2, 2, 2, 2, 1, 1, 1, 0, 2, 2, 1, 1, 1, 2, 2, 3, 3, 3, 3, 3, 3, 0, 3, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 3, 0, 3, 0, 0, 3, 0, 0, 0, 3, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 1, 2, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 0, 2, 1, 2, 2, 0, 2, 2, 0, 0, 2, 2, 0, 0, 2, 0, 3, 2, 2, 1, 3, 2, 2, 2, 1, 2, 2, 3, 1, 3, 2, 1, 3, 3, 2, 1, 3, 2, 2, 2, 1, 2, 2, 2, 1, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 1, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 3, 2, 2, 1, 3, 3, 2, 2, 0, 0, 2, 0, 0, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, 3, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 1, 2, 2, 0, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0, 2, 0, 3, 2, 1, 0, 3, 2, 0, 2, 0, 2, 2, 0, 3, 2, 1, 3, 2, 2, 2, 1, 3, 2, 1, 2, 3, 1, 2, 2, 2, 1, 2, 3, 1, 2, 3, 2, 1, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 1, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 1, 2, 0, 2, 0, 2, 0, 0, 2, 0, 2, 2, 0, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 3, 3, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3, 3, 3, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 3, 3, 1, 3, 3, 1, 3, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 2, 3, 2, 2, 2, 0, 2, 3, 2, 2, 2, 2, 3, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 3, 2, 2, 2, 0, 2, 1, 3, 2, 1, 3, 2, 2, 1, 3, 2, 2, 1, 3, 2, 2, 1, 3, 2, 1, 2, 1, 2, 3, 2, 2, 1, 2, 2, 2, 3, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 3, 3, 2, 2, 3, 2, 2, 0, 3, 2, 1, 3, 2, 2, 0, 2, 0, 0, 2, 3, 2, 0, 2, 2, 2, 2, 0, 2, 3, 2, 1, 2, 3, 1, 2, 2, 1, 2, 3, 2, 2, 2, 2, 1, 1, 3, 3, 3, 3, 3, 3, 3, 0, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 2, 3, 3, 3, 2, 3, 3, 3, 2, 2, 3, 2, 2, 2, 3, 2, 3, 3, 2, 2, 2, 3, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 1, 2, 2, 3, 1, 2, 2, 3, 1, 2, 2, 3, 2, 1, 2, 2, 1, 2, 2, 3, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]\n",
            "Action list's shape looks like  (5,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:2009: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNkmwucrHMen"
      },
      "source": [
        "Analysis of actions taken by agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHdAItjj1nxw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a07c3129-1b23-4265-85af-d7f3e2a8afc0"
      },
      "source": [
        "distribution = {}\n",
        "for actions in action_list:\n",
        "  for action in actions:\n",
        "    if action not in distribution.keys():\n",
        "      distribution[action] = 1\n",
        "    else:\n",
        "      distribution[action] += 1\n",
        "print(distribution)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{3: 169, 1: 128, 0: 292, 2: 484}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9ekhg-O1W8g",
        "outputId": "db5df423-0f9f-4127-d3a3-3fd9f0143baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "356"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ricE0schY75M"
      },
      "source": [
        "Saving the result of Model Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZsMkGmIY42b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec1e0561-2085-436a-96d1-7fe8bce1b164"
      },
      "source": [
        "PATH = \"Action_List_test\" + str(best_batch) + \".npy\"# Can be modified into the name or path you want\n",
        "np.save(PATH ,np.array(action_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-a88282b32115>:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  np.save(PATH ,np.array(action_list))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "USKX53JE_Ytf",
        "outputId": "134cb3ab-88da-412f-e433-a54496856c78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Action_List_test330.npy'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asK7WfbkaLjt"
      },
      "source": [
        "### This is the file you need to submit !!!\n",
        "Download the testing result to your device\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-CqyhHzaWAL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "db96c944-4b4e-4597-d7cc-d5ae4d334ebe"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3ce96743-437b-45e4-9764-04eedfba8dee\", \"Action_List_262.npy\", 3767)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seT4NUmWmAZ1"
      },
      "source": [
        "# Reproduction for Evaluation\n",
        "The code below simulates the environment and is used for grading."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U69c-YTxaw6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78d68524-fc84-4f07-965a-057254ee85b0"
      },
      "source": [
        "action_list = np.load('/content/Action_List_297.npy',allow_pickle=True) # The action list you submit\n",
        "seed = 2023 # Do not revise this\n",
        "fix(env, seed)\n",
        "\n",
        "#agent.network.eval()  # set network to evaluation mode\n",
        "\n",
        "test_total_reward = []\n",
        "if len(action_list) != 5:\n",
        "  print(\"Wrong format of file !!!\")\n",
        "  exit(0)\n",
        "for actions in action_list:\n",
        "\n",
        "  state = env.reset()\n",
        "  #img = plt.imshow(env.render(mode='rgb_array'))\n",
        "\n",
        "  total_reward = 0\n",
        "\n",
        "  done = False\n",
        "  done_count = 0\n",
        "  for action in actions:\n",
        "    state, reward, done, _ = env.step(action)\n",
        "    done_count += 1\n",
        "    total_reward += reward\n",
        "    if done:\n",
        "      break\n",
        "\n",
        "  print(f\"Your reward is : %.2f\"%total_reward)\n",
        "  test_total_reward.append(total_reward)\n",
        "print(f\"Your final reward is : %.2f\"%np.mean(test_total_reward))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your reward is : 267.55\n",
            "Your reward is : 285.34\n",
            "Your reward is : 310.62\n",
            "Your reward is : 315.04\n",
            "Your reward is : 308.42\n",
            "Your final reward is : 297.39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjFBWwQP1hVe"
      },
      "source": [
        "# Your score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpJpZz3Wbm0X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b472cc7-7592-4eb6-c6d0-3a95ad0ca308"
      },
      "source": [
        "print(f\"Your final reward is : %.2f\"%np.mean(test_total_reward))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your final reward is : 290.41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#375 274\n",
        "#356"
      ],
      "metadata": {
        "id": "tTUEhm4nOaxe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}